# matcher_streamlit_beauty_rtl_v3.py
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from dataclasses import dataclass
from typing import Optional, Dict, Any, List, Tuple

st.set_page_config(page_title="××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”", layout="wide")

# ====== ×¢×™×¦×•×‘ ××•×“×¨× ×™ + RTL + ×”×¡×ª×¨×ª "Press Enter to apply" ======
st.markdown("""
<style>
@font-face { font-family:'David'; src:url('https://example.com/David.ttf') format('truetype'); }
html, body, [class*="css"] { font-family:'David',sans-serif!important; }

/* ====== ×¢×™×¦×•×‘ ××•×“×¨× ×™ + RTL ====== */
:root{
  --bg-1:#e0f7fa; --bg-2:#ede7f6; --bg-3:#fff3e0; --bg-4:#fce4ec; --bg-5:#e8f5e9;
  --ink:#0f172a; --primary:#9b5de5; --primary-700:#f15bb5; --ring:rgba(155,93,229,.35);
}
[data-testid="stAppViewContainer"]{
  background:
    radial-gradient(1200px 600px at 15% 10%, var(--bg-2) 0%, transparent 70%),
    radial-gradient(1000px 700px at 85% 20%, var(--bg-3) 0%, transparent 70%),
    radial-gradient(900px 500px at 50% 80%, var(--bg-4) 0%, transparent 70%),
    radial-gradient(700px 400px at 10% 85%, var(--bg-5) 0%, transparent 70%),
    linear-gradient(135deg, var(--bg-1) 0%, #ffffff 100%) !important;
  color: var(--ink);
}
.main .block-container{
  background: rgba(255,255,255,.78);
  backdrop-filter: blur(10px);
  border:1px solid rgba(15,23,42,.08);
  box-shadow:0 15px 35px rgba(15,23,42,.08);
  border-radius:24px; padding:2.5rem; margin-top:1rem;
}
/* ×›×•×ª×¨×•×ª */
h1,h2,h3,.stMarkdown h1,.stMarkdown h2{
  text-align:center; letter-spacing:.5px; text-shadow:0 1px 2px rgba(255,255,255,.7);
  font-weight:700; color:#222; margin-bottom:1rem;
}
/* ×›×¤×ª×•×¨ */
.stButton > button{
  background:linear-gradient(135deg,var(--primary) 0%,var(--primary-700) 100%)!important;
  color:#fff!important; border:none!important; border-radius:18px!important;
  padding:1rem 2rem!important; font-size:1.1rem!important; font-weight:600!important;
  box-shadow:0 8px 18px var(--ring)!important; transition:all .15s ease!important;
}
.stButton > button:hover{ transform:translateY(-3px) scale(1.02); filter:brightness(1.08); }
.stButton > button:focus{ outline:none!important; box-shadow:0 0 0 4px var(--ring)!important; }

/* ×§×œ×˜×™× */
div.stSelectbox > div, div.stMultiSelect > div, .stTextInput > div > div > input{
  border-radius:14px!important; border:1px solid rgba(15,23,42,.12)!important;
  box-shadow:0 3px 10px rgba(15,23,42,.04)!important; padding:.6rem .8rem!important;
  color:var(--ink)!important; font-size:1rem!important;
}

/* ×˜××‘×™× â€“ ×¨×•×—×‘ ×§×˜×Ÿ ×™×•×ª×¨ */
.stTabs [data-baseweb="tab"]{
  border-radius:14px!important; background:rgba(255,255,255,.65);
  margin-inline-start:.3rem; padding:.4rem .8rem; font-weight:600;
  min-width: 110px !important; text-align:center; font-size:0.9rem !important;
}
.stTabs [data-baseweb="tab"]:hover{ background:rgba(255,255,255,.9); }

/* RTL */
.stApp,.main,[data-testid="stSidebar"]{ direction:rtl; text-align:right; }
label,.stMarkdown,.stText,.stCaption{ text-align:right!important; }

/* ×”×¡×ª×¨×ª ×˜×™×¤ "Press Enter to apply" */
*[title="Press Enter to apply"]{ display:none !important; }

/* ====== ×›×¤×ª×•×¨×™ ×”×•×¨×“×” â€“ ×¡×’× ×•×Ÿ "×¤×™×œ" ====== */
div.stDownloadButton{ direction:rtl; text-align:right; }
div.stDownloadButton > button{
  border:1px solid rgba(15,23,42,.12)!important; border-radius:999px!important;
  padding:.85rem 1.2rem!important; font-size:1.05rem!important; font-weight:600!important;
  background:#fff!important; color:#111!important;
  box-shadow:0 8px 18px rgba(15,23,42,.06)!important; display:inline-flex!important;
  align-items:center!important; gap:.5rem!important;
}
div.stDownloadButton > button:hover{
  transform:translateY(-1px); box-shadow:0 10px 22px rgba(15,23,42,.08)!important;
}
</style>
""", unsafe_allow_html=True)

# ====== 0) ×›×•×ª×¨×ª (Hero) ======
st.markdown("<h1>××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;color:#475569;margin-top:-8px;'>×›××Ÿ ××©×‘×¦×™× ×¡×˜×•×“× ×˜×™× ×œ××§×•××•×ª ×”×ª××—×•×ª ×‘×§×œ×•×ª, ×‘×”×ª×‘×¡×¡ ×¢×œ ×ª×—×•×, ×¢×™×¨ ×•×‘×§×©×•×ª.</p>", unsafe_allow_html=True)

# ====== ××•×“×œ × ×™×§×•×“ ======
@dataclass
class Weights:
    w_field: float = 0.70
    w_city: float = 0.20
    w_special: float = 0.10

W = Weights()

# ××™×¤×•×™ ×©××•×ª ×¢××•×“×•×ª ××¤×©×¨×™×™×
STU_COLS = {
    "id": ["××¡×¤×¨ ×ª×¢×•×“×ª ×–×”×•×ª", "×ª×¢×•×“×ª ×–×”×•×ª", "×ª\"×–", "×ª×–", "×ª×¢×•×“×ª ×–×”×•×ª ×”×¡×˜×•×“× ×˜"],
    "first": ["×©× ×¤×¨×˜×™"],
    "last": ["×©× ××©×¤×—×”"],
    "address": ["×›×ª×•×‘×ª", "×›×ª×•×‘×ª ×”×¡×˜×•×“× ×˜", "×¨×—×•×‘"],
    "city": ["×¢×™×¨ ××’×•×¨×™×", "×¢×™×¨"],
    "phone": ["×˜×œ×¤×•×Ÿ", "××¡×¤×¨ ×˜×œ×¤×•×Ÿ"],
    "email": ["×“×•×\"×œ", "×“×•××´×œ", "××™××™×™×œ", "×›×ª×•×‘×ª ××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ"],
    "preferred_field": ["×ª×—×•× ××•×¢×“×£","×ª×—×•××™× ××•×¢×“×¤×™×"],
    "special_req": ["×‘×§×©×” ××™×•×—×“×ª"],
    "partner": ["×‘×Ÿ/×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ\\×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ/×‘×ª ×–×•×’", "×‘×Ÿ\\×‘×ª ×–×•×’"]
}
SITE_COLS = {
    "name": ["××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”", "××•×¡×“", "×©× ××•×¡×“ ×”×”×ª××—×•×ª"],
    "field": ["×ª×—×•× ×”×”×ª××—×•×ª", "×ª×—×•× ×”×ª××—×•×ª"],
    "street": ["×¨×—×•×‘"],
    "city": ["×¢×™×¨"],
    "capacity": ["××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜", "×§×™×‘×•×œ×ª"],
    "sup_first": ["×©× ×¤×¨×˜×™"],
    "sup_last": ["×©× ××©×¤×—×”"],
    "phone": ["×˜×œ×¤×•×Ÿ"],
    "email": ["××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ", "×“×•×\"×œ", "×“×•××´×œ"]
}

# ====== Utilities ======
def pick_col(df: pd.DataFrame, options: List[str]) -> Optional[str]:
    for opt in options:
        if opt in df.columns:
            return opt
    return None

def read_any(uploaded) -> pd.DataFrame:
    name = uploaded.name.lower()
    if name.endswith(".csv"):
        return pd.read_csv(uploaded, encoding="utf-8-sig")
    if name.endswith(".xlsx") or name.endswith(".xls"):
        return pd.read_excel(uploaded)
    # × ×™×¡×™×•×Ÿ ××—×¨×•×Ÿ
    try:
        return pd.read_excel(uploaded)
    except Exception:
        return pd.read_csv(uploaded, encoding="utf-8-sig")

def normalize_text(x: Any) -> str:
    if x is None: return ""
    return str(x).strip()

def detect_site_type(name: str, field: str) -> str:
    text = f"{name or ''} {field or ''}".replace("Ö¾"," ").replace("-"," ").lower()
    pairs = [("×›×œ×","×›×œ×"),("×‘×™×ª ×¡×•×”×¨","×›×œ×"),
             ("×‘×™×ª ×—×•×œ×™×","×‘×™×ª ×—×•×œ×™×"),("××¨×›×– ×¨×¤×•××™","×‘×™×ª ×—×•×œ×™×"),
             ("××¨×¤××”","×‘×¨×™××•×ª"),
             ("×‘×™\"×¡","×‘×™×ª ×¡×¤×¨"),("×‘×™×ª ×¡×¤×¨","×‘×™×ª ×¡×¤×¨"),("×ª×™×›×•×Ÿ","×‘×™×ª ×¡×¤×¨"),
             ("×’×Ÿ","×’×Ÿ ×™×œ×“×™×"),
             ("××¨×›×– ×§×”×™×œ×ª×™","×§×”×™×œ×”"),("×¨×•×•×—×”","×¨×•×•×—×”"),
             ("×—×•×¡×Ÿ","×‘×¨×™××•×ª ×”× ×¤×©"),("×‘×¨×™××•×ª ×”× ×¤×©","×‘×¨×™××•×ª ×”× ×¤×©")]
    for k,v in pairs:
        if k in text: return v
    if "×—×™× ×•×š" in (field or ""): return "×—×™× ×•×š"
    return "××—×¨"

def tokens(s: str) -> List[str]:
    return [t for t in str(s).replace(","," ").replace("/"," ").replace("-"," ").split() if t]

def field_match_score(stu_pref: str, site_field: str) -> float:
    if not stu_pref:
        return 50.0
    sp = stu_pref.strip(); sf = site_field.strip()
    if not sf: return 40.0
    if sp and sp in sf: return 90.0
    tp = set([w for w in tokens(sp) if len(w) > 1])
    tf = set([w for w in tokens(sf) if len(w) > 1])
    if tp.intersection(tf): return 75.0
    return 45.0

def special_req_score(req: str, site_type: str, same_city: bool) -> float:
    if not req: return 70.0
    if "×œ× ×‘×‘×™×ª ×—×•×œ×™×" in req and site_type == "×‘×™×ª ×—×•×œ×™×": return 0.0
    if "×§×¨×•×‘" in req: return 90.0 if same_city else 55.0
    return 75.0

def compute_score(stu: pd.Series, site: pd.Series, W: Weights) -> float:
    same_city = (stu.get("stu_city") and site.get("site_city") and stu.get("stu_city") == site.get("site_city"))
    field_s  = field_match_score(stu.get("stu_pref",""), site.get("site_field",""))
    city_s   = 100.0 if same_city else 65.0
    special_s= special_req_score(stu.get("stu_req",""), site.get("site_type",""), same_city)
    score = W.w_field*field_s + W.w_city*city_s + W.w_special*special_s
    return float(np.clip(score, 0, 100))

def find_partner_map(students_df: pd.DataFrame) -> Dict[str,str]:
    ids = set(students_df["stu_id"]); m: Dict[str,str] = {}
    for _, r in students_df.iterrows():
        sid = r["stu_id"]; pid = r.get("stu_partner","")
        if not pid: continue
        if pid in ids and pid != sid:
            m[sid] = pid; continue
        for _, r2 in students_df.iterrows():
            full = f"{r2.get('stu_first','')} {r2.get('stu_last','')}".strip()
            if pid and full and pid in full and r2["stu_id"] != sid:
                m[sid] = r2["stu_id"]; break
    return m

def candidate_table_for_student(stu: pd.Series, sites_df: pd.DataFrame, W: Weights) -> pd.DataFrame:
    tmp = sites_df.copy()
    tmp["score"] = tmp.apply(lambda r: compute_score(stu, r, W), axis=1)
    return tmp.sort_values(["score"], ascending=[False])

# ====== Resolvers (×¢× ×‘×“×™×§×•×ª ×—×•×‘×” ×ª×§×™× ×•×ª) ======
def resolve_students(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or not isinstance(df, pd.DataFrame) or df.empty:
        raise ValueError("×§×•×‘×¥ ×”×¡×˜×•×“× ×˜×™× ×¨×™×§ ××• ×œ× × ×˜×¢×Ÿ ×›×¨××•×™.")

    out = df.copy()

    # ×¢××•×“×•×ª ×—×•×‘×”
    id_col    = pick_col(out, STU_COLS["id"])
    first_col = pick_col(out, STU_COLS["first"])
    last_col  = pick_col(out, STU_COLS["last"])

    missing = []
    if id_col is None:    missing.append("×ª×¢×•×“×ª ×–×”×•×ª (××—×ª ××”××¤×©×¨×•×™×•×ª ×”××•×›×¨×•×ª)")
    if first_col is None: missing.append("×©× ×¤×¨×˜×™")
    if last_col is None:  missing.append("×©× ××©×¤×—×”")
    if missing:
        raise ValueError("×—×¡×¨×•×ª ×¢××•×“×•×ª ×—×•×‘×” ×‘×§×•×‘×¥ ×”×¡×˜×•×“× ×˜×™×: " + ", ".join(missing))

    out["stu_id"]    = out[id_col]
    out["stu_first"] = out[first_col]
    out["stu_last"]  = out[last_col]

    # ××•×¤×¦×™×•× ×œ×™
    def opt(opts, default=""):
        col = pick_col(out, opts)
        return out[col] if col else default

    out["stu_phone"]   = opt(STU_COLS["phone"])
    out["stu_email"]   = opt(STU_COLS["email"])
    out["stu_city"]    = opt(STU_COLS["city"])
    out["stu_address"] = opt(STU_COLS["address"])
    out["stu_pref"]    = opt(STU_COLS["preferred_field"])
    out["stu_req"]     = opt(STU_COLS["special_req"])
    out["stu_partner"] = opt(STU_COLS["partner"])

    for c in ["stu_id","stu_first","stu_last","stu_phone","stu_email",
              "stu_city","stu_address","stu_pref","stu_req","stu_partner"]:
        out[c] = out[c].apply(normalize_text)

    return out

def resolve_sites(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or not isinstance(df, pd.DataFrame) or df.empty:
        raise ValueError("×§×•×‘×¥ ×”××ª×¨×™×/××“×¨×™×›×™× ×¨×™×§ ××• ×œ× × ×˜×¢×Ÿ ×›×¨××•×™.")

    out = df.copy()

    # ×¢××•×“×•×ª ×—×•×‘×”
    name_col  = pick_col(out, SITE_COLS["name"])
    field_col = pick_col(out, SITE_COLS["field"])

    missing = []
    if name_col is None:  missing.append("××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×” (×©× ×”××•×¡×“)")
    if field_col is None: missing.append("×ª×—×•× ×”×”×ª××—×•×ª")
    if missing:
        raise ValueError("×—×¡×¨×•×ª ×¢××•×“×•×ª ×—×•×‘×” ×‘×§×•×‘×¥ ×”××ª×¨×™×: " + ", ".join(missing))

    out["site_name"]  = out[name_col]
    out["site_field"] = out[field_col]

    # ××•×¤×¦×™×•× ×œ×™
    def opt(opts, default=""):
        col = pick_col(out, opts)
        return out[col] if col else default

    out["site_street"] = opt(SITE_COLS["street"])
    out["site_city"]   = opt(SITE_COLS["city"])

    cap_col = pick_col(out, SITE_COLS["capacity"])
    if cap_col:
        out["site_capacity"] = pd.to_numeric(out[cap_col], errors="coerce").fillna(1).astype(int)
    else:
        out["site_capacity"] = 1
    out["capacity_left"] = out["site_capacity"].astype(int)

    out["site_type"] = out.apply(lambda r: detect_site_type(r.get("site_name"), r.get("site_field")), axis=1)

    sup_first = pick_col(out, SITE_COLS["sup_first"])
    sup_last  = pick_col(out, SITE_COLS["sup_last"])
    out["supervisor"] = ""
    if sup_first or sup_last:
        ff = out[sup_first] if sup_first else ""
        ll = out[sup_last]  if sup_last  else ""
        out["supervisor"] = (ff.astype(str) + " " + ll.astype(str)).str.strip()

    for c in ["site_name","site_field","site_street","site_city","site_type","supervisor"]:
        out[c] = out[c].apply(normalize_text)

    return out

# ====== ××œ×’×•×¨×™×ª× ×©×™×‘×•×¥ ======
def greedy_match(students_df: pd.DataFrame, sites_df: pd.DataFrame, W: Weights) -> pd.DataFrame:
    """
    ××—×–×™×¨ DataFrame ×©×œ ×›×œ ×”×¡×˜×•×“× ×˜×™×. ×× ××™×Ÿ ××§×•×/×”×ª×××” â€“ ×”×¡×˜×•×“× ×˜ ×™×•×¤×™×¢ ×›'×œ× ×©×•×‘×¥'.
    ×œ× ××•×—×§/××¡× ×Ÿ ×©×•× ×¨×©×•××” ××”×§×‘×¦×™× ×”××§×•×¨×™×™×.
    """
    separate_couples = True
    top_k = 10

    def dec_cap(idx: int):
        sites_df.at[idx, "capacity_left"] = int(sites_df.at[idx, "capacity_left"]) - 1

    results: List[Tuple[pd.Series, Optional[pd.Series]]] = []
    processed = set()
    partner_map = find_partner_map(students_df)

    # ×‘× ×™/×‘× ×•×ª ×–×•×’ ×ª×—×™×œ×” (×× ××¤×©×¨ ×œ×©×‘×¥ ××ª ×©× ×™×”×)
    for _, s in students_df.iterrows():
        sid = s["stu_id"]
        if sid in processed: 
            continue
        pid = partner_map.get(sid)
        if pid and partner_map.get(pid) == sid:
            partner_row = students_df[students_df["stu_id"] == pid]
            if partner_row.empty:
                continue
            s2 = partner_row.iloc[0]
            cand1 = candidate_table_for_student(s, sites_df[sites_df["capacity_left"]>0], W).head(top_k)
            cand2 = candidate_table_for_student(s2, sites_df[sites_df["capacity_left"]>0], W).head(top_k)
            best = (-1.0, None, None)
            for i1, r1 in cand1.iterrows():
                for i2, r2 in cand2.iterrows():
                    if i1 == i2:  # ×œ× ××•×ª×• ××§×•× ×œ×©× ×™×”×
                        continue
                    if separate_couples and r1.get("supervisor") and r1.get("supervisor") == r2.get("supervisor"):
                        continue
                    sc = float(r1["score"]) + float(r2["score"])
                    if sc > best[0]:
                        best = (sc, i1, i2)
            if best[1] is not None and best[2] is not None:
                rsite1 = sites_df.loc[best[1]]
                rsite2 = sites_df.loc[best[2]]
                dec_cap(best[1]); dec_cap(best[2])
                results.append((s, rsite1))
                results.append((s2, rsite2))
                processed.add(sid); processed.add(pid)
            # ×× ×œ× ××¦×× ×• ×©× ×™ ××§×•××•×ª â€“ × ×¢×‘×•×¨ ×œ×©×œ×‘ ×”"×‘×•×“×“×™×" ×©×™×˜×¤×œ ×‘×›×œ ××—×“ ×‘× ×¤×¨×“

    # ×‘×•×“×“×™× ×•×›×œ ××™ ×©×œ× ×©×•×‘×¥ ×¢×“ ×¢×›×©×™×•
    for _, s in students_df.iterrows():
        sid = s["stu_id"]
        if sid in processed:
            continue
        cand = candidate_table_for_student(s, sites_df[sites_df["capacity_left"]>0], W).head(top_k)
        if not cand.empty:
            chosen_idx = cand.index[0]
            rsite = sites_df.loc[chosen_idx]
            dec_cap(chosen_idx)
            results.append((s, rsite))
            processed.add(sid)
        else:
            # ××™×Ÿ ××§×•× ×–××™×Ÿ/×”×ª×××” â€“ ×”×•×¡×£ ×›×¨×©×•××” "×œ× ×©×•×‘×¥"
            results.append((s, None))
            processed.add(sid)

    # ×‘× ×™×™×ª ×˜×‘×œ×ª ×¤×œ×˜ â€“ ×›×œ ×”×¡×˜×•×“× ×˜×™× ×™×•×¤×™×¢×•
    rows = []
    for s, r in results:
        if r is None:
            rows.append({
                "×ª\"×– ×”×¡×˜×•×“× ×˜": s.get("stu_id"),
                "×©× ×¤×¨×˜×™": s.get("stu_first"),
                "×©× ××©×¤×—×”": s.get("stu_last"),
                "×›×ª×•×‘×ª": s.get("stu_address"),
                "×¢×™×¨": s.get("stu_city"),
                "××¡×¤×¨ ×˜×œ×¤×•×Ÿ": s.get("stu_phone"),
                "××™××™×™×œ": s.get("stu_email"),
                "××—×•×– ×”×ª×××”": 0.0,
                "×©× ××§×•× ×”×”×ª××—×•×ª": "×œ× ×©×•×‘×¥",
                "×¢×™×¨ ×”××•×¡×“": "",
                "×¡×•×’ ××§×•× ×”×©×™×‘×•×¥": "",
                "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": "",
            })
        else:
            score = compute_score(s, r, W)
            rows.append({
                "×ª\"×– ×”×¡×˜×•×“× ×˜": s.get("stu_id"),
                "×©× ×¤×¨×˜×™": s.get("stu_first"),
                "×©× ××©×¤×—×”": s.get("stu_last"),
                "×›×ª×•×‘×ª": s.get("stu_address"),
                "×¢×™×¨": s.get("stu_city"),
                "××¡×¤×¨ ×˜×œ×¤×•×Ÿ": s.get("stu_phone"),
                "××™××™×™×œ": s.get("stu_email"),
                "××—×•×– ×”×ª×××”": round(score, 1),
                "×©× ××§×•× ×”×”×ª××—×•×ª": r.get("site_name"),
                "×¢×™×¨ ×”××•×¡×“": r.get("site_city"),
                "×¡×•×’ ××§×•× ×”×©×™×‘×•×¥": r.get("site_type"),
                "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": r.get("site_field"),
            })
    out = pd.DataFrame(rows)
    desired = ["×ª\"×– ×”×¡×˜×•×“× ×˜","×©× ×¤×¨×˜×™","×©× ××©×¤×—×”","×›×ª×•×‘×ª","×¢×™×¨","××¡×¤×¨ ×˜×œ×¤×•×Ÿ","××™××™×™×œ",
               "××—×•×– ×”×ª×××”","×©× ××§×•× ×”×”×ª××—×•×ª","×¢×™×¨ ×”××•×¡×“","×¡×•×’ ××§×•× ×”×©×™×‘×•×¥","×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“"]
    remaining = [c for c in out.columns if c not in desired]
    return out[[c for c in desired if c in out.columns] + remaining]

# ====== 1) ×”×•×¨××•×ª ×©×™××•×© ======
st.markdown("## ğŸ“˜ ×”×•×¨××•×ª ×©×™××•×©")
st.markdown("""
1. **×§×•×‘×¥ ×¡×˜×•×“× ×˜×™× (CSV/XLSX):** ×©× ×¤×¨×˜×™, ×©× ××©×¤×—×”, ×ª×¢×•×“×ª ×–×”×•×ª, ×›×ª×•×‘×ª/×¢×™×¨, ×˜×œ×¤×•×Ÿ, ××™××™×™×œ.  
   ××•×¤×¦×™×•× ×œ×™: ×ª×—×•× ××•×¢×“×£, ×‘×§×©×” ××™×•×—×“×ª, ×‘×Ÿ/×‘×ª ×–×•×’ ×œ×”×›×©×¨×”.
2. **×§×•×‘×¥ ××ª×¨×™×/××“×¨×™×›×™× (CSV/XLSX):** ××•×¡×“/×©×™×¨×•×ª, ×ª×—×•× ×”×ª××—×•×ª, ×¨×—×•×‘, ×¢×™×¨, ××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”.  
   ××•×¤×¦×™×•× ×œ×™: ×©× ×¤×¨×˜×™+×©× ××©×¤×—×” ×©×œ ×”××“×¨×™×š, ×˜×œ×¤×•×Ÿ, ××™××™×™×œ.
3. ×œ×—×™×¦×” ×¢×œ **×‘×¦×¢ ×©×™×‘×•×¥** ×ª×—×©×‘ *××—×•×– ×”×ª×××”* ×œ×¤×™ ×ª×—×•× (70%), ×¢×™×¨ (20%), ×‘×§×©×•×ª (10%), ×›×•×œ×œ ×”×¤×¨×“×ª ×‘× ×™/×‘× ×•×ª ×–×•×’ ×•××›×™×¤×ª ×§×™×‘×•×œ×ª.
4. ×‘×¡×•×£ × ×™×ª×Ÿ ×œ×”×•×¨×™×“ ××ª ×§×•×‘×¥ ×”×ª×•×¦××•×ª (CSV/XLSX).
""")

# ====== 2) ×“×•×’××” ×œ×©×™××•×© ======
st.markdown("## ğŸ§ª ×“×•×’××” ×œ×©×™××•×©")
example_students = pd.DataFrame([
    {"×©× ×¤×¨×˜×™":"×¨×•×ª", "×©× ××©×¤×—×”":"×›×”×Ÿ", "×ª×¢×•×“×ª ×–×”×•×ª":"123456789", "×›×ª×•×‘×ª":"×”×¨×¦×œ 12", "×¢×™×¨ ××’×•×¨×™×":"×ª×œ ××‘×™×‘", "×˜×œ×¤×•×Ÿ":"0501111111", "×“×•×\"×œ":"ruth@example.com", "×ª×—×•× ××•×¢×“×£":"×‘×¨×™××•×ª ×”× ×¤×©"},
    {"×©× ×¤×¨×˜×™":"×™×•××‘", "×©× ××©×¤×—×”":"×œ×•×™", "×ª×¢×•×“×ª ×–×”×•×ª":"987654321", "×›×ª×•×‘×ª":"×“×™×–× ×’×•×£ 80", "×¢×™×¨ ××’×•×¨×™×":"×ª×œ ××‘×™×‘", "×˜×œ×¤×•×Ÿ":"0502222222", "×“×•×\"×œ":"yoav@example.com", "×ª×—×•× ××•×¢×“×£":"×¨×•×•×—×”"}
])
example_sites = pd.DataFrame([
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××¨×›×– ×—×•×¡×Ÿ ×ª×œ ××‘×™×‘", "×ª×—×•× ×”×”×ª××—×•×ª":"×‘×¨×™××•×ª ×”× ×¤×©", "×¨×—×•×‘":"××‘×Ÿ ×’×‘×™×¨×•×œ 1", "×¢×™×¨":"×ª×œ ××‘×™×‘", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":2},
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××—×œ×§×ª ×¨×•×•×—×” ×¨××ª ×’×Ÿ", "×ª×—×•× ×”×”×ª××—×•×ª":"×¨×•×•×—×”", "×¨×—×•×‘":"×‘×™××œ×™×§ 10", "×¢×™×¨":"×¨××ª ×’×Ÿ", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":1},
])
colX, colY = st.columns(2, gap="large")
with colX:
    st.write("**×“×•×’××” â€“ ×¡×˜×•×“× ×˜×™×**")
    st.dataframe(example_students, use_container_width=True)
    st.download_button("â¬‡ï¸ ×”×•×¨×“×ª ×“×•×’××ª ×¡×˜×•×“× ×˜×™× (CSV)",
                       data=example_students.to_csv(index=False, encoding="utf-8-sig"),
                       file_name="students_example.csv", mime="text/csv")
with colY:
    st.write("**×“×•×’××” â€“ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×**")
    st.dataframe(example_sites, use_container_width=True)
    st.download_button("â¬‡ï¸ ×”×•×¨×“×ª ×“×•×’××ª ××ª×¨×™× (CSV)",
                       data=example_sites.to_csv(index=False, encoding="utf-8-sig"),
                       file_name="sites_example.csv", mime="text/csv")

# ====== 3) ×”×¢×œ××ª ×§×‘×¦×™× ======
st.markdown("## ğŸ“¤ ×”×¢×œ××ª ×§×‘×¦×™×")
colA, colB = st.columns(2, gap="large")

df_students_raw = None
df_sites_raw = None

with colA:
    students_file = st.file_uploader("×§×•×‘×¥ ×¡×˜×•×“× ×˜×™×", type=["csv","xlsx","xls"], key="students_file")
    if students_file is not None:
        st.caption("×”×¦×¦×” ×œ-5 ×”×¨×©×•××•×ª ×”×¨××©×•× ×•×ª (×œ× ××•×—×§×™× ×©×•× ×¢××•×“×”):")
        try:
            df_students_raw = read_any(students_file)
            st.dataframe(df_students_raw.head(5), use_container_width=True)
        except Exception:
            st.error("×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×”×§×•×‘×¥.")

with colB:
    sites_file = st.file_uploader("×§×•×‘×¥ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×", type=["csv","xlsx","xls"], key="sites_file")
    if sites_file is not None:
        st.caption("×”×¦×¦×” ×œ-5 ×”×¨×©×•××•×ª ×”×¨××©×•× ×•×ª (×œ× ××•×—×§×™× ×©×•× ×¢××•×“×”):")
        try:
            df_sites_raw = read_any(sites_file)
            st.dataframe(df_sites_raw.head(5), use_container_width=True)
        except Exception:
            st.error("×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×”×§×•×‘×¥.")

# ====== 4) ×©×™×‘×•×¥ ======
st.markdown("## âš™ï¸ ×‘×™×¦×•×¢ ×”×©×™×‘×•×¥")
run_btn = st.button("ğŸš€ ×‘×¦×¢ ×©×™×‘×•×¥", use_container_width=True)

result_df = None
unmatched_students = None
unused_sites = None

if run_btn:
    if students_file is None or sites_file is None:
        st.error("× × ×œ×”×¢×œ×•×ª ××ª ×©× ×™ ×”×§×‘×¦×™× ×œ×¤× ×™ ×”×¤×¢×œ×ª ×”×©×™×‘×•×¥.")
    elif df_students_raw is None:
        st.error("×§×•×‘×¥ ×”×¡×˜×•×“× ×˜×™× ×œ× × ×§×¨×. ×‘×“×§×™ ××ª ×”×¤×•×¨××˜/×›×•×ª×¨×•×ª ×•× ×¡×™ ×©×•×‘.")
    elif df_sites_raw is None:
        st.error("×§×•×‘×¥ ×”××ª×¨×™× ×œ× × ×§×¨×. ×‘×“×§×™ ××ª ×”×¤×•×¨××˜/×›×•×ª×¨×•×ª ×•× ×¡×™ ×©×•×‘.")
    else:
        try:
            students = resolve_students(df_students_raw)
            sites    = resolve_sites(df_sites_raw)
            result_df = greedy_match(students, sites, W)

            # --- ×¡×˜×•×“× ×˜×™× ×©×œ× ×©×•×‘×¦×• ---
            unmatched_students = result_df[result_df["×©× ××§×•× ×”×”×ª××—×•×ª"] == "×œ× ×©×•×‘×¥"]

            # --- ××•×¡×“×•×ª ×©×œ× ×©×•×‘×¥ ××œ×™×”× ××£ ××—×“ ---
            used_sites = set(result_df["×©× ××§×•× ×”×”×ª××—×•×ª"].unique())
            unused_sites = sites[~sites["site_name"].isin(used_sites)]

            st.success("×”×©×™×‘×•×¥ ×”×•×©×œ× âœ“")
        except ValueError as ve:
            st.error(str(ve))
        except Exception as e:
            st.exception(e)

# ====== 5) ×ª×•×¦××•×ª ======
st.markdown("## ğŸ“Š ×ª×•×¦××•×ª ×”×©×™×‘×•×¥")
if result_df is not None and not result_df.empty:
    st.dataframe(result_df, use_container_width=True)

    # ×›×¤×ª×•×¨ Excel ×‘×œ×‘×“
    xlsx_io = BytesIO()
    with pd.ExcelWriter(xlsx_io, engine="xlsxwriter") as writer:
        result_df.to_excel(writer, index=False, sheet_name="×©×™×‘×•×¥")
    xlsx_io.seek(0)
    st.download_button(
        label="×”×•×¨×“×ª Excel (XLSX)",
        data=xlsx_io.getvalue(),
        file_name="student_site_matching.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        key="dl_xlsx"
    )

    # --- ×˜×‘×œ×”: ×¡×˜×•×“× ×˜×™× ×©×œ× ×©×•×‘×¦×• ---
    if unmatched_students is not None and not unmatched_students.empty:
        st.markdown("### ğŸ‘©â€ğŸ“ ×¡×˜×•×“× ×˜×™× ×©×œ× ×©×•×‘×¦×•")
        st.dataframe(unmatched_students, use_container_width=True)

    # --- ×˜×‘×œ×”: ××•×¡×“×•×ª ×œ×œ× ×¡×˜×•×“× ×˜×™× ---
    if unused_sites is not None and not unused_sites.empty:
        st.markdown("### ğŸ« ××•×¡×“×•×ª ×©×œ× ×©×•×‘×¥ ××œ×™×”× ××£ ×¡×˜×•×“× ×˜")
        st.dataframe(unused_sites[["site_name","site_city","site_field","site_capacity"]], use_container_width=True)
else:
    st.caption("×˜×¨× ×”×•×¤×¢×œ ×©×™×‘×•×¥ ××• ×©××™×Ÿ ×ª×•×¦××•×ª ×œ×”×¦×’×”.")
