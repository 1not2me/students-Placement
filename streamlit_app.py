
# matcher_streamlit_beauty_rtl_v2.py
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
from dataclasses import dataclass
from typing import Optional, Dict, Any, List

st.set_page_config(page_title="××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”", layout="wide")

# ====== ×¢×™×¦×•×‘ ××•×“×¨× ×™ + RTL + ×”×¡×ª×¨×ª "Press Enter to apply" ======
st.markdown("""
<style>
@font-face {
  font-family:'David';
  src:url('https://example.com/David.ttf') format('truetype');
}
html, body, [class*="css"] {
  font-family:'David',sans-serif!important;
}

/* ====== ×¢×™×¦×•×‘ ××•×“×¨× ×™ + RTL ====== */
:root{
  --bg-1:#e0f7fa;
  --bg-2:#ede7f6;
  --bg-3:#fff3e0;
  --bg-4:#fce4ec;
  --bg-5:#e8f5e9;
  --ink:#0f172a;
  --primary:#9b5de5;
  --primary-700:#f15bb5;
  --ring:rgba(155,93,229,.35);
}

[data-testid="stAppViewContainer"]{
  background:
    radial-gradient(1200px 600px at 15% 10%, var(--bg-2) 0%, transparent 70%),
    radial-gradient(1000px 700px at 85% 20%, var(--bg-3) 0%, transparent 70%),
    radial-gradient(900px 500px at 50% 80%, var(--bg-4) 0%, transparent 70%),
    radial-gradient(700px 400px at 10% 85%, var(--bg-5) 0%, transparent 70%),
    linear-gradient(135deg, var(--bg-1) 0%, #ffffff 100%) !important;
  color: var(--ink);
}

.main .block-container{
  background: rgba(255,255,255,.78);
  backdrop-filter: blur(10px);
  border:1px solid rgba(15,23,42,.08);
  box-shadow:0 15px 35px rgba(15,23,42,.08);
  border-radius:24px;
  padding:2.5rem;
  margin-top:1rem;
}

/* ×›×•×ª×¨×•×ª */
h1,h2,h3,.stMarkdown h1,.stMarkdown h2{
  text-align:center;
  letter-spacing:.5px;
  text-shadow:0 1px 2px rgba(255,255,255,.7);
  font-weight:700;
  color:#222;
  margin-bottom:1rem;
}

/* ×›×¤×ª×•×¨ */
.stButton > button{
  background:linear-gradient(135deg,var(--primary) 0%,var(--primary-700) 100%)!important;
  color:#fff!important;
  border:none!important;
  border-radius:18px!important;
  padding:1rem 2rem!important;
  font-size:1.1rem!important;
  font-weight:600!important;
  box-shadow:0 8px 18px var(--ring)!important;
  transition:all .15s ease!important;
}
.stButton > button:hover{
  transform:translateY(-3px) scale(1.02);
  filter:brightness(1.08);
}
.stButton > button:focus{
  outline:none!important;
  box-shadow:0 0 0 4px var(--ring)!important;
}

/* ×§×œ×˜×™× */
div.stSelectbox > div,
div.stMultiSelect > div,
.stTextInput > div > div > input{
  border-radius:14px!important;
  border:1px solid rgba(15,23,42,.12)!important;
  box-shadow:0 3px 10px rgba(15,23,42,.04)!important;
  padding:.6rem .8rem!important;
  color:var(--ink)!important;
  font-size:1rem!important;
}

/* ×˜××‘×™× â€“ ×¨×•×—×‘ ×§×˜×Ÿ ×™×•×ª×¨ */
.stTabs [data-baseweb="tab"]{
  border-radius:14px!important;
  background:rgba(255,255,255,.65);
  margin-inline-start:.3rem;
  padding:.4rem .8rem;
  font-weight:600;
  min-width: 110px !important;
  text-align:center;
  font-size:0.9rem !important;
}
.stTabs [data-baseweb="tab"]:hover{
  background:rgba(255,255,255,.9);
}

/* RTL */
.stApp,.main,[data-testid="stSidebar"]{
  direction:rtl;
  text-align:right;
}
label,.stMarkdown,.stText,.stCaption{
  text-align:right!important;
}

/* ×”×¡×ª×¨×ª ×˜×™×¤ "Press Enter to apply" */
*[title="Press Enter to apply"]{ display:none !important; }
</style>
""", unsafe_allow_html=True)

# ====== 0) ×›×•×ª×¨×ª (Hero) ======
st.markdown("<h1>××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;color:#475569;margin-top:-8px;'>×›××Ÿ ××©×‘×¦×™× ×¡×˜×•×“× ×˜×™× ×œ××§×•××•×ª ×”×ª××—×•×ª ×‘×§×œ×•×ª, ×‘×”×ª×‘×¡×¡ ×¢×œ ×ª×—×•×, ×¢×™×¨ ×•×‘×§×©×•×ª.</p>", unsafe_allow_html=True)

# ====== ××•×“×œ × ×™×§×•×“ (×œ×œ× ××¨×—×§, ×œ×œ× ×¡×œ×™×™×“×¨×™×) ======
@dataclass
class Weights:
    w_field: float = 0.70
    w_city: float = 0.20
    w_special: float = 0.10

STU_COLS = {
    "id": ["××¡×¤×¨ ×ª×¢×•×“×ª ×–×”×•×ª", "×ª×¢×•×“×ª ×–×”×•×ª", "×ª\"×–", "×ª×–", "×ª×¢×•×“×ª ×–×”×•×ª ×”×¡×˜×•×“× ×˜"],
    "first": ["×©× ×¤×¨×˜×™"],
    "last": ["×©× ××©×¤×—×”"],
    "address": ["×›×ª×•×‘×ª", "×›×ª×•×‘×ª ×”×¡×˜×•×“× ×˜", "×¨×—×•×‘"],
    "city": ["×¢×™×¨ ××’×•×¨×™×", "×¢×™×¨"],
    "phone": ["×˜×œ×¤×•×Ÿ", "××¡×¤×¨ ×˜×œ×¤×•×Ÿ"],
    "email": ["×“×•×\"×œ", "×“×•××´×œ", "××™××™×™×œ", "×›×ª×•×‘×ª ××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ"],
    "preferred_field": ["×ª×—×•× ××•×¢×“×£","×ª×—×•××™× ××•×¢×“×¤×™×"],
    "special_req": ["×‘×§×©×” ××™×•×—×“×ª"],
    "partner": ["×‘×Ÿ/×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ\\×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ/×‘×ª ×–×•×’", "×‘×Ÿ\\×‘×ª ×–×•×’"]
}
SITE_COLS = {
    "name": ["××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”", "××•×¡×“", "×©× ××•×¡×“ ×”×”×ª××—×•×ª"],
    "field": ["×ª×—×•× ×”×”×ª××—×•×ª", "×ª×—×•× ×”×ª××—×•×ª"],
    "street": ["×¨×—×•×‘"],
    "city": ["×¢×™×¨"],
    "capacity": ["××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜", "×§×™×‘×•×œ×ª"],
    "sup_first": ["×©× ×¤×¨×˜×™"],
    "sup_last": ["×©× ××©×¤×—×”"],
    "phone": ["×˜×œ×¤×•×Ÿ"],
    "email": ["××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ", "×“×•×\"×œ", "×“×•××´×œ"]
}

def pick_col(df: pd.DataFrame, options: List[str]) -> Optional[str]:
    for opt in options:
        if opt in df.columns: return opt
    return None

def read_any(uploaded) -> pd.DataFrame:
    name = uploaded.name.lower()
    if name.endswith(".csv"):
        return pd.read_csv(uploaded, encoding="utf-8-sig")
    if name.endswith(".xlsx") or name.endswith(".xls"):
        return pd.read_excel(uploaded)
    try:
        return pd.read_excel(uploaded)
    except Exception:
        return pd.read_csv(uploaded, encoding="utf-8-sig")

def normalize_text(x: Any) -> str:
    if x is None: return ""
    return str(x).strip()

def detect_site_type(name: str, field: str) -> str:
    text = f"{name or ''} {field or ''}".replace("Ö¾"," ").replace("-"," ").lower()
    pairs = [("×›×œ×","×›×œ×"),("×‘×™×ª ×¡×•×”×¨","×›×œ×"),
             ("×‘×™×ª ×—×•×œ×™×","×‘×™×ª ×—×•×œ×™×"),("××¨×›×– ×¨×¤×•××™","×‘×™×ª ×—×•×œ×™×"),
             ("××¨×¤××”","×‘×¨×™××•×ª"),
             ("×‘×™\"×¡","×‘×™×ª ×¡×¤×¨"),("×‘×™×ª ×¡×¤×¨","×‘×™×ª ×¡×¤×¨"),("×ª×™×›×•×Ÿ","×‘×™×ª ×¡×¤×¨"),
             ("×’×Ÿ","×’×Ÿ ×™×œ×“×™×"),
             ("××¨×›×– ×§×”×™×œ×ª×™","×§×”×™×œ×”"),("×¨×•×•×—×”","×¨×•×•×—×”"),
             ("×—×•×¡×Ÿ","×‘×¨×™××•×ª ×”× ×¤×©"),("×‘×¨×™××•×ª ×”× ×¤×©","×‘×¨×™××•×ª ×”× ×¤×©")]
    for k,v in pairs:
        if k in text: return v
    if "×—×™× ×•×š" in (field or ""): return "×—×™× ×•×š"
    return "××—×¨"

def resolve_students(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["stu_id"]    = out[pick_col(out, STU_COLS["id"])]
    out["stu_first"] = out[pick_col(out, STU_COLS["first"])]
    out["stu_last"]  = out[pick_col(out, STU_COLS["last"])]
    out["stu_phone"] = out[pick_col(out, STU_COLS["phone"])]
    out["stu_email"] = out[pick_col(out, STU_COLS["email"])]
    out["stu_city"]  = out[pick_col(out, STU_COLS["city"])] if pick_col(out, STU_COLS["city"]) else ""
    out["stu_address"] = out[pick_col(out, STU_COLS["address"])] if pick_col(out, STU_COLS["address"]) else ""
    pref_col = pick_col(out, STU_COLS["preferred_field"])
    out["stu_pref"] = out[pref_col] if pref_col else ""
    out["stu_req"]  = out[pick_col(out, STU_COLS["special_req"])] if pick_col(out, STU_COLS["special_req"]) else ""
    out["stu_partner"] = out[pick_col(out, STU_COLS["partner"])] if pick_col(out, STU_COLS["partner"]) else ""
    for c in ["stu_id","stu_first","stu_last","stu_phone","stu_email","stu_city","stu_address","stu_pref","stu_req","stu_partner"]:
        out[c] = out[c].apply(normalize_text)
    return out

def resolve_sites(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["site_name"]  = out[pick_col(out, SITE_COLS["name"])]
    out["site_field"] = out[pick_col(out, SITE_COLS["field"])]
    out["site_street"]= out[pick_col(out, SITE_COLS["street"])] if pick_col(out, SITE_COLS["street"]) else ""
    out["site_city"]  = out[pick_col(out, SITE_COLS["city"])] if pick_col(out, SITE_COLS["city"]) else ""
    cap_col = pick_col(out, SITE_COLS["capacity"])
    out["site_capacity"] = pd.to_numeric(out[cap_col], errors="coerce").fillna(1).astype(int) if cap_col else 1
    out["capacity_left"] = out["site_capacity"].astype(int)
    out["site_type"] = out.apply(lambda r: detect_site_type(r.get("site_name"), r.get("site_field")), axis=1)
    sup_first = pick_col(out, SITE_COLS["sup_first"])
    sup_last  = pick_col(out, SITE_COLS["sup_last"])
    out["supervisor"] = ""
    if sup_first or sup_last:
        ff = out[sup_first] if sup_first else ""
        ll = out[sup_last]  if sup_last  else ""
        out["supervisor"] = (ff.astype(str) + " " + ll.astype(str)).str.strip()
    for c in ["site_name","site_field","site_street","site_city","site_type","supervisor"]:
        out[c] = out[c].apply(normalize_text)
    return out

def tokens(s: str) -> List[str]:
    return [t for t in str(s).replace(","," ").replace("/"," ").replace("-"," ").split() if t]

def field_match_score(stu_pref: str, site_field: str) -> float:
    if not stu_pref: 
        return 50.0
    sp = stu_pref.strip()
    sf = site_field.strip()
    if not sf:
        return 40.0
    if sp and sp in sf:
        return 90.0
    tp = set([w for w in tokens(sp) if len(w) > 1])
    tf = set([w for w in tokens(sf) if len(w) > 1])
    if tp.intersection(tf):
        return 75.0
    return 45.0

def special_req_score(req: str, site_type: str, same_city: bool) -> float:
    if not req:
        return 70.0
    if "×œ× ×‘×‘×™×ª ×—×•×œ×™×" in req and site_type == "×‘×™×ª ×—×•×œ×™×":
        return 0.0
    if "×§×¨×•×‘" in req:
        return 90.0 if same_city else 55.0
    return 75.0

def compute_score(stu: pd.Series, site: pd.Series, W: Weights) -> float:
    same_city = (stu.get("stu_city") and site.get("site_city") and stu.get("stu_city") == site.get("site_city"))
    field_s  = field_match_score(stu.get("stu_pref",""), site.get("site_field",""))
    city_s   = 100.0 if same_city else 65.0
    special_s= special_req_score(stu.get("stu_req",""), site.get("site_type",""), same_city)
    score = W.w_field*field_s + W.w_city*city_s + W.w_special*special_s
    return float(np.clip(score, 0, 100))

def find_partner_map(students_df: pd.DataFrame) -> Dict[str,str]:
    ids = set(students_df["stu_id"])
    m = {}
    for _, r in students_df.iterrows():
        sid = r["stu_id"]
        pid = r.get("stu_partner","")
        if not pid: 
            continue
        if pid in ids and pid != sid:
            m[sid] = pid
            continue
        for _, r2 in students_df.iterrows():
            full = f"{r2.get('stu_first','')} {r2.get('stu_last','')}".strip()
            if pid and full and pid in full and r2["stu_id"] != sid:
                m[sid] = r2["stu_id"]
                break
    return m

def candidate_table_for_student(stu: pd.Series, sites_df: pd.DataFrame, W: Weights) -> pd.DataFrame:
    tmp = sites_df.copy()
    tmp["score"] = tmp.apply(lambda r: compute_score(stu, r, W), axis=1)
    return tmp.sort_values(["score"], ascending=[False])

def greedy_match(students_df: pd.DataFrame, sites_df: pd.DataFrame, W: Weights) -> pd.DataFrame:
    separate_couples = True
    top_k = 10

    def dec_cap(idx: int):
        sites_df.at[idx, "capacity_left"] = int(sites_df.at[idx, "capacity_left"]) - 1

    results = []
    processed = set()
    partner_map = find_partner_map(students_df)

    # Couples first
    for _, s in students_df.iterrows():
        sid = s["stu_id"]
        if sid in processed: 
            continue
        pid = partner_map.get(sid)
        if pid and partner_map.get(pid) == sid:
            partner_row = students_df[students_df["stu_id"] == pid]
            if partner_row.empty:
                continue
            s2 = partner_row.iloc[0]
            cand1 = candidate_table_for_student(s, sites_df[sites_df["capacity_left"]>0], W).head(top_k)
            cand2 = candidate_table_for_student(s2, sites_df[sites_df["capacity_left"]>0], W).head(top_k)
            best = (-1.0, None, None)
            for i1, r1 in cand1.iterrows():
                for i2, r2 in cand2.iterrows():
                    if i1 == i2:
                        continue
                    if separate_couples and r1.get("supervisor") and r1.get("supervisor") == r2.get("supervisor"):
                        continue
                    sc = float(r1["score"]) + float(r2["score"])
                    if sc > best[0]:
                        best = (sc, i1, i2)
            if best[1] is not None and best[2] is not None:
                rsite1 = sites_df.loc[best[1]]
                rsite2 = sites_df.loc[best[2]]
                dec_cap(best[1]); dec_cap(best[2])
                results.append((s, rsite1))
                results.append((s2, rsite2))
                processed.add(sid); processed.add(pid)

    # Singles
    for _, s in students_df.iterrows():
        sid = s["stu_id"]
        if sid in processed: 
            continue
        cand = candidate_table_for_student(s, sites_df[sites_df["capacity_left"]>0], W).head(top_k)
        if not cand.empty:
            chosen_idx = cand.index[0]
            rsite = sites_df.loc[chosen_idx]
            dec_cap(chosen_idx)
            results.append((s, rsite))
            processed.add(sid)

    rows = []
    for s, r in results:
        score = compute_score(s, r, W)
        rows.append({
            "×ª\"×– ×”×¡×˜×•×“× ×˜": s.get("stu_id"),
            "×©× ×¤×¨×˜×™": s.get("stu_first"),
            "×©× ××©×¤×—×”": s.get("stu_last"),
            "×›×ª×•×‘×ª": s.get("stu_address"),
            "×¢×™×¨": s.get("stu_city"),
            "××¡×¤×¨ ×˜×œ×¤×•×Ÿ": s.get("stu_phone"),
            "××™××™×™×œ": s.get("stu_email"),
            "××—×•×– ×”×ª×××”": round(score, 1),
            "×©× ××§×•× ×”×”×ª××—×•×ª": r.get("site_name"),
            "×¢×™×¨ ×”××•×¡×“": r.get("site_city"),
            "×¡×•×’ ××§×•× ×”×©×™×‘×•×¥": r.get("site_type"),
            "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": r.get("site_field"),
        })
    out = pd.DataFrame(rows)
    desired = ["×ª\"×– ×”×¡×˜×•×“× ×˜","×©× ×¤×¨×˜×™","×©× ××©×¤×—×”","×›×ª×•×‘×ª","×¢×™×¨","××¡×¤×¨ ×˜×œ×¤×•×Ÿ","××™××™×™×œ",
               "××—×•×– ×”×ª×××”","×©× ××§×•× ×”×”×ª××—×•×ª","×¢×™×¨ ×”××•×¡×“","×¡×•×’ ××§×•× ×”×©×™×‘×•×¥","×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“"]
    return out[[c for c in desired if c in out.columns]]

W = Weights()

# ====== 1) ×”×•×¨××•×ª ×©×™××•×© ======
st.markdown("## ğŸ“˜ ×”×•×¨××•×ª ×©×™××•×©")
st.markdown("""
1. **×§×•×‘×¥ ×¡×˜×•×“× ×˜×™× (CSV/XLSX):** ×©× ×¤×¨×˜×™, ×©× ××©×¤×—×”, ×ª×¢×•×“×ª ×–×”×•×ª, ×›×ª×•×‘×ª/×¢×™×¨, ×˜×œ×¤×•×Ÿ, ××™××™×™×œ.  
   ××•×¤×¦×™×•× ×œ×™: ×ª×—×•× ××•×¢×“×£, ×‘×§×©×” ××™×•×—×“×ª, ×‘×Ÿ/×‘×ª ×–×•×’ ×œ×”×›×©×¨×”.
2. **×§×•×‘×¥ ××ª×¨×™×/××“×¨×™×›×™× (CSV/XLSX):** ××•×¡×“/×©×™×¨×•×ª, ×ª×—×•× ×”×ª××—×•×ª, ×¨×—×•×‘, ×¢×™×¨, ××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”.  
   ××•×¤×¦×™×•× ×œ×™: ×©× ×¤×¨×˜×™+×©× ××©×¤×—×” ×©×œ ×”××“×¨×™×š, ×˜×œ×¤×•×Ÿ, ××™××™×™×œ.
3. ×œ×—×™×¦×” ×¢×œ **×‘×¦×¢ ×©×™×‘×•×¥** ×ª×—×©×‘ *××—×•×– ×”×ª×××”* ×œ×¤×™ ×ª×—×•× (70%), ×¢×™×¨ (20%), ×‘×§×©×•×ª (10%), ×›×•×œ×œ ×”×¤×¨×“×ª ×‘× ×™/×‘× ×•×ª ×–×•×’ ×•××›×™×¤×ª ×§×™×‘×•×œ×ª.
4. ×‘×¡×•×£ × ×™×ª×Ÿ ×œ×”×•×¨×™×“ ××ª ×§×•×‘×¥ ×”×ª×•×¦××•×ª.
""")

# ====== 2) ×“×•×’××” ×œ×©×™××•×© (× ×¢×” ×œ×¤× ×™ ×”×”×¢×œ××”) ======
st.markdown("## ğŸ§ª ×“×•×’××” ×œ×©×™××•×©")
example_students = pd.DataFrame([
    {"×©× ×¤×¨×˜×™":"×¨×•×ª", "×©× ××©×¤×—×”":"×›×”×Ÿ", "×ª×¢×•×“×ª ×–×”×•×ª":"123456789", "×›×ª×•×‘×ª":"×”×¨×¦×œ 12", "×¢×™×¨ ××’×•×¨×™×":"×ª×œ ××‘×™×‘", "×˜×œ×¤×•×Ÿ":"0501111111", "×“×•×\"×œ":"ruth@example.com", "×ª×—×•× ××•×¢×“×£":"×‘×¨×™××•×ª ×”× ×¤×©"},
    {"×©× ×¤×¨×˜×™":"×™×•××‘", "×©× ××©×¤×—×”":"×œ×•×™", "×ª×¢×•×“×ª ×–×”×•×ª":"987654321", "×›×ª×•×‘×ª":"×“×™×–× ×’×•×£ 80", "×¢×™×¨ ××’×•×¨×™×":"×ª×œ ××‘×™×‘", "×˜×œ×¤×•×Ÿ":"0502222222", "×“×•×\"×œ":"yoav@example.com", "×ª×—×•× ××•×¢×“×£":"×¨×•×•×—×”"}
])
example_sites = pd.DataFrame([
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××¨×›×– ×—×•×¡×Ÿ ×ª×œ ××‘×™×‘", "×ª×—×•× ×”×”×ª××—×•×ª":"×‘×¨×™××•×ª ×”× ×¤×©", "×¨×—×•×‘":"××‘×Ÿ ×’×‘×™×¨×•×œ 1", "×¢×™×¨":"×ª×œ ××‘×™×‘", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":2},
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××—×œ×§×ª ×¨×•×•×—×” ×¨××ª ×’×Ÿ", "×ª×—×•× ×”×”×ª××—×•×ª":"×¨×•×•×—×”", "×¨×—×•×‘":"×‘×™××œ×™×§ 10", "×¢×™×¨":"×¨××ª ×’×Ÿ", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":1},
])
colX, colY = st.columns(2, gap="large")
with colX:
    st.write("**×“×•×’××” â€“ ×¡×˜×•×“× ×˜×™×**")
    st.dataframe(example_students, use_container_width=True)
    st.download_button("â¬‡ï¸ ×”×•×¨×“×ª ×“×•×’××ª ×¡×˜×•×“× ×˜×™× (CSV)",
                       data=example_students.to_csv(index=False, encoding="utf-8-sig"),
                       file_name="students_example.csv", mime="text/csv")
with colY:
    st.write("**×“×•×’××” â€“ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×**")
    st.dataframe(example_sites, use_container_width=True)
    st.download_button("â¬‡ï¸ ×”×•×¨×“×ª ×“×•×’××ª ××ª×¨×™× (CSV)",
                       data=example_sites.to_csv(index=False, encoding="utf-8-sig"),
                       file_name="sites_example.csv", mime="text/csv")

# ====== 3) ×”×¢×œ××ª ×§×‘×¦×™× ======
st.markdown("## ğŸ“¤ ×”×¢×œ××ª ×§×‘×¦×™×")
colA, colB = st.columns(2, gap="large")
with colA:
    students_file = st.file_uploader("×§×•×‘×¥ ×¡×˜×•×“× ×˜×™×", type=["csv","xlsx","xls"], key="students_file")
    if students_file is not None:
        st.caption("×”×¦×¦×” ×œ-5 ×”×¨×©×•××•×ª ×”×¨××©×•× ×•×ª:")
        try:
            df_students_raw = read_any(students_file)
            st.dataframe(df_students_raw.head(5), use_container_width=True)
        except Exception:
            st.error("×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×”×§×•×‘×¥.")
            df_students_raw = None
    else:
        df_students_raw = None

with colB:
    sites_file = st.file_uploader("×§×•×‘×¥ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×", type=["csv","xlsx","xls"], key="sites_file")
    if sites_file is not None:
        st.caption("×”×¦×¦×” ×œ-5 ×”×¨×©×•××•×ª ×”×¨××©×•× ×•×ª:")
        try:
            df_sites_raw = read_any(sites_file)
            st.dataframe(df_sites_raw.head(5), use_container_width=True)
        except Exception:
            st.error("×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×”×§×•×‘×¥.")
            df_sites_raw = None
    else:
        df_sites_raw = None

# ====== 4) ×©×™×‘×•×¥ ======
st.markdown("## âš™ï¸ ×‘×™×¦×•×¢ ×”×©×™×‘×•×¥")
run_btn = st.button("ğŸš€ ×‘×¦×¢ ×©×™×‘×•×¥", use_container_width=True)

result_df = None
if run_btn:
    if students_file is None or sites_file is None:
        st.error("× × ×œ×”×¢×œ×•×ª ××ª ×©× ×™ ×”×§×‘×¦×™× ×œ×¤× ×™ ×”×¤×¢×œ×ª ×”×©×™×‘×•×¥.")
    else:
        try:
            for df in (df_students_raw, df_sites_raw):
                drop_cols = [c for c in df.columns if str(c).startswith("Unnamed")]
                df.drop(columns=drop_cols, inplace=True, errors="ignore")
            students = resolve_students(df_students_raw)
            sites = resolve_sites(df_sites_raw)
            result_df = greedy_match(students, sites, W)
            st.success("×”×©×™×‘×•×¥ ×”×•×©×œ× âœ“")
        except Exception as e:
            st.exception(e)

# ====== 5) ×ª×•×¦××•×ª ======
st.markdown("## ğŸ“Š ×ª×•×¦××•×ª ×”×©×™×‘×•×¥")
if 'result_df' in locals() and result_df is not None and not result_df.empty:
    st.dataframe(result_df, use_container_width=True)
    csv = result_df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button("â¬‡ï¸ ×”×•×¨×“×ª ×§×•×‘×¥ ×”×ª×•×¦××•×ª (CSV)", data=csv, file_name="student_site_matching.csv", mime="text/csv")
else:
    st.caption("×˜×¨× ×”×•×¤×¢×œ ×©×™×‘×•×¥ ××• ×©××™×Ÿ ×ª×•×¦××•×ª ×œ×”×¦×’×”.")
