# matcher_streamlit_beauty_rtl_v7_fixed.py
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from dataclasses import dataclass
from typing import Optional, Any, List, Dict
import re

# =========================
# ×§×•× ×¤×™×’×•×¨×¦×™×” ×›×œ×œ×™×ª
# =========================
st.set_page_config(page_title="××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”", layout="wide")

# ====== CSS â€“ ×¢×™×¦×•×‘ ××•×“×¨× ×™ + RTL + ×’×•×¤×Ÿ David ======
st.markdown("""
<style>
/* × ×©×ª××© ×‘×’×•×¤×Ÿ David ×× ×§×™×™× ×‘××¢×¨×›×ª; ××—×¨×ª × ×™×¤×•×œ ×œ×§×œ××¡×™×™× */
:root{
  --bg-1:#e0f7fa;
  --bg-2:#ede7f6;
  --bg-3:#fff3e0;
  --bg-4:#fce4ec;
  --bg-5:#e8f5e9;
  --ink:#0f172a;
  --primary:#9b5de5;
  --primary-700:#f15bb5;
  --ring:rgba(155,93,229,.35);
}

html, body, [class*="css"], .stApp, .main, [data-testid="stSidebar"]{
  font-family: "David", "Noto Sans Hebrew", "Segoe UI", system-ui, sans-serif !important;
}

[data-testid="stAppViewContainer"]{
  background:
    radial-gradient(1200px 600px at 15% 10%, var(--bg-2) 0%, transparent 70%),
    radial-gradient(1000px 700px at 85% 20%, var(--bg-3) 0%, transparent 70%),
    radial-gradient(900px 500px at 50% 80%, var(--bg-4) 0%, transparent 70%),
    radial-gradient(700px 400px at 10% 85%, var(--bg-5) 0%, transparent 70%),
    linear-gradient(135deg, var(--bg-1) 0%, #ffffff 100%) !important;
  color: var(--ink);
}

.main .block-container{
  background: rgba(255,255,255,.78);
  backdrop-filter: blur(10px);
  border:1px solid rgba(15,23,42,.08);
  box-shadow:0 15px 35px rgba(15,23,42,.08);
  border-radius:24px;
  padding:2.5rem;
  margin-top:1rem;
}

h1,h2,h3,.stMarkdown h1,.stMarkdown h2{
  text-align:center;
  letter-spacing:.5px;
  text-shadow:0 1px 2px rgba(255,255,255,.7);
  font-weight:700;
  color:#222;
  margin-bottom:1rem;
}

.stApp,.main,[data-testid="stSidebar"]{ direction:rtl; text-align:right; }
label,.stMarkdown,.stText,.stCaption{ text-align:right!important; }

/* ×›×¤×ª×•×¨ ×¨××©×™ â€“ ×’×“×•×œ ×•×¨×—×‘ */
.cta-wrap > div > button{
  background:linear-gradient(90deg,var(--primary) 0%,var(--primary-700) 100%)!important;
  color:#fff!important;
  border:none!important;
  border-radius:24px!important;
  padding:1.4rem 2rem!important;
  font-size:1.25rem!important;
  font-weight:700!important;
  box-shadow:0 10px 22px var(--ring)!important;
  transition:all .15s ease!important;
  width:100%!important;
}
.cta-wrap > div > button:hover{ transform:translateY(-3px) scale(1.02); filter:brightness(1.07); }
.cta-wrap > div > button:focus{ outline:none!important; box-shadow:0 0 0 4px var(--ring)!important; }
</style>
""", unsafe_allow_html=True)

# ====== ×›×•×ª×¨×ª ======
st.markdown("<h1>××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;color:#475569;margin-top:-8px;'>×›××Ÿ ××©×‘×¦×™× ×¡×˜×•×“× ×˜×™× ×œ××§×•××•×ª ×”×ª××—×•×ª ×‘×§×œ×•×ª, ×‘×”×ª×‘×¡×¡ ×¢×œ ×ª×—×•×, ×¢×™×¨ ×•×‘×§×©×•×ª.</p>", unsafe_allow_html=True)

# ====== ××•×“×œ × ×™×§×•×“ ======
@dataclass
class Weights:
    # ××©×§×œ×™× â€“ ××™×™×¦×¨×™× ×©×•× ×•×ª ×××™×ª×™×ª ×‘×™×Ÿ ××•×¢××“×™×
    w_field: float   = 0.55   # ×ª×—×•×
    w_city: float    = 0.25   # ×¢×™×¨/××–×•×¨
    w_special: float = 0.20   # ×‘×§×©×•×ª ××™×•×—×“×•×ª

# ×¢××•×“×•×ª ×¡×˜×•×“× ×˜×™×
STU_COLS = {
    "id": ["××¡×¤×¨ ×ª×¢×•×“×ª ×–×”×•×ª", "×ª×¢×•×“×ª ×–×”×•×ª", "×ª\"×–", "×ª×–", "×ª×¢×•×“×ª ×–×”×•×ª ×”×¡×˜×•×“× ×˜"],
    "first": ["×©× ×¤×¨×˜×™"],
    "last": ["×©× ××©×¤×—×”"],
    "address": ["×›×ª×•×‘×ª", "×›×ª×•×‘×ª ×”×¡×˜×•×“× ×˜", "×¨×—×•×‘"],
    "city": ["×¢×™×¨ ××’×•×¨×™×", "×¢×™×¨"],
    "phone": ["×˜×œ×¤×•×Ÿ", "××¡×¤×¨ ×˜×œ×¤×•×Ÿ"],
    "email": ["×“×•×\"×œ", "×“×•××´×œ", "××™××™×™×œ", "×›×ª×•×‘×ª ××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ"],
    "preferred_field": ["×ª×—×•× ××•×¢×“×£","×ª×—×•××™× ××•×¢×“×¤×™×"],
    "special_req": ["×‘×§×©×” ××™×•×—×“×ª"],
    "partner": ["×‘×Ÿ/×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ\\×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ/×‘×ª ×–×•×’", "×‘×Ÿ\\×‘×ª ×–×•×’"]
}

# ×¢××•×“×•×ª ××ª×¨×™×
SITE_COLS = {
    "name": ["××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”", "××•×¡×“", "×©× ××•×¡×“ ×”×”×ª××—×•×ª", "×©× ×”××•×¡×“", "××•×¡×“ ×”×”×›×©×¨×”"],
    "field": ["×ª×—×•× ×”×”×ª××—×•×ª", "×ª×—×•× ×”×ª××—×•×ª"],
    "street": ["×¨×—×•×‘"],
    "city": ["×¢×™×¨"],
    "capacity": ["××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜", "×§×™×‘×•×œ×ª"],
    "sup_first": ["×©× ×¤×¨×˜×™"],
    "sup_last": ["×©× ××©×¤×—×”"],
    "phone": ["×˜×œ×¤×•×Ÿ"],
    "email": ["××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ", "×“×•×\"×œ", "×“×•××´×œ"],
    "review": ["×—×•×•×ª ×“×¢×ª ××“×¨×™×š"]
}

def pick_col(df: pd.DataFrame, options: List[str]) -> Optional[str]:
    for opt in options:
        if opt in df.columns: return opt
    return None

# ----- ×§×¨×™××ª ×§×‘×¦×™× -----
def read_any(uploaded) -> pd.DataFrame:
    name = (uploaded.name or "").lower()
    if name.endswith(".csv"):
        return pd.read_csv(uploaded, encoding="utf-8-sig")
    if name.endswith((".xlsx",".xls")):
        return pd.read_excel(uploaded)
    return pd.read_csv(uploaded, encoding="utf-8-sig")

def normalize_text(x: Any) -> str:
    return (str(x or "")).strip()

# ----- ×¡×˜×•×“× ×˜×™× -----
def resolve_students(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["stu_id"]    = out[pick_col(out, STU_COLS["id"])]
    out["stu_first"] = out[pick_col(out, STU_COLS["first"])]
    out["stu_last"]  = out[pick_col(out, STU_COLS["last"])]

    city_col = pick_col(out, STU_COLS["city"]) or pick_col(out, STU_COLS["address"])
    out["stu_city"]  = out[city_col] if city_col else ""

    # ×ª×—×•× ××•×¢×“×£/×™×
    pref_col = pick_col(out, ["×ª×—×•××™× ××•×¢×“×¤×™×"]) or pick_col(out, STU_COLS["preferred_field"])
    out["stu_pref"] = out[pref_col] if pref_col else ""

    out["stu_req"]  = out[pick_col(out, STU_COLS["special_req"])] if pick_col(out, STU_COLS["special_req"]) else ""

    for c in ["stu_id","stu_first","stu_last","stu_city","stu_pref","stu_req"]:
        out[c] = out[c].apply(normalize_text)

    return out

# ----- ××ª×¨×™× -----
def resolve_sites(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["site_name"]  = out[pick_col(out, SITE_COLS["name"])]
    out["site_field"] = out[pick_col(out, SITE_COLS["field"])]
    out["site_city"]  = out[pick_col(out, SITE_COLS["city"])]

    cap_col = pick_col(out, SITE_COLS["capacity"])
    out["site_capacity"] = pd.to_numeric(out[cap_col], errors="coerce").fillna(1).astype(int) if cap_col else 1
    out["capacity_left"] = out["site_capacity"].astype(int)

    sup_first = pick_col(out, SITE_COLS["sup_first"])
    sup_last  = pick_col(out, SITE_COLS["sup_last"])
    out["×©× ×”××“×¨×™×š"] = ""
    if sup_first or sup_last:
        ff = out[sup_first] if sup_first else ""
        ll = out[sup_last]  if sup_last else ""
        out["×©× ×”××“×¨×™×š"] = (ff.astype(str) + " " + ll.astype(str)).str.strip()

    for c in ["site_name","site_field","site_city","×©× ×”××“×¨×™×š"]:
        out[c] = out[c].apply(normalize_text)
    return out

# ====== ×¢×–×¨ ×œ× ×™×§×•×“ ======
CITY_REGION: Dict[str, str] = {
    "×ª×œ ××‘×™×‘": "××¨×›×–", "×¨××ª ×’×Ÿ": "××¨×›×–", "×’×‘×¢×ª×™×™×": "××¨×›×–",
    "×¤×ª×— ×ª×§×•×•×”": "××¨×›×–", "×¨××©×•×Ÿ ×œ×¦×™×•×Ÿ": "××¨×›×–", "× ×ª× ×™×”": "×©×¨×•×Ÿ",
    "×¨×¢× × ×”": "×©×¨×•×Ÿ", "×›×¤×¨ ×¡×‘×": "×©×¨×•×Ÿ",
    "×—×™×¤×”": "×¦×¤×•×Ÿ", "×§×¨×™×•×ª": "×¦×¤×•×Ÿ", "× ×”×¨×™×”": "×¦×¤×•×Ÿ", "×¢×›×•": "×¦×¤×•×Ÿ", "×¦×¤×ª": "×¦×¤×•×Ÿ", "×˜×‘×¨×™×”": "×¦×¤×•×Ÿ",
    "××©×“×•×“": "×“×¨×•×", "××©×§×œ×•×Ÿ": "×“×¨×•×", "×‘××¨ ×©×‘×¢": "×“×¨×•×",
    "×¨×—×•×‘×•×ª": "×©×¤×œ×”"
}

def _norm(s: Any) -> str:
    return (str(s or "")).strip().lower()

def _tokenize_field(s: str) -> List[str]:
    s = _norm(s)
    s = re.sub(r"[^×-×ªa-z0-9\s/,+-]", " ", s)
    parts = re.split(r"[/,|\\s]+", s)
    return [p for p in parts if p]

def jaccard(a: List[str], b: List[str]) -> float:
    A, B = set(a), set(b)
    if not A or not B: return 0.0
    inter = len(A & B)
    union = len(A | B)
    return inter/union if union else 0.0

def domain_score(stu_pref_text: str, site_field_text: str) -> int:
    if not stu_pref_text or not site_field_text:
        return 0
    a = _tokenize_field(stu_pref_text)
    b = _tokenize_field(site_field_text)
    sim = jaccard(a, b)
    if sim >= 0.67: return 100
    if sim >= 0.33: return 80
    return 50

def city_score(stu_city: str, site_city: str) -> int:
    s_c = normalize_text(stu_city)
    t_c = normalize_text(site_city)
    if not s_c or not t_c: return 0
    if s_c == t_c: return 100
    s_r = CITY_REGION.get(s_c, "")
    t_r = CITY_REGION.get(t_c, "")
    if s_r and t_r:
        if s_r == t_r: return 85
        NEI = {
            "××¨×›×–": {"×©×¨×•×Ÿ", "×©×¤×œ×”"},
            "×©×¨×•×Ÿ": {"××¨×›×–", "×¦×¤×•×Ÿ"},
            "×¦×¤×•×Ÿ": {"×©×¨×•×Ÿ"},
            "×©×¤×œ×”": {"××¨×›×–", "×“×¨×•×"},
            "×“×¨×•×": {"×©×¤×œ×”"},
        }
        if t_r in NEI.get(s_r, set()):
            return 70
        return 50
    return 50

def special_score(stu_req: str, same_city: bool) -> int:
    txt = _norm(stu_req)
    if not txt: return 0
    if "×§×¨×•×‘" in txt or "×§×¨×‘×”" in txt or "×‘×™×ª" in txt:
        return 100 if same_city else 70
    return 60

# ====== ×—×™×©×•×‘ ×¦×™×•×Ÿ ======
def compute_score(stu: pd.Series, site: pd.Series, W: Weights) -> float:
    same_city = (_norm(stu.get("stu_city")) and _norm(site.get("site_city")) and
                 _norm(stu.get("stu_city")) == _norm(site.get("site_city")))
    f = domain_score(stu.get("stu_pref",""), site.get("site_field",""))
    c = city_score(stu.get("stu_city",""), site.get("site_city",""))
    s = special_score(stu.get("stu_req",""), same_city)
    score = W.w_field*f + W.w_city*c + W.w_special*s
    return float(np.clip(score, 0, 100))

def compute_score_with_explain(stu: pd.Series, site: pd.Series, W: Weights):
    same_city = (_norm(stu.get("stu_city")) and _norm(site.get("site_city")) and
                 _norm(stu.get("stu_city")) == _norm(site.get("site_city")))
    f = domain_score(stu.get("stu_pref",""), site.get("site_field",""))
    c = city_score(stu.get("stu_city",""), site.get("site_city",""))
    s = special_score(stu.get("stu_req",""), same_city)
    parts = {
        "×”×ª×××ª ×ª×—×•×": int(round(W.w_field * f)),
        "××¨×—×§/×’×™××•×’×¨×¤×™×”": int(round(W.w_city * c)),
        "×‘×§×©×•×ª ××™×•×—×“×•×ª": int(round(W.w_special * s)),
        "×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª": 0,
    }
    score = int(np.clip(sum(parts.values()), 0, 100))
    return score, parts

# =========================
# 1) ×”×•×¨××•×ª ×©×™××•×©
# =========================
st.markdown("## ğŸ“˜ ×”×•×¨××•×ª ×©×™××•×©")
st.markdown("""
1. **×§×•×‘×¥ ×¡×˜×•×“× ×˜×™× (CSV/XLSX):** ×©× ×¤×¨×˜×™, ×©× ××©×¤×—×”, ×ª×¢×•×“×ª ×–×”×•×ª, ×¢×™×¨/×›×ª×•×‘×ª, ×˜×œ×¤×•×Ÿ, ××™××™×™×œ.  
   ××•×¤×¦×™×•× ×œ×™: ×ª×—×•× ××•×¢×“×£/×™×, ×‘×§×©×” ××™×•×—×“×ª.  
2. **×§×•×‘×¥ ××ª×¨×™×/××“×¨×™×›×™× (CSV/XLSX):** ××•×¡×“/×©×™×¨×•×ª, ×ª×—×•× ×”×ª××—×•×ª, ×¢×™×¨, ×§×™×‘×•×œ×ª, ××“×¨×™×š, ×—×•×•×ª ×“×¢×ª.  
3. ×›×¤×ª×•×¨ **×‘×¦×¢ ×©×™×‘×•×¥** ××—×©×‘ ××—×•×– ×”×ª×××” ×œ×¤×™ ×ª×—×•× (55%), ××–×•×¨/×¢×™×¨ (25%), ×‘×§×©×•×ª (20%).
""")

# =========================
# 2) ×“×•×’××” ×œ×©×™××•×©
# =========================
st.markdown("## ğŸ§ª ×“×•×’××” ×œ×©×™××•×©")
example_students = pd.DataFrame([
    {"×©× ×¤×¨×˜×™":"×¨×•×ª", "×©× ××©×¤×—×”":"×›×”×Ÿ", "×ª×¢×•×“×ª ×–×”×•×ª":"123456789", "×¢×™×¨ ××’×•×¨×™×":"×ª×œ ××‘×™×‘", "×˜×œ×¤×•×Ÿ":"0501111111", "×“×•×\"×œ":"ruth@example.com", "×ª×—×•× ××•×¢×“×£":"×‘×¨×™××•×ª ×”× ×¤×©", "×‘×§×©×” ××™×•×—×“×ª":"×§×¨×•×‘ ×œ×‘×™×ª"},
    {"×©× ×¤×¨×˜×™":"×™×•××‘", "×©× ××©×¤×—×”":"×œ×•×™", "×ª×¢×•×“×ª ×–×”×•×ª":"987654321", "×¢×™×¨ ××’×•×¨×™×":"×—×™×¤×”", "×˜×œ×¤×•×Ÿ":"0502222222", "×“×•×\"×œ":"yoav@example.com", "×ª×—×•× ××•×¢×“×£":"×¨×•×•×—×”"},
    {"×©× ×¤×¨×˜×™":"×¡×××—", "×©× ××©×¤×—×”":"×—'×•×¨×™", "×ª×¢×•×“×ª ×–×”×•×ª":"456789123", "×¢×™×¨ ××’×•×¨×™×":"×¢×›×•", "×˜×œ×¤×•×Ÿ":"0503333333", "×“×•×\"×œ":"sama@example.com", "×ª×—×•× ××•×¢×“×£":"×—×™× ×•×š ××™×•×—×“"},
])
example_sites = pd.DataFrame([
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××¨×›×– ×—×•×¡×Ÿ ×ª×œ ××‘×™×‘", "×ª×—×•× ×”×”×ª××—×•×ª":"×‘×¨×™××•×ª ×”× ×¤×©", "×¢×™×¨":"×ª×œ ××‘×™×‘", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":2, "×©× ×¤×¨×˜×™":"×“× ×™××œ", "×©× ××©×¤×—×”":"×›×”×Ÿ", "×—×•×•×ª ×“×¢×ª ××“×¨×™×š":"××“×¨×™×š ××¦×•×™×Ÿ"},
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××—×œ×§×ª ×¨×•×•×—×” ×—×™×¤×”", "×ª×—×•× ×”×”×ª××—×•×ª":"×¨×•×•×—×”", "×¢×™×¨":"×—×™×¤×”", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":1, "×©× ×¤×¨×˜×™":"××™×›×œ", "×©× ××©×¤×—×”":"×œ×•×™", "×—×•×•×ª ×“×¢×ª ××“×¨×™×š":"×–×§×•×§×” ×œ×©×™×¤×•×¨"},
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"×‘×™×ª ×¡×¤×¨ ×™×“ ×œ×‘× ×™×", "×ª×—×•× ×”×”×ª××—×•×ª":"×—×™× ×•×š ××™×•×—×“", "×¢×™×¨":"×¢×›×•", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":1, "×©× ×¤×¨×˜×™":"×©×¨×”", "×©× ××©×¤×—×”":"×›×”×Ÿ"},
])
colX, colY = st.columns(2, gap="large")
with colX:
    st.write("**×“×•×’××” â€“ ×¡×˜×•×“× ×˜×™×**")
    st.dataframe(example_students, use_container_width=True)
with colY:
    st.write("**×“×•×’××” â€“ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×**")
    st.dataframe(example_sites, use_container_width=True)

# =========================
# 3) ×”×¢×œ××ª ×§×‘×¦×™×
# =========================
st.markdown("## ğŸ“¤ ×”×¢×œ××ª ×§×‘×¦×™×")
colA, colB = st.columns(2, gap="large")

with colA:
    students_file = st.file_uploader("×§×•×‘×¥ ×¡×˜×•×“× ×˜×™×", type=["csv","xlsx","xls"], key="students_file")
    if students_file is not None:
        try:
            st.session_state["df_students_raw"] = read_any(students_file)
            st.dataframe(st.session_state["df_students_raw"].head(5), use_container_width=True)
        except Exception as e:
            st.error(f"×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×§×•×‘×¥ ×”×¡×˜×•×“× ×˜×™×: {e}")

with colB:
    sites_file = st.file_uploader("×§×•×‘×¥ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×", type=["csv","xlsx","xls"], key="sites_file")
    if sites_file is not None:
        try:
            st.session_state["df_sites_raw"] = read_any(sites_file)
            st.dataframe(st.session_state["df_sites_raw"].head(5), use_container_width=True)
        except Exception as e:
            st.error(f"×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×§×•×‘×¥ ×”××ª×¨×™×/××“×¨×™×›×™×: {e}")

for k in ["df_students_raw","df_sites_raw","result_df","unmatched_students","unused_sites","sites_after"]:
    st.session_state.setdefault(k, None)

# ====== ×©×™×‘×•×¥ ======
def greedy_match(students_df: pd.DataFrame, sites_df: pd.DataFrame, W: Weights) -> pd.DataFrame:
    results = []
    supervisor_count = {}  # × ×™×ª×Ÿ ×œ×”×’×‘×™×œ/×œ××¤×¡ ×œ×¤×™ ×¦×•×¨×š (×“×•×’××”: ×¢×“ 2 ×¡×˜×•×“× ×˜×™× ×œ×›×œ ××“×¨×™×š)

    for _, s in students_df.iterrows():
        cand = sites_df[sites_df["capacity_left"] > 0].copy()
        if cand.empty:
            results.append({
                "×ª\"×– ×”×¡×˜×•×“× ×˜": s.get("stu_id",""),
                "×©× ×¤×¨×˜×™": s.get("stu_first",""),
                "×©× ××©×¤×—×”": s.get("stu_last",""),
                "×©× ××§×•× ×”×”×ª××—×•×ª": "×œ× ×©×•×‘×¥",
                "×¢×™×¨ ×”××•×¡×“": "",
                "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": "",
                "×©× ×”××“×¨×™×š": "",
                "××—×•×– ×”×ª×××”": 0,
                "_expl": {"×”×ª×××ª ×ª×—×•×":0,"××¨×—×§/×’×™××•×’×¨×¤×™×”":0,"×‘×§×©×•×ª ××™×•×—×“×•×ª":0,"×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª":0}
            })
            continue

        cand[["score","_parts"]] = cand.apply(
            lambda r: pd.Series(compute_score_with_explain(s, r, W)), axis=1
        )

        # ×“×•×’××ª ××’×‘×œ×”: ×¢×“ 2 ×œ-××“×¨×™×š (× ×™×ª×Ÿ ×œ×‘×˜×œ ×¢"×™ ×”×—×–×¨×ª True ×§×‘×•×¢)
        def allowed_supervisor(r):
            sup = r.get("×©× ×”××“×¨×™×š", "")
            return supervisor_count.get(sup, 0) < 2 if sup else True

        cand = cand[cand.apply(allowed_supervisor, axis=1)]
        if cand.empty:
            all_sites = sites_df[sites_df["capacity_left"] > 0].copy()
            if all_sites.empty:
                results.append({
                    "×ª\"×– ×”×¡×˜×•×“× ×˜": s.get("stu_id",""),
                    "×©× ×¤×¨×˜×™": s.get("stu_first",""),
                    "×©× ××©×¤×—×”": s.get("stu_last",""),
                    "×©× ××§×•× ×”×”×ª××—×•×ª": "×œ× ×©×•×‘×¥",
                    "×¢×™×¨ ×”××•×¡×“": "",
                    "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": "",
                    "×©× ×”××“×¨×™×š": "",
                    "××—×•×– ×”×ª×××”": 0,
                    "_expl": {"×”×ª×××ª ×ª×—×•×":0,"××¨×—×§/×’×™××•×’×¨×¤×™×”":0,"×‘×§×©×•×ª ××™×•×—×“×•×ª":0,"×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª":0}
                })
                continue
            all_sites[["score","_parts"]] = all_sites.apply(
                lambda r: pd.Series(compute_score_with_explain(s, r, W)), axis=1
            )
            cand = all_sites.sort_values("score", ascending=False).head(1)
        else:
            cand = cand.sort_values("score", ascending=False)

        chosen = cand.iloc[0]
        idx = chosen.name
        sites_df.at[idx, "capacity_left"] -= 1

        sup_name = chosen.get("×©× ×”××“×¨×™×š", "")
        if sup_name:
            supervisor_count[sup_name] = supervisor_count.get(sup_name, 0) + 1

        results.append({
            "×ª\"×– ×”×¡×˜×•×“× ×˜": s.get("stu_id",""),
            "×©× ×¤×¨×˜×™": s.get("stu_first",""),
            "×©× ××©×¤×—×”": s.get("stu_last",""),
            "×©× ××§×•× ×”×”×ª××—×•×ª": chosen.get("site_name",""),
            "×¢×™×¨ ×”××•×¡×“": chosen.get("site_city",""),
            "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": chosen.get("site_field",""),
            "×©× ×”××“×¨×™×š": sup_name,
            "××—×•×– ×”×ª×××”": int(chosen["score"]),
            "_expl": chosen["_parts"]
        })

    return pd.DataFrame(results)

# ---- ×™×¦×™×¨×ª XLSX ----
def df_to_xlsx_bytes(df: pd.DataFrame, sheet_name: str = "×©×™×‘×•×¥") -> bytes:
    xlsx_io = BytesIO()
    import xlsxwriter
    with pd.ExcelWriter(xlsx_io, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    xlsx_io.seek(0)
    return xlsx_io.getvalue()

# =========================
# ×©×™×‘×•×¥ ×•×”×¦×’×ª ×ª×•×¦××•×ª
# =========================
if "result_df" not in st.session_state:
    st.session_state["result_df"] = None

st.markdown("## âš™ï¸ ×‘×™×¦×•×¢ ×”×©×™×‘×•×¥")
c1, c2, c3 = st.columns([1,6,1])
with c2:
    st.markdown('<div class="cta-wrap">', unsafe_allow_html=True)
    run_match = st.button("×‘×¦×¢ ×©×™×‘×•×¥ ğŸš€", use_container_width=True, key="run_match")
    st.markdown('</div>', unsafe_allow_html=True)

if run_match:
    try:
        students = resolve_students(st.session_state["df_students_raw"])
        sites    = resolve_sites(st.session_state["df_sites_raw"])
        result_df = greedy_match(students, sites, Weights())
        st.session_state["result_df"] = result_df
        st.session_state["sites_after"] = sites
        st.success("×”×©×™×‘×•×¥ ×”×•×©×œ× âœ“")
    except Exception as e:
        st.exception(e)

if isinstance(st.session_state["result_df"], pd.DataFrame) and not st.session_state["result_df"].empty:
    st.markdown("## ğŸ“Š ×ª×•×¦××•×ª ×”×©×™×‘×•×¥")

    base_df = st.session_state["result_df"].copy()

    # ×˜×‘×œ×ª ×ª×•×¦××•×ª ××¨×›×–×™×ª (×œ×¤×™ ×“×¨×™×©×ª ×”××¨×¦×™×)
    df_show = pd.DataFrame({
        "××—×•×– ×”×ª×××”": base_df["××—×•×– ×”×ª×××”"].astype(int),
        "×©× ×”×¡×˜×•×“× ×˜/×™×ª": (base_df["×©× ×¤×¨×˜×™"].astype(str) + " " + base_df["×©× ××©×¤×—×”"].astype(str)).str.strip(),
        "×ª×¢×•×“×ª ×–×”×•×ª": base_df["×ª\"×– ×”×¡×˜×•×“× ×˜"],
        "×ª×—×•× ×”×ª××—×•×ª": base_df["×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“"],
        "×¢×™×¨ ×”××•×¡×“": base_df["×¢×™×¨ ×”××•×¡×“"],
        "×©× ××§×•× ×”×”×ª××—×•×ª": base_df["×©× ××§×•× ×”×”×ª××—×•×ª"],
        "×©× ×”××“×¨×™×š/×”": base_df["×©× ×”××“×¨×™×š"],
    }).sort_values("××—×•×– ×”×ª×××”", ascending=False)

    st.markdown("### ×˜×‘×œ×ª ×ª×•×¦××•×ª ××¨×›×–×™×ª")
    st.dataframe(df_show, use_container_width=True)

    # ×”×•×¨×“×”
    xlsx_results = df_to_xlsx_bytes(df_show, sheet_name="×ª×•×¦××•×ª")
    st.download_button(
        "â¬‡ï¸ ×”×•×¨×“×ª XLSX â€“ ×ª×•×¦××•×ª ×”×©×™×‘×•×¥",
        data=xlsx_results,
        file_name="student_site_matching.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # ×”×¡×‘×¨ ×¦×™×•×Ÿ
    st.markdown("### ğŸ§© ×”×¡×‘×¨ ×¦×™×•×Ÿ â€“ ×©×‘×™×¨×ª ×”×ª×××”")
    idx_max = len(base_df) - 1
    ex_idx = st.number_input("×‘×—×¨/×™ ×©×•×¨×” ×œ×”×¡×‘×¨ (0..):", min_value=0, max_value=idx_max, value=0, step=1)
    try:
        expl = base_df.iloc[int(ex_idx)]["_expl"]
        ex_df = pd.DataFrame({
            "××¨×›×™×‘": ["××¨×—×§/×’×™××•×’×¨×¤×™×”","×”×ª×××ª ×ª×—×•×","×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª","×‘×§×©×•×ª ××™×•×—×“×•×ª"],
            "×ª×¨×•××”": [expl.get("××¨×—×§/×’×™××•×’×¨×¤×™×”",0), expl.get("×”×ª×××ª ×ª×—×•×",0), expl.get("×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª",0), expl.get("×‘×§×©×•×ª ××™×•×—×“×•×ª",0)]
        })
        ex_df.loc[len(ex_df.index)] = {"××¨×›×™×‘": "×¡×”\"×›", "×ª×¨×•××”": int(base_df.iloc[int(ex_idx)]["××—×•×– ×”×ª×××”"])}
        st.table(ex_df)
    except Exception:
        st.info("××™×Ÿ × ×ª×•× ×™ ×”×¡×‘×¨ ×œ×¦×™×•×Ÿ ×¢×‘×•×¨ ×”×©×•×¨×” ×©× ×‘×—×¨×”.")

    # ×“×•×— ×¡×™×›×•× ×œ×¤×™ ××§×•× ×”×›×©×¨×”
    st.markdown("### ğŸ“ ×˜×‘×œ×ª ×¡×™×›×•× ×œ×¤×™ ××§×•× ×”×›×©×¨×”")
    summary_df = (
        base_df
        .groupby(["×©× ××§×•× ×”×”×ª××—×•×ª","×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“","×©× ×”××“×¨×™×š"])
        .agg({
            "×ª\"×– ×”×¡×˜×•×“× ×˜":"count",
            "×©× ×¤×¨×˜×™": list,
            "×©× ××©×¤×—×”": list
        }).reset_index()
    )
    summary_df.rename(columns={"×ª\"×– ×”×¡×˜×•×“× ×˜":"×›××” ×¡×˜×•×“× ×˜×™×"}, inplace=True)
    summary_df["×”××œ×¦×ª ×©×™×‘×•×¥"] = summary_df.apply(
        lambda row: " + ".join([f"{f} {l}" for f, l in zip(row["×©× ×¤×¨×˜×™"], row["×©× ××©×¤×—×”"])]),
        axis=1
    )
    summary_df = summary_df[[
        "×©× ××§×•× ×”×”×ª××—×•×ª","×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“","×©× ×”××“×¨×™×š","×›××” ×¡×˜×•×“× ×˜×™×","×”××œ×¦×ª ×©×™×‘×•×¥"
    ]]
    st.dataframe(summary_df, use_container_width=True)

    xlsx_summary = df_to_xlsx_bytes(summary_df, sheet_name="×¡×™×›×•×")
    st.download_button(
        "â¬‡ï¸ ×”×•×¨×“×ª XLSX â€“ ×˜×‘×œ×ª ×¡×™×›×•×",
        data=xlsx_summary,
        file_name="student_site_summary.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # ×“×•×— ×§×™×‘×•×œ×•×ª
    st.markdown("### ğŸ·ï¸ ×“×•×— ×§×™×‘×•×œ×•×ª ×œ×¤×™ ××§×•× ×”×›×©×¨×”")
    sites_after = st.session_state.get("sites_after", None)
    if isinstance(sites_after, pd.DataFrame) and not sites_after.empty:
        caps = sites_after.groupby("site_name")["site_capacity"].sum().to_dict()
        assigned = base_df.groupby("×©× ××§×•× ×”×”×ª××—×•×ª")["×ª\"×– ×”×¡×˜×•×“× ×˜"].count().to_dict()
        cap_rows = []
        for site, capacity in caps.items():
            used = int(assigned.get(site, 0))
            cap_rows.append({
                "×©× ××§×•× ×”×”×ª××—×•×ª": site,
                "×§×™×‘×•×œ×ª": int(capacity),
                "×©×•×‘×¦×• ×‘×¤×•×¢×œ": used,
                "×™×ª×¨×”/×—×•×¡×¨": int(capacity - used)
            })
        cap_df = pd.DataFrame(cap_rows).sort_values("×©× ××§×•× ×”×”×ª××—×•×ª")
        st.dataframe(cap_df, use_container_width=True)

        under = cap_df[cap_df["×™×ª×¨×”/×—×•×¡×¨"] > 0]
        over  = cap_df[cap_df["×™×ª×¨×”/×—×•×¡×¨"] < 0]
        if not under.empty:
            st.info("××•×¡×“×•×ª ×¢× ××§×•××•×ª ×¤× ×•×™×™×:\n- " + "\n- ".join(under["×©× ××§×•× ×”×”×ª××—×•×ª"].tolist()))
        if not over.empty:
            st.error("××•×¡×“×•×ª ×¢× ×—×¨×™×’×” (×¢×•×“×£ ×©×™×‘×•×¥):\n- " + "\n- ".join(over["×©× ××§×•× ×”×”×ª××—×•×ª"].tolist()))
    else:
        st.info("×œ× × ××¦××• × ×ª×•× ×™ ×§×™×‘×•×œ×ª ×œ×©×™×‘×•×¥ ×–×”.")

    # ×“×•×— ×¨×™×›×•×–×™ ×¤×¨Ö¾××•×¨×”
    st.markdown("### ğŸ‘©â€ğŸ« ×“×•×— ×¤×¨Ö¾××•×¨×” ×©×™×˜×•×ª")
    teachers_list = ["(×›×•×œ×)"] + sorted([x for x in base_df["×©× ×”××“×¨×™×š"].unique() if str(x).strip() != ""])
    pick_teacher = st.selectbox("×¡×™× ×•×Ÿ ×œ×¤×™ ××•×¨×”:", teachers_list, index=0)
    df_for_teacher = base_df.copy()
    if pick_teacher != "(×›×•×œ×)":
        df_for_teacher = df_for_teacher[df_for_teacher["×©× ×”××“×¨×™×š"] == pick_teacher]
    st.dataframe(
        pd.DataFrame({
            "×©× ×”×¡×˜×•×“× ×˜/×™×ª": (df_for_teacher["×©× ×¤×¨×˜×™"].astype(str) + " " + df_for_teacher["×©× ××©×¤×—×”"].astype(str)).str.strip(),
            "×ª×¢×•×“×ª ×–×”×•×ª": df_for_teacher["×ª\"×– ×”×¡×˜×•×“× ×˜"],
            "×©× ××§×•× ×”×”×ª××—×•×ª": df_for_teacher["×©× ××§×•× ×”×”×ª××—×•×ª"],
            "××—×•×– ×”×ª×××”": df_for_teacher["××—×•×– ×”×ª×××”"].astype(int)
        }).sort_values("××—×•×– ×”×ª×××”", ascending=False),
        use_container_width=True
    )
