# streamlit_app.py
# ---------------------------------------------------------
# ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× ×œ×¤×™ "××™-××ª××™×-×œ" (×’××™×©):
# - ×”××©×ª××© ××¢×œ×” ×§×‘×¦×™ ×¡×˜×•×“× ×˜×™×/××ª×¨×™× (CSV/XLSX) ×•×‘×•×—×¨ ×’×™×œ×™×•× ×•×ª/×¢××•×“×•×ª.
# - × ×™×§×•×“: ×ª×—×•× (×—×¤×™×¤×”/×”×›×œ×”), ×¢×™×¨ (× ×™×¨××•×œ), ××¨×—×§ (×§×™×¨×‘×”) + ×§×™×‘×•×œ×ª.
# - ×ª×•×¦××ª ×©×™×‘×•×¥ ×›×•×œ×œ×ª: ×ª"×–, ×©× ×¤×¨×˜×™, ×©× ××©×¤×—×”, ×¢×™×¨ ××’×•×¨×™×, ××ª×¨, ×¢×™×¨ ××ª×¨, % ×”×ª×××”, ×©× ××“×¨×™×š.
# ---------------------------------------------------------

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from io import BytesIO
import re, time, math

# ========= Geopy (×œ×’×™××•×§×•×“) =========
try:
    from geopy.geocoders import Nominatim
    GEOPY_OK = True
except Exception:
    GEOPY_OK = False

# =========================
# ×”×’×“×¨×•×ª ×›×œ×œ×™×•×ª + ×¢×™×¦×•×‘
# =========================
st.set_page_config(page_title="×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ××™-××ª××™×-×œ", layout="wide")

st.markdown("""
<style>
:root{
  --ink:#0f172a; 
  --muted:#475569; 
  --ring:rgba(99,102,241,.25); 
  --card:rgba(255,255,255,.85);
  --border:#e2e8f0;
}

/* RTL + ×¤×•× ×˜×™× */
html, body, [class*="css"] { font-family: system-ui, "Segoe UI", Arial; }
.stApp, .main, [data-testid="stSidebar"]{ direction:rtl; text-align:right; }

/* ×¨×§×¢ */
[data-testid="stAppViewContainer"]{
  background:
    radial-gradient(1200px 600px at 8% 8%, #e0f7fa 0%, transparent 65%),
    radial-gradient(1000px 500px at 92% 12%, #ede7f6 0%, transparent 60%),
    radial-gradient(900px 500px at 20% 90%, #fff3e0 0%, transparent 55%);
}
.block-container{ padding-top:1.1rem; }

/* ×›×¨×˜×™×¡×™× */
.card{ background:var(--card); border:1px solid var(--border); border-radius:16px; padding:18px 20px; box-shadow:0 8px 24px rgba(2,6,23,.06); }
.hero{
  background:linear-gradient(180deg, rgba(255,255,255,.96), rgba(255,255,255,.9));
  border:1px solid var(--border); border-radius:18px; padding:22px 20px; box-shadow:0 8px 28px rgba(2,6,23,.06);
}
.hero h1{ margin:0 0 6px 0; color:var(--ink); font-size:28px; }
.hero p{ margin:0; color:var(--muted); }

/* ××¡×’×¨×ª ×œ×˜×•×¤×¡ */
[data-testid="stForm"], .boxed{
  background:var(--card);
  border:1px solid #e2e8f0;
  border-radius:16px;
  padding:18px 20px;
  box-shadow:0 8px 24px rgba(2,6,23,.06);
}

/* ×ª×•×•×™×•×ª + × ×§×•×“×ª×™×™× ××™××™×Ÿ */
[data-testid="stWidgetLabel"] p{
  text-align:right; 
  margin-bottom:.25rem; 
  color:var(--muted); 
}
[data-testid="stWidgetLabel"] p::after{
  content: " :";
}

/* ×©×“×•×ª */
input, textarea, select{ direction:rtl; text-align:right; }

/* KPI */
.metric{
  display:flex; align-items:center; justify-content:space-between;
  padding:10px 12px; border:1px solid var(--border); border-radius:14px; background:#fff;
}
.metric .label{ color:var(--muted); font-size:.9rem; }
.metric .value{ color:var(--ink); font-weight:700; }

hr{ border-color:var(--border); }
.small{ color:#64748b; font-size:.92rem; }
</style>
""", unsafe_allow_html=True)

# =========================
# ×§×‘×•×¢×™× ×•×§×‘×¦×™ ×§××©
# =========================
GEOCODE_CACHE = Path("./geocode_cache.csv")

# =========================
# ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ â€“ ×§×¨×™××”/× ×™×¨××•×œ/×¤×™×¦×•×œ/××¨×—×§
# =========================
def read_anytable(upload, sheet_name=None):
    """×§×•×¨× CSV/XLSX; ×× XLSX ×•××™×Ÿ sheet_name -> ×™×˜×¢×Ÿ ××ª ×”×¨××©×•×Ÿ."""
    if upload is None:
        return None, []
    name = upload.name.lower()
    if name.endswith(".csv"):
        try:
            return pd.read_csv(upload), []
        except Exception:
            upload.seek(0)
            return pd.read_csv(upload, encoding="utf-8-sig"), []
    else:
        try:
            xf = pd.ExcelFile(upload)
            sheets = xf.sheet_names
            if sheet_name and sheet_name in sheets:
                return xf.parse(sheet_name), sheets
            else:
                return xf.parse(sheets[0]), sheets
        except Exception:
            return None, []

def _strip(x): 
    return "" if pd.isna(x) else str(x).strip()

def _lc(x): 
    return _strip(x).lower()

_PUNCT_RE = re.compile(r"[\"'`â€â€œ×³×´\.\!\?\:\;\|\Â·â€¢\u2022\(\)\[\]\{\}]+")
_WS_RE    = re.compile(r"\s+")
def normalize_text(s: str) -> str:
    s = _strip(s)
    s = _PUNCT_RE.sub(" ", s)
    s = s.replace("-", " ").replace("â€“", " ").replace("â€”", " ").replace("/", " ")
    s = _WS_RE.sub(" ", s).strip()
    return s.lower()

def split_multi(raw) -> set:
    if pd.isna(raw): return set()
    s = str(raw).replace("\n", ",")
    s = re.sub(r"[;/|â€¢Â·â€¢]", ",", s)
    s = s.replace("â€“", ",").replace("â€”", ",").replace("/", ",")
    if "," not in s:
        s = re.sub(r"\s{2,}", ",", s)
    items = [normalize_text(p) for p in s.split(",") if normalize_text(p)]
    return set(items)

def overlap_count(set_a: set, set_b: set) -> int:
    cnt = 0
    for a in set_a:
        for b in set_b:
            if not a or not b: 
                continue
            if a == b:
                cnt += 1
            else:
                if (len(a) >= 3 and a in b) or (len(b) >= 3 and b in a):
                    cnt += 1
    return cnt

def haversine_km(lat1, lon1, lat2, lon2):
    if None in [lat1, lon1, lat2, lon2]: return None
    try:
        R = 6371.0
        p1 = math.radians(lat1); p2 = math.radians(lat2)
        dphi = math.radians(lat2 - lat1); dl = math.radians(lon2 - lon1)
        a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dl/2)**2
        c = 2 * math.asin(math.sqrt(a))
        return R * c
    except Exception:
        return None

def bytes_for_download(df, filename):
    bio = BytesIO()
    df.to_csv(bio, index=False, encoding="utf-8-sig"); bio.seek(0)
    return bio, filename

# ---- ×§××© ×’×™××•×§×•×“ ----
def load_geocode_cache():
    if GEOCODE_CACHE.exists():
        try:
            df = pd.read_csv(GEOCODE_CACHE)
            return {row["query"]: (row["lat"], row["lon"]) for _, row in df.iterrows()}
        except Exception:
            return {}
    return {}

def save_geocode_cache(cache_dict):
    try:
        df = pd.DataFrame([{"query": k, "lat": v[0], "lon": v[1]} for k, v in cache_dict.items()])
        df.to_csv(GEOCODE_CACHE, index=False, encoding="utf-8-sig")
    except Exception:
        pass

@st.cache_data(show_spinner=False)
def geocode_query(query):
    if not GEOPY_OK: return None
    geolocator = Nominatim(user_agent="student-placement-app")
    time.sleep(1.0)  # × ×™××•×¡ ×œ-OSM
    try:
        loc = geolocator.geocode(query)
        if loc: return (loc.latitude, loc.longitude)
    except Exception:
        return None
    return None

def geocode_many(queries, country_hint="×™×©×¨××œ"):
    cache = load_geocode_cache()
    out = {}
    for q in queries:
        if not q: out[q] = (None, None); continue
        q_norm = f"{q}, {country_hint}" if country_hint and country_hint not in q else q
        if q_norm in cache: out[q] = cache[q_norm]; continue
        res = geocode_query(q_norm)
        if res is None: out[q] = (None, None)
        else:
            out[q] = (float(res[0]), float(res[1]))
            cache[q_norm] = out[q]
    save_geocode_cache(cache)
    return out

# =========================
# ××©×§×•×œ×•×ª × ×™×§×•×“
# =========================
W_DOMAIN_MAIN  = 2.0   # ×ª×—×•× ××•×¢×“×£ â†” ×ª×—×•× ×”×”×ª××—×•×ª
W_DOMAIN_MULTI = 1.0   # ×—×¤×™×¤×”/×”×›×œ×” ×œ×›×œ ×¢×¨×š × ×•×¡×£
W_CITY         = 1.2   # ×¢×™×¨ (× ×™×¨××•×œ)
DEFAULT_W_DISTANCE = 1.8
DEFAULT_MAX_KM     = 60

# =========================
# ×”×¢×œ××•×ª + ×¢××•×“ ×”×‘×™×ª
# =========================
st.markdown(
    """
<div class="hero">
  <h1>ğŸ“… ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ××™-××ª××™×-×œ</h1>
  <p>×”×¢×œ×• ×§×•×‘×¦×™ ×¡×˜×•×“× ×˜×™× ×•××ª×¨×™× (CSV/XLSX), ××™×¤×• ×¢××•×“×•×ª, ×—×©×‘×• ××¨×—×§ ×•×”×¤×¢×™×œ×• ×©×™×‘×•×¥ ×œ×¤×™ ×ª×—×•× + ×¢×™×¨ + ×§×™×¨×‘×” + ×§×™×‘×•×œ×ª.</p>
</div>
""", unsafe_allow_html=True)

with st.sidebar:
    st.header("×”×¢×œ××ª × ×ª×•× ×™×")
    up_students = st.file_uploader("×§×•×‘×¥ ×¡×˜×•×“× ×˜×™× (CSV/XLSX)", type=["csv","xlsx","xls"])
    up_sites    = st.file_uploader("×§×•×‘×¥ ××ª×¨×™×/××•×¡×“×•×ª (CSV/XLSX)", type=["csv","xlsx","xls"])

    # ×‘×—×™×¨×ª ×’×™×œ×™×•×Ÿ ×× Excel
    stu_df, stu_sheets = read_anytable(up_students)
    site_df, site_sheets = read_anytable(up_sites)

    if stu_sheets:
        sheet = st.selectbox("×’×™×œ×™×•×Ÿ ×¡×˜×•×“× ×˜×™× (Excel)", options=stu_sheets, index=0)
        stu_df, _ = read_anytable(up_students, sheet_name=sheet)
    if site_sheets:
        sheet = st.selectbox("×’×™×œ×™×•×Ÿ ××ª×¨×™× (Excel)", options=site_sheets, index=0)
        site_df, _ = read_anytable(up_sites, sheet_name=sheet)

    st.divider()
    st.subheader("××¨×—×§ (×§×™×¨×‘×”)")
    use_distance   = st.checkbox("×©×§×œ×•×œ ××¨×—×§ ×‘×¦×™×•×Ÿ", value=True)
    hard_limit_on  = st.checkbox("××œ ×ª×©×‘×¥ ××¢×‘×¨ ×œ×˜×•×•×— ××§×¡×™××œ×™", value=True)
    max_km         = st.slider("×˜×•×•×— ××§×¡×™××œ×™ (×§\"×)", 10, 200, DEFAULT_MAX_KM, 5)
    w_distance     = st.slider("××©×§×œ ×”××¨×—×§", 0.0, 5.0, DEFAULT_W_DISTANCE, 0.1)
    st.caption("×× ××™×Ÿ Lat/Lon ×‘×§×‘×¦×™× â€“ × ×‘×¦×¢ ×’×™××•×§×•×“ ×œ×¤×™ ×¢×™×¨/×›×ª×•×‘×ª (OSM) ×¢× ×§××©.")

# =========================
# Tabs
# =========================
tab_guide, tab_map, tab_data, tab_match, tab_export = st.tabs(["ğŸ“– ××“×¨×™×š", "ğŸ—ºï¸ ××™×¤×•×™ ×¢××•×“×•×ª", "ğŸ“¥ ×ª×¦×•×’×ª × ×ª×•× ×™×", "ğŸ§© ×©×™×‘×•×¥", "ğŸ“¤ ×™×™×¦×•×"])

# =========================
# ××“×¨×™×š
# =========================
with tab_guide:
    st.subheader("××“×¨×™×š ××œ× ×œ×©×™××•×©")
    st.markdown(f"""
1) **×”×¢×œ××ª ×§×‘×¦×™×**: ×”×¢×œ×• ×§×•×‘×¥ ×¡×˜×•×“× ×˜×™× ×•×§×•×‘×¥ ××ª×¨×™× (CSV/XLSX). ×× ×§×•×‘×¥ Excel â€“ ×‘×—×¨×• ×’×™×œ×™×•×Ÿ ×‘×¡×¨×’×œ ×”×™×× ×™.  
2) **××™×¤×•×™ ×¢××•×“×•×ª**: ×‘×˜××‘ *××™×¤×•×™ ×¢××•×“×•×ª* ×‘×—×¨×• ××™×œ×• ×¢××•×“×•×ª ××™×™×¦×’×•×ª:
   - ×¢×‘×•×¨ **×¡×˜×•×“× ×˜×™×**: ×ª\"×–, ×©× ×¤×¨×˜×™, ×©× ××©×¤×—×” (××• ×©× ××œ×), ×¢×™×¨ ××’×•×¨×™×, ×ª×—×•× ××•×¢×“×£, ×•×ª×—×•××™× ××‘×•×§×©×™× (×¨×™×‘×•×™ ×¢×¨×›×™×).
   - ×¢×‘×•×¨ **××ª×¨×™×**: ×©× ××ª×¨/××•×¡×“, ×¢×™×¨, ×ª×—×•× ×”×”×ª××—×•×ª, ×§×™×‘×•×œ×ª (×‘×¨×™×¨×ª ××—×“×œ 1 ×× ×œ× ×§×™×™×), (××•×¤×¦×™×•× ×œ×™) Lat/Lon, **×©× ×”××“×¨×™×š**.
3) **×©×§×œ×•×œ ××¨×—×§**: ×‘×¡×¨×’×œ ×”×™×× ×™ ××¤×©×¨ ×œ×”×¤×¢×™×œ ×¦×™×•×Ÿ ×§×™×¨×‘×” ×•/××• ×›×œ×œ ×§×©×™×— "×œ× ×œ×©×‘×¥ ××¢×œ {DEFAULT_MAX_KM} ×§\"×".  
   × ×•×¡×—×ª ×”××¨×—×§: `distance_score = w_distance * (1 - min(distance_km / max_km, 1))`.
4) **×©×™×‘×•×¥**: ×‘×˜××‘ *×©×™×‘×•×¥*â€”×”×¨×™×¦×•. ×”××œ×’×•×¨×™×ª× Greedy ×‘×•×—×¨ ×œ×›×œ ×¡×˜×•×“× ×˜/×™×ª ××ª ×”××ª×¨ ×‘×¢×œ ×”×¦×™×•×Ÿ ×”×’×‘×•×” ×‘×™×•×ª×¨ ×©× ×•×ª×¨×” ×‘×• ×§×™×‘×•×œ×ª.
5) **×ª×•×¦××•×ª**: ×ª×§×‘×œ×• ×˜×‘×œ×” ×¢× `student_id_num (×ª\"×–)`, `first_name`, `last_name`, `home_city`, `assigned_site`, `assigned_city`, `assigned_distance_km`, `match_percent`, `mentor_name`, `status`.  
6) **×™×¦×•×**: ×‘×˜××‘ *×™×™×¦×•×* × ×™×ª×Ÿ ×œ×”×•×¨×™×“ CSV ××• ×œ×©××•×¨ ×‘×©× `assignments.csv`.
""")

# =========================
# ××™×¤×•×™ ×¢××•×“×•×ª (×’××™×©!)
# =========================
with tab_map:
    if (up_students is None) or (up_sites is None) or (stu_df is None) or (site_df is None):
        st.warning("×”×¢×œ×• ×©× ×™ ×§×‘×¦×™× (×¡×˜×•×“× ×˜×™× ×•××ª×¨×™×) ×›×“×™ ×œ××¤×•×ª ×¢××•×“×•×ª.", icon="âš ï¸")
    else:
        st.subheader("××™×¤×•×™ ×©×“×•×ª â€“ ×¡×˜×•×“× ×˜×™×")
        s_cols = list(stu_df.columns)

        col_id_num = st.selectbox("×ª\"×– ×”×¡×˜×•×“× ×˜/×™×ª", options=s_cols)
        col_id     = st.selectbox("×¢××•×“×ª ××–×”×” ×¤× ×™××™ (××• ×”×©××™×¨×• ×¨×™×§ ×œ×™×¦×™×¨×” ××•×˜×•××˜×™×ª)", options=["(×œ×™×¦×•×¨ ××•×˜×•××˜×™×ª)"] + s_cols, index=0)
        col_fname  = st.selectbox("×©× ×¤×¨×˜×™ (××• ×‘×—×¨×• '××™×Ÿ')", options=["(××™×Ÿ)"] + s_cols, index=0)
        col_lname  = st.selectbox("×©× ××©×¤×—×” (××• ×‘×—×¨×• '××™×Ÿ')", options=["(××™×Ÿ)"] + s_cols, index=0)
        col_fullnm = st.selectbox("×©× ××œ× ×‘×•×“×“ (×× ×§×™×™×)", options=["(××™×Ÿ)"] + s_cols, index=0)
        col_city_s = st.selectbox("×¢×™×¨ ××’×•×¨×™×", options=s_cols)
        col_pref   = st.selectbox("×ª×—×•× ××•×¢×“×£ (×¢×¨×š ××—×“ ××• ×˜×§×¡×˜)", options=s_cols)
        col_domains= st.selectbox("×ª×—×•××™× ××‘×•×§×©×™× (×¨×™×‘×•×™ ×¢×¨×›×™× ××•×¤×¨×“×™× ×‘×¤×¡×™×§×™×/× ×§×•×“×”-×¤×¡×™×§/×§×•-× ×˜×•×™)", options=s_cols)

        # ×§×•××•×¨×“×™× ×˜×•×ª ×¡×˜×•×“× ×˜×™× (×œ× ×—×•×‘×”)
        col_s_lat  = st.selectbox("×¡×˜×•×“× ×˜×™× â€“ Latitude (×× ×§×™×™×)", options=["(××™×Ÿ)"] + s_cols, index=0)
        col_s_lon  = st.selectbox("×¡×˜×•×“× ×˜×™× â€“ Longitude (×× ×§×™×™×)", options=["(××™×Ÿ)"] + s_cols, index=0)

        st.divider()
        st.subheader("××™×¤×•×™ ×©×“×•×ª â€“ ××ª×¨×™×/××•×¡×“×•×ª")
        t_cols = list(site_df.columns)
        col_site   = st.selectbox("×©× ××ª×¨/××•×¡×“", options=t_cols)
        col_city_t = st.selectbox("×¢×™×¨ ××ª×¨/××•×¡×“", options=t_cols)
        col_domain = st.selectbox("×ª×—×•× ×”×”×ª××—×•×ª", options=t_cols)
        col_cap    = st.selectbox("×§×™×‘×•×œ×ª (×× ××™×Ÿ â€“ ×‘×—×¨×• '××™×Ÿ' ×•× ×—×©×‘ 1)", options=["(××™×Ÿ)"] + t_cols, index=0)
        col_mentor = st.selectbox("×©× ×”××“×¨×™×š/×” (×× ×§×™×™×)", options=["(××™×Ÿ)"] + t_cols, index=0)

        # ×§×•××•×¨×“×™× ×˜×•×ª ××ª×¨×™× (×œ× ×—×•×‘×”)
        col_t_lat = st.selectbox("××ª×¨×™× â€“ Latitude (×× ×§×™×™×)", options=["(××™×Ÿ)"] + t_cols, index=0)
        col_t_lon = st.selectbox("××ª×¨×™× â€“ Longitude (×× ×§×™×™×)", options=["(××™×Ÿ)"] + t_cols, index=0)

        # ×©××™×¨×” ×œ-session_state
        st.session_state["map"] = {
            "stu": dict(id_num=col_id_num, id=col_id, fname=col_fname, lname=col_lname, fullnm=col_fullnm,
                        city=col_city_s, pref=col_pref, doms=col_domains,
                        lat=col_s_lat, lon=col_s_lon),
            "site": dict(name=col_site, city=col_city_t, domain=col_domain,
                         cap=col_cap, lat=col_t_lat, lon=col_t_lon, mentor=col_mentor)
        }
        st.success("×”××™×¤×•×™ × ×©××¨. ×¢×‘×¨×• ×œ'ğŸ“¥ ×ª×¦×•×’×ª × ×ª×•× ×™×' ×œ×‘×“×™×§×” ××• ×œ'ğŸ§© ×©×™×‘×•×¥' ×œ×”×¨×¦×”.")

# =========================
# ×ª×¦×•×’×ª × ×ª×•× ×™×
# =========================
with tab_data:
    if (up_students is None) or (up_sites is None) or (stu_df is None) or (site_df is None):
        st.info("×”×¢×œ×• ×§×‘×¦×™× ×•××¤×• ×¢××•×“×•×ª ×‘×˜××‘×™× ×”×§×•×“××™×.")
    else:
        cA, cB = st.columns(2)
        with cA:
            st.markdown("**×¡×˜×•×“× ×˜×™× (Raw):**")
            st.dataframe(stu_df, use_container_width=True, height=320)
        with cB:
            st.markdown("**××ª×¨×™×/××•×¡×“×•×ª (Raw):**")
            st.dataframe(site_df, use_container_width=True, height=320)

# =========================
# ×©×™×‘×•×¥ (×›×•×œ×œ ××¨×—×§)
# =========================
with tab_match:
    if (up_students is None) or (up_sites is None) or ("map" not in st.session_state):
        st.warning("×¦×¨×™×š ×œ×”×¢×œ×•×ª ×§×‘×¦×™× ×•×œ×‘×¦×¢ ××™×¤×•×™ ×¢××•×“×•×ª ×‘×˜××‘ 'ğŸ—ºï¸ ××™×¤×•×™ ×¢××•×“×•×ª'.", icon="âš ï¸")
    else:
        M = st.session_state["map"]
        mS, mT = M["stu"], M["site"]

        # --- ×”×›× ×”: ×¡×˜×•×“× ×˜×™×
        stu = stu_df.copy()
        # ××–×”×” ×¤× ×™××™
        if mS["id"] == "(×œ×™×¦×•×¨ ××•×˜×•××˜×™×ª)":
            stu["student_id"] = [f"S{i+1:03d}" for i in range(len(stu))]
        else:
            stu["student_id"] = stu[mS["id"]].astype(str).fillna("").replace("", "S-NA").values

        # ×ª"×– (×—×•×‘×” ×œ×¤×œ×˜)
        stu["student_id_num"] = stu[mS["id_num"]].astype(str).fillna("").str.strip()

        # ×©× ××œ×/×¤×¨×˜×™/××©×¤×—×” + ×¢×™×¨
        if mS["fullnm"] != "(××™×Ÿ)":
            full = stu[mS["fullnm"]].astype(str).fillna("").str.strip()
            # × × ×¡×” ×œ×¤×¦×œ ×œ×©× ×¤×¨×˜×™/××©×¤×—×” ×× ×™×© ×¨×•×•×—
            parts = full.str.split(r"\s+", n=1, expand=True)
            stu["first_name"] = parts[0].fillna("")
            stu["last_name"]  = parts[1].fillna("")
        else:
            stu["first_name"] = stu[mS["fname"]].astype(str).fillna("").str.strip() if mS["fname"]!="(××™×Ÿ)" else ""
            stu["last_name"]  = stu[mS["lname"]].astype(str).fillna("").str.strip() if mS["lname"]!="(××™×Ÿ)" else ""
            if isinstance(stu["first_name"], str) or isinstance(stu["last_name"], str):
                # ×× ×œ× × ×‘×—×¨×• ×¢××•×“×•×ª â€” × ×©×ª××© ×‘××–×”×”
                stu["first_name"] = stu["first_name"] if not isinstance(stu["first_name"], str) else ""
                stu["last_name"]  = stu["last_name"] if not isinstance(stu["last_name"], str) else ""
        stu["home_city"] = stu[mS["city"]].astype(str).fillna("").str.strip()

        # ×©×“×•×ª ×—×•×‘×”
        for req in [mS["city"], mS["pref"], mS["doms"]]:
            if req not in stu.columns:
                st.error(f"×¢××•×“×ª ×¡×˜×•×“× ×˜×™× ×—×¡×¨×”: {req}")
                st.stop()

        # --- ×”×›× ×”: ××ª×¨×™×
        site = site_df.copy()
        for req in [mT["name"], mT["city"], mT["domain"]]:
            if req not in site.columns:
                st.error(f"×¢××•×“×ª ××ª×¨×™× ×—×¡×¨×”: {req}")
                st.stop()

        if mT["cap"] == "(××™×Ÿ)" or (mT["cap"] not in site.columns):
            site["capacity"] = 1
        else:
            site["capacity"] = pd.to_numeric(site[mT["cap"]], errors="coerce").fillna(1).astype(int).clip(lower=0)
        site = site[site["capacity"] > 0]

        # --- ×¢×™×‘×•×“ ××“×¨×™×š
        mentor_col_exists = mT["mentor"] != "(××™×Ÿ)" and (mT["mentor"] in site.columns)

        def union_domains(series) -> str:
            acc = set()
            for v in series.dropna(): acc |= split_multi(v)
            return ", ".join(sorted(acc)) if acc else ""

        def first_non_empty(series) -> str:
            for v in series:
                if _strip(v): return v
            return ""

        agg_dict = {
            mT["city"]: first_non_empty,
            mT["domain"]: union_domains
        }
        if mentor_col_exists:
            agg_dict[mT["mentor"]] = first_non_empty

        sites_agg = site.groupby(mT["name"], as_index=False).agg(agg_dict)
        site_capacity = site.groupby(mT["name"])["capacity"].sum().to_dict()
        site_city_map = pd.Series(sites_agg[mT["city"]].values, index=sites_agg[mT["name"]].astype(str)).to_dict()
        site_domain_map = pd.Series(sites_agg[mT["domain"]].values, index=sites_agg[mT["name"]].astype(str)).to_dict()
        site_mentor_map = {}
        if mentor_col_exists:
            site_mentor_map = pd.Series(sites_agg[mT["mentor"]].values, index=sites_agg[mT["name"]].astype(str)).to_dict()

        # --- Lat/Lon ×¢××•×“×•×ª (××•×¤×¦×™×•× ×œ×™)
        def get_opt_col(df, colname):
            return None if (colname == "(××™×Ÿ)" or (colname not in df.columns)) else colname

        s_lat_col = get_opt_col(stu, mS["lat"]); s_lon_col = get_opt_col(stu, mS["lon"])
        t_lat_col = get_opt_col(site, mT["lat"]); t_lon_col = get_opt_col(site, mT["lon"])

        # --- ×§×•××•×¨×“×™× ×˜×•×ª ×¡×˜×•×“× ×˜×™×
        stu_coords = {}
        if s_lat_col and s_lon_col:
            for _, r in stu.iterrows():
                lat = pd.to_numeric(r[s_lat_col], errors="coerce"); lon = pd.to_numeric(r[s_lon_col], errors="coerce")
                stu_coords[r["student_id"]] = (lat if pd.notna(lat) else None, lon if pd.notna(lon) else None)
        elif use_distance and GEOPY_OK:
            cities = sorted(set(_strip(c) for c in stu[mS["city"]].fillna("").astype(str)))
            city2xy = geocode_many(cities, country_hint="×™×©×¨××œ")
            for _, r in stu.iterrows():
                stu_coords[r["student_id"]] = city2xy.get(_strip(r[mS["city"]]), (None, None))
        else:
            for _, r in stu.iterrows(): stu_coords[r["student_id"]] = (None, None)

        # --- ×§×•××•×¨×“×™× ×˜×•×ª ××ª×¨×™×
        site_coords = {}
        if t_lat_col and t_lon_col:
            for _, r in site.iterrows():
                sname = _strip(r[mT["name"]])
                lat = pd.to_numeric(r[t_lat_col], errors="coerce"); lon = pd.to_numeric(r[t_lon_col], errors="coerce")
                site_coords[sname] = (lat if pd.notna(lat) else None, lon if pd.notna(lon) else None)
        elif use_distance and GEOPY_OK:
            queries = []
            for _, r in sites_agg.iterrows():
                q = _strip(r[mT["name"]]); c = _strip(r[mT["city"]])
                queries.append(f"{q}, {c}" if c else q)
            q2xy = geocode_many(sorted(set(queries)), country_hint="×™×©×¨××œ")
            for _, r in sites_agg.iterrows():
                q = _strip(r[mT["name"]]); c = _strip(r[mT["city"]])
                site_coords[q] = q2xy.get(f"{q}, {c}" if c else q, (None, None))
        else:
            for _, r in sites_agg.iterrows():
                site_coords[_strip(r[mT["name"]])] = (None, None)

        # --- × ×™×§×•×“ ×‘×¡×™×¡ + ×‘×•× ×•×¡ ××¨×—×§
        def base_match_score(stu_row, site_name):
            score = 0.0
            # ×ª×—×•×
            pref_set = split_multi(stu_row.get(mS["pref"], ""))
            dom_site = split_multi(site_domain_map.get(site_name, ""))
            if not dom_site:
                dom_raw = site_domain_map.get(site_name, "")
                dom_site = {normalize_text(dom_raw)} if dom_raw else set()
            if pref_set and dom_site:
                c1 = overlap_count(pref_set, dom_site)
                if c1 > 0: score += W_DOMAIN_MAIN + W_DOMAIN_MULTI * max(0, c1-1)
            # ×ª×—×•××™× × ×•×¡×¤×™×
            all_set = split_multi(stu_row.get(mS["doms"], ""))
            if all_set and dom_site:
                c2 = overlap_count(all_set, dom_site)
                if c2 > 0: score += W_DOMAIN_MULTI * c2
            # ×¢×™×¨
            s_city  = normalize_text(stu_row.get(mS["city"], ""))
            t_city  = normalize_text(site_city_map.get(site_name, ""))
            if s_city and t_city and (s_city == t_city or s_city in t_city or t_city in s_city):
                score += W_CITY
            return score

        def distance_km_for(sid, site_name):
            lat1, lon1 = stu_coords.get(sid, (None, None))
            lat2, lon2 = site_coords.get(site_name, (None, None))
            return haversine_km(lat1, lon1, lat2, lon2)

        def distance_bonus(dist_km):
            if (not use_distance) or dist_km is None: return 0.0
            proximity = max(0.0, 1.0 - min(dist_km / max_km, 1.0))
            return w_distance * proximity

        # --- ×¦×™×•× ×™× ×œ×›×œ ×¦××“ --->
        rows = []
        for _, srow in stu.iterrows():
            sid = srow["student_id"]; sname_first = srow.get("first_name","")
            for site_name in sites_agg[mT["name"]].astype(str):
                base = base_match_score(srow, site_name)
                dkm = distance_km_for(sid, site_name)
                # ×›×œ×œ ×§×©×™×— ××¨×—×§
                if hard_limit_on and use_distance and (dkm is None or dkm > max_km):
                    total = -1e9
                else:
                    total = base + distance_bonus(dkm)
                rows.append((sid, site_name, total, site_city_map.get(site_name, ""), None if dkm is None else round(dkm,1)))
        scores = pd.DataFrame(rows, columns=["student_id","site_name","score","site_city","distance_km"])

        # --- Top-3 ×ª×¦×•×’×” ××”×™×¨×”
        st.markdown("##### Top-3 ×”×ª×××•×ª ×œ×›×œ ×¡×˜×•×“× ×˜/×™×ª (×›×•×œ×œ ×¢×™×¨ ×•××¨×—×§)")
        top3 = scores.sort_values(["student_id","score"], ascending=[True, False]).groupby("student_id").head(3)
        st.dataframe(top3, use_container_width=True, height=300)

        # --- × ×¨××•×œ ×œ××—×•×–×™× ×œ×›×œ ×¡×˜×•×“× ×˜ (0â€“100) ×¢×œ ×‘×¡×™×¡ ×”×˜×•×•×— ×”××™×©×™
        scores_norm = []
        for sid, grp in scores.groupby("student_id"):
            g = grp.copy()
            feasible = g[g["score"] > -1e8]["score"]
            if len(feasible) == 0:
                g["match_percent"] = 0.0
            else:
                smin, smax = feasible.min(), feasible.max()
                if smax - smin <= 1e-9:
                    g["match_percent"] = 100.0  # ×›×œ ×”××ª×¨×™× ×©×•×•×™× ××• ×¦×™×•×Ÿ ×™×—×™×“
                else:
                    g["match_percent"] = ((g["score"] - smin) / (smax - smin) * 100.0).clip(lower=0, upper=100)
            scores_norm.append(g)
        scores = pd.concat(scores_norm, ignore_index=True)

        # --- ×©×™×‘×•×¥ Greedy ---
        assignments, cap_left = [], site_capacity.copy()
        # ××¤×•×ª ×¢×–×¨ ×œ×©××•×ª
        stu_lookup = stu.set_index("student_id")[["student_id_num","first_name","last_name","home_city"]].to_dict(orient="index")

        for sid, grp in scores.groupby("student_id"):
            grp = grp.sort_values("score", ascending=False)
            chosen_site = "×œ×œ× ×©×™×‘×•×¥"
            chosen_score = 0.0
            chosen_city, chosen_dist, chosen_percent = "", None, 0.0
            for _, r in grp.iterrows():
                if r["score"] < -1e8:  # × ×¤×¡×œ ×‘×’×œ×œ ××¨×—×§
                    continue
                site_nm = r["site_name"]
                if cap_left.get(site_nm, 0) > 0:
                    chosen_site = site_nm
                    chosen_score = float(r["score"])
                    chosen_percent = float(round(float(r["match_percent"]), 1))
                    chosen_city = site_city_map.get(site_nm, _strip(r.get("site_city","")))
                    chosen_dist = r.get("distance_km", None)
                    cap_left[site_nm] -= 1
                    break

            srec = stu_lookup.get(sid, {})
            mentor = site_mentor_map.get(chosen_site, "") if chosen_site != "×œ×œ× ×©×™×‘×•×¥" else ""
            assignments.append({
                "student_id_num": srec.get("student_id_num",""),
                "first_name": srec.get("first_name",""),
                "last_name": srec.get("last_name",""),
                "home_city": srec.get("home_city",""),
                "assigned_site": chosen_site,
                "assigned_city": chosen_city,
                "assigned_distance_km": (None if pd.isna(chosen_dist) or chosen_dist is None else float(chosen_dist)),
                "match_percent": chosen_percent,
                "mentor_name": mentor,
                "status": "×©×•×‘×¥" if chosen_site != "×œ×œ× ×©×™×‘×•×¥" else "×××ª×™×Ÿ"
            })

        asg = pd.DataFrame(assignments)

        st.success(f"×©×•×‘×¦×• {(asg['status']=='×©×•×‘×¥').sum()} â€¢ ×××ª×™× ×™× {(asg['status']=='×××ª×™×Ÿ').sum()}")
        st.dataframe(asg, use_container_width=True, height=420)

        cA, cB, cC = st.columns(3)
        with cA: st.metric("×¡×”\"×› ×¡×˜×•×“× ×˜×™×", len(asg))
        with cB: st.metric("×©×•×‘×¦×•", int((asg["status"]=="×©×•×‘×¥").sum()))
        with cC: st.metric("×××ª×™× ×™×", int((asg["status"]=="×××ª×™×Ÿ").sum()))

        st.session_state["assignments_df"] = asg

# =========================
# ×™×™×¦×•×
# =========================
with tab_export:
    st.subheader("×”×•×¨×“×”/×©××™×¨×”")
    if isinstance(st.session_state.get("assignments_df"), pd.DataFrame):
        out = st.session_state["assignments_df"].copy()
        # ×¡×“×¨ ×•×¢××•×“×•×ª ×œ×¤×œ×˜ ×”×¡×•×¤×™
        cols = ["student_id_num","first_name","last_name","home_city",
                "assigned_site","assigned_city","assigned_distance_km","match_percent","mentor_name","status"]
        out = out[cols]
        st.dataframe(out, use_container_width=True, height=340)
        fname = f"assignments_{datetime.now().strftime('%Y%m%d_%H%M')}.csv"
        bio, _ = bytes_for_download(out, fname)
        st.download_button("â¬‡ï¸ ×”×•×¨×“×ª CSV", bio, file_name=fname, mime="text/csv", use_container_width=True)

        if st.checkbox("×©××•×¨ ×’× ×‘×©× ×”×§×‘×•×¢ assignments.csv"):
            try:
                out.to_csv("assignments.csv", index=False, encoding="utf-8-sig")
                st.success("× ×©××¨ assignments.csv ×‘×ª×™×§×™×™×ª ×”××¤×œ×™×§×¦×™×”.")
            except Exception as e:
                st.error(f"×©×’×™××ª ×©××™×¨×”: {e}")
    else:
        st.info("××™×Ÿ ×¢×“×™×™×Ÿ ×ª×•×¦××•×ª â€“ ×”×¨×™×¦×• ×©×™×‘×•×¥ ×‘×˜××‘ \"ğŸ§© ×©×™×‘×•×¥\".")
