# matcher_streamlit_beauty_rtl_v7_fixed.py
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from dataclasses import dataclass
from typing import Optional, Any, List, Dict
import re

# =========================
# ×§×•× ×¤×™×’×•×¨×¦×™×” ×›×œ×œ×™×ª
# =========================
# ====== ×§×•× ×¤×™×’×•×¨×¦×™×” ×›×œ×œ×™×ª ======
st.set_page_config(page_title="××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”", layout="wide")

# ====== CSS â€“ ×¢×™×¦×•×‘ + RTL + David ======
st.markdown("""
<style>
:root{
  --bg-1:#e0f7fa; --bg-2:#ede7f6; --bg-3:#fff3e0; --bg-4:#fce4ec; --bg-5:#e8f5e9;
  --ink:#0f172a; --primary:#9b5de5; --primary-700:#f15bb5; --ring:rgba(155,93,229,.35);
}

/* ×’×•×¤×Ÿ David â€“ ×’×œ×•×‘×œ×™ + ×›×œ ×¨×›×™×‘×™ ×”×˜×•×¤×¡ ×©×œ Streamlit */
html, body, [class*="css"], .stApp, .main, [data-testid="stSidebar"],
.stMarkdown, .stText, .stCaption,
.stButton button,
.stTextInput input, .stNumberInput input,
.stTextArea textarea,
.stSelectbox [data-baseweb="select"] *, .stMultiSelect [data-baseweb="select"] *,
.stDateInput input, .stTimeInput input,
input, textarea, select {
  font-family: "David", "Noto Sans Hebrew", "Segoe UI", system-ui, sans-serif !important;
}

/* ×›×™×•×•×Ÿ ×›×ª×™×‘×” ×•×™×™×©×•×¨ ×œ×™××™×Ÿ */
.stApp,.main,[data-testid="stSidebar"]{ direction:rtl; text-align:right; }
label,.stMarkdown,.stText,.stCaption{ text-align:right!important; }

/* placeholder ×‘×’×•×¤×Ÿ David */
.stTextInput input::placeholder,
.stTextArea textarea::placeholder,
input::placeholder, textarea::placeholder {
  font-family: "David", "Noto Sans Hebrew", "Segoe UI", system-ui, sans-serif !important;
  opacity:.8;
}

/* ×¨×§×¢ ×•Ö¾Container */
[data-testid="stAppViewContainer"]{
  background:
    radial-gradient(1200px 600px at 15% 10%, var(--bg-2) 0%, transparent 70%),
    radial-gradient(1000px 700px at 85% 20%, var(--bg-3) 0%, transparent 70%),
    radial-gradient(900px 500px at 50% 80%, var(--bg-4) 0%, transparent 70%),
    radial-gradient(700px 400px at 10% 85%, var(--bg-5) 0%, transparent 70%),
    linear-gradient(135deg, var(--bg-1) 0%, #ffffff 100%) !important;
  color: var(--ink);
}
.main .block-container{
  background: rgba(255,255,255,.78);
  backdrop-filter: blur(10px);
  border:1px solid rgba(15,23,42,.08);
  box-shadow:0 15px 35px rgba(15,23,42,.08);
  border-radius:24px;
  padding:2.5rem;
  margin-top:1rem;
}

/* ×›×•×ª×¨×•×ª */
h1,h2,h3,.stMarkdown h1,.stMarkdown h2{
  text-align:center; letter-spacing:.5px; text-shadow:0 1px 2px rgba(255,255,255,.7);
  font-weight:700; color:#222; margin-bottom:1rem;
}

/* ×›×¤×ª×•×¨ ×¨××©×™ */
.cta-wrap { max-width: 620px; margin: 0 auto; }
.cta-wrap > div > button{
  background:linear-gradient(90deg,var(--primary) 0%,var(--primary-700) 100%)!important;
  color:#fff!important; border:none!important; border-radius:24px!important;
  padding:1.4rem 2rem!important; font-size:1.25rem!important; font-weight:700!important;
  box-shadow:0 10px 22px var(--ring)!important; transition:all .15s ease!important; width:100%!important;
}
.cta-wrap > div > button:hover{ transform:translateY(-3px) scale(1.02); filter:brightness(1.07); }
.cta-wrap > div > button:focus{ outline:none!important; box-shadow:0 0 0 4px var(--ring)!important; }
</style>
""", unsafe_allow_html=True)

# ====== ×›×•×ª×¨×ª ======
st.markdown("<h1>××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”</h1>", unsafe_allow_html=True)

st.markdown("<p style='text-align:center;color:#475569;margin-top:-8px;'>×›××Ÿ ××©×‘×¦×™× ×¡×˜×•×“× ×˜×™× ×œ××§×•××•×ª ×”×ª××—×•×ª ×‘×§×œ×•×ª, ×‘×”×ª×‘×¡×¡ ×¢×œ ×ª×—×•×, ×¢×™×¨ ×•×‘×§×©×•×ª.</p>", unsafe_allow_html=True)

# ====== ××•×“×œ × ×™×§×•×“ ======
@dataclass
class Weights:
    w_field: float   = 0.50   # ×ª×—×•× ×”×”×ª××—×•×ª
    w_city: float    = 0.05   # ××–×•×¨ / ×¢×™×¨
    w_special: float = 0.45   # ×‘×§×©×•×ª ××™×•×—×“×•×ª

# ×¢××•×“×•×ª ×¡×˜×•×“× ×˜×™×
STU_COLS = {
    "id": ["××¡×¤×¨ ×ª×¢×•×“×ª ×–×”×•×ª", "×ª×¢×•×“×ª ×–×”×•×ª", "×ª\"×–", "×ª×–", "×ª×¢×•×“×ª ×–×”×•×ª ×”×¡×˜×•×“× ×˜"],
    "first": ["×©× ×¤×¨×˜×™"],
    "last": ["×©× ××©×¤×—×”"],
    "address": ["×›×ª×•×‘×ª", "×›×ª×•×‘×ª ×”×¡×˜×•×“× ×˜", "×¨×—×•×‘"],
    "city": ["×¢×™×¨ ××’×•×¨×™×", "×¢×™×¨"],
    "phone": ["×˜×œ×¤×•×Ÿ", "××¡×¤×¨ ×˜×œ×¤×•×Ÿ"],
    "email": ["×“×•×\"×œ", "×“×•××´×œ", "××™××™×™×œ", "×›×ª×•×‘×ª ××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ"],
    "preferred_field": ["×ª×—×•× ××•×¢×“×£","×ª×—×•××™× ××•×¢×“×¤×™×"],
    "special_req": ["×‘×§×©×” ××™×•×—×“×ª"],
    "partner": ["×‘×Ÿ/×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ\\×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ/×‘×ª ×–×•×’", "×‘×Ÿ\\×‘×ª ×–×•×’"]
}

# ×¢××•×“×•×ª ××ª×¨×™×
SITE_COLS = {
    "name": ["××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”", "××•×¡×“", "×©× ××•×¡×“ ×”×”×ª××—×•×ª", "×©× ×”××•×¡×“", "××•×¡×“ ×”×”×›×©×¨×”"],
    "field": ["×ª×—×•× ×”×”×ª××—×•×ª", "×ª×—×•× ×”×ª××—×•×ª"],
    "street": ["×¨×—×•×‘"],
    "city": ["×¢×™×¨"],
    "capacity": ["××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜", "×§×™×‘×•×œ×ª"],
    "sup_first": ["×©× ×¤×¨×˜×™"],
    "sup_last": ["×©× ××©×¤×—×”"],
    "phone": ["×˜×œ×¤×•×Ÿ"],
    "email": ["××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ", "×“×•×\"×œ", "×“×•××´×œ"],
    "review": ["×—×•×•×ª ×“×¢×ª ××“×¨×™×š"]
}

def pick_col(df: pd.DataFrame, options: List[str]) -> Optional[str]:
    for opt in options:
        if opt in df.columns: return opt
    return None

# ----- ×§×¨×™××ª ×§×‘×¦×™× -----
def read_any(uploaded) -> pd.DataFrame:
    name = (uploaded.name or "").lower()
    if name.endswith(".csv"):
        return pd.read_csv(uploaded, encoding="utf-8-sig")
    if name.endswith((".xlsx",".xls")):
        return pd.read_excel(uploaded)
    return pd.read_csv(uploaded, encoding="utf-8-sig")

def normalize_text(x: Any) -> str:
    return (str(x or "")).strip()

# ----- ×¡×˜×•×“× ×˜×™× -----
def resolve_students(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["stu_id"]    = out[pick_col(out, STU_COLS["id"])]
    out["stu_first"] = out[pick_col(out, STU_COLS["first"])]
    out["stu_last"]  = out[pick_col(out, STU_COLS["last"])]

    city_col = pick_col(out, STU_COLS["city"]) or pick_col(out, STU_COLS["address"])
    out["stu_city"]  = out[city_col] if city_col else ""

    pref_col = pick_col(out, ["×ª×—×•××™× ××•×¢×“×¤×™×"]) or pick_col(out, STU_COLS["preferred_field"])
    out["stu_pref"] = out[pref_col] if pref_col else ""

    out["stu_req"]  = out[pick_col(out, STU_COLS["special_req"])] if pick_col(out, STU_COLS["special_req"]) else ""

    for c in ["stu_id","stu_first","stu_last","stu_city","stu_pref","stu_req"]:
        out[c] = out[c].apply(normalize_text)
    return out

# ----- ××ª×¨×™× -----
def resolve_sites(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["site_name"]  = out[pick_col(out, SITE_COLS["name"])]
    out["site_field"] = out[pick_col(out, SITE_COLS["field"])]
    out["site_city"]  = out[pick_col(out, SITE_COLS["city"])]

    cap_col = pick_col(out, SITE_COLS["capacity"])
    out["site_capacity"] = pd.to_numeric(out[cap_col], errors="coerce").fillna(1).astype(int) if cap_col else 1
    out["capacity_left"] = out["site_capacity"].astype(int)

    sup_first = pick_col(out, SITE_COLS["sup_first"])
    sup_last  = pick_col(out, SITE_COLS["sup_last"])
    out["×©× ×”××“×¨×™×š"] = ""
    if sup_first or sup_last:
        ff = out[sup_first] if sup_first else ""
        ll = out[sup_last]  if sup_last else ""
        out["×©× ×”××“×¨×™×š"] = (ff.astype(str) + " " + ll.astype(str)).str.strip()

    for c in ["site_name","site_field","site_city","×©× ×”××“×¨×™×š"]:
        out[c] = out[c].apply(normalize_text)
    return out

# ====== ×¢×–×¨ ×œ× ×™×§×•×“ ======

# ××™×œ×•×Ÿ ××™×œ×™× × ×¨×“×¤×•×ª/× ×¨××•×œ ××•×©×’×™× (××¤×©×¨ ×œ×”×¨×—×™×‘ ×‘×§×œ×•×ª)
SYNONYMS = {
    "×‘×¨×™××•×ª ×”× ×¤×©": {"×‘×¨×™××•×ª", "× ×¤×©", "×¤×¡×™×›×™××˜×¨×™×”", "×”×ª××›×¨×•×™×•×ª"},
    "×—×™× ×•×š ××™×•×—×“": {"×—×™× ×•×š", "××™×•×—×“", "×œ×§×•×™×•×ª", "×©×™×œ×•×‘"},
    "×¨×•×•×—×”": {"×¨×•×•×—×”", "×©×™×¨×•×ª×™ ×¨×•×•×—×”", "××—×œ×§×ª ×¨×•×•×—×”"},
    "×™×œ×“×™× ×•× ×•×¢×¨": {"×™×œ×“×™×", "× ×•×¢×¨", "× ×•×¢×¨ ×‘×¡×™×›×•×Ÿ"},
    "×‘×¨×™××•×ª": {"×‘×¨×™××•×ª", "×¨×¤×•××”", "×‘×™×ª ×—×•×œ×™×", "×§×”×™×œ×” ×¨×¤×•××™×ª"},
    "××©×¤×—×”": {"××©×¤×—×”", "×”×•×¨×•×ª"},
    "× ×©×™×": {"× ×©×™×", "××œ×™××•×ª ×‘××©×¤×—×”"},
    "×©×™×§×•×": {"×©×™×§×•×", "×©×™×§×•××™"},
    "×§×”×™×œ×”": {"×§×”×™×œ×”", "×¢×™×¨", "××¨×›×– ×§×”×™×œ×ª×™"},
}

def expand_with_synonyms(tokens: List[str]) -> List[str]:
    out = set(tokens)
    for canon, syns in SYNONYMS.items():
        if canon in tokens or any(s in tokens for s in syns):
            out.add(canon)
            out.update(syns)
    return list(out)

CITY_REGION: Dict[str, str] = {
    "×ª×œ ××‘×™×‘": "××¨×›×–", "×¨××ª ×’×Ÿ": "××¨×›×–", "×’×‘×¢×ª×™×™×": "××¨×›×–",
    "×¤×ª×— ×ª×§×•×•×”": "××¨×›×–", "×¨××©×•×Ÿ ×œ×¦×™×•×Ÿ": "××¨×›×–", "× ×ª× ×™×”": "×©×¨×•×Ÿ",
    "×¨×¢× × ×”": "×©×¨×•×Ÿ", "×›×¤×¨ ×¡×‘×": "×©×¨×•×Ÿ",
    "×—×™×¤×”": "×¦×¤×•×Ÿ", "×§×¨×™×•×ª": "×¦×¤×•×Ÿ", "× ×”×¨×™×”": "×¦×¤×•×Ÿ", "×¢×›×•": "×¦×¤×•×Ÿ", "×¦×¤×ª": "×¦×¤×•×Ÿ", "×˜×‘×¨×™×”": "×¦×¤×•×Ÿ",
    "××©×“×•×“": "×“×¨×•×", "××©×§×œ×•×Ÿ": "×“×¨×•×", "×‘××¨ ×©×‘×¢": "×“×¨×•×",
    "×¨×—×•×‘×•×ª": "×©×¤×œ×”"
}

NEIGHBOR = {
    "××¨×›×–": {"×©×¨×•×Ÿ", "×©×¤×œ×”"},
    "×©×¨×•×Ÿ": {"××¨×›×–", "×¦×¤×•×Ÿ"},
    "×¦×¤×•×Ÿ": {"×©×¨×•×Ÿ"},
    "×©×¤×œ×”": {"××¨×›×–", "×“×¨×•×"},
    "×“×¨×•×": {"×©×¤×œ×”"},
}

SPLIT_RE = re.compile(r"[;,/|+]+|\s{2,}")

def _norm(s: Any) -> str:
    return (str(s or "")).strip().lower()

def _tokenize_field(s: str) -> List[str]:
    s = _norm(s)
    s = re.sub(r"[^×-×ªa-z0-9\s/,+-]", " ", s)
    parts = [p for p in SPLIT_RE.split(s) if p]
    parts = expand_with_synonyms(parts)
    return parts

def jaccard(a: List[str], b: List[str]) -> float:
    A, B = set(a), set(b)
    if not A or not B: return 0.0
    inter = len(A & B)
    union = len(A | B)
    return inter/union if union else 0.0

def best_pref_similarity(stu_pref_text: str, site_field_text: str) -> float:
    """
    ×ª×•××š ×‘××¡×¤×¨ ×ª×—×•××™× ××•×¢×“×¤×™× ×œ×¡×˜×•×“× ×˜ (××•×¤×¨×“×™× ×‘×¤×¡×™×§×™×/× ×§×•×“×” ×¤×¡×™×§/×§×• × ×˜×•×™/×¨×•×•×—×™× ××¨×•×‘×™×).
    ××—×–×™×¨ ××ª ×”×“××™×•×Ÿ ×”××§×¡×™××œ×™ ×œ××ª×¨.
    """
    if not stu_pref_text or not site_field_text:
        return 0.0
    # ×¤×™×¦×•×œ ×ª×—×•××™ ×¡×˜×•×“× ×˜
    raw = [x for x in re.split(r"[;,/|]+", stu_pref_text) if x.strip()]
    site_tokens = _tokenize_field(site_field_text)
    best = 0.0
    for pref in raw if raw else [stu_pref_text]:
        pref_tokens = _tokenize_field(pref)
        sim = jaccard(pref_tokens, site_tokens)
        if sim > best:
            best = sim
    return best

def domain_score(stu_pref_text: str, site_field_text: str) -> float:
    sim = best_pref_similarity(stu_pref_text, site_field_text)  # 0..1
    return 100.0 * sim

def city_score(stu_city: str, site_city: str) -> float:
    s_c = normalize_text(stu_city)
    t_c = normalize_text(site_city)
    if not s_c or not t_c: return 50.0  # ×‘×¨×™×¨×ª ××—×“×œ ×œ× ×™×“×•×¢
    if s_c == t_c: return 100.0
    s_r = CITY_REGION.get(s_c, "")
    t_r = CITY_REGION.get(t_c, "")
    if s_r and t_r:
        if s_r == t_r: return 75.0
        if t_r in NEIGHBOR.get(s_r, set()): return 55.0
        return 35.0
    return 45.0

def special_score(stu_req: str, same_city: bool) -> float:
    """
    ×‘×•× ×•×¡ × ×§×•×“×ª×™: '×§×¨×•×‘', '×§×¨×‘×”', '×‘×™×ª' -> ××©×§×œ ×’×‘×•×” ×™×•×ª×¨.
    × ×™×ª×Ÿ ×œ×”×¨×—×™×‘ ×¢× ××™×œ×•×ª ××¤×ª×— × ×•×¡×¤×•×ª.
    """
    txt = _norm(stu_req)
    if not txt: return 50.0  # × ×™×™×˜×¨×œ×™
    if "×§×¨×•×‘" in txt or "×§×¨×‘×”" in txt or "×‘×™×ª" in txt:
        return 100.0 if same_city else 65.0
    return 60.0

# ====== ×—×™×©×•×‘ ×¦×™×•×Ÿ ×’×•×œ××™ ======
def raw_score(stu: pd.Series, site: pd.Series, W: Weights) -> float:
    same_city = (_norm(stu.get("stu_city")) and _norm(site.get("site_city")) and
                 _norm(stu.get("stu_city")) == _norm(site.get("site_city")))
    f = domain_score(stu.get("stu_pref",""), site.get("site_field",""))   # 0..100 ×¨×¦×™×£
    c = city_score(stu.get("stu_city",""), site.get("site_city",""))      # 0..100
    s = special_score(stu.get("stu_req",""), same_city)                    # 0..100
    score = W.w_field*f + W.w_city*c + W.w_special*s                       # 0..100
    return float(np.clip(score, 0, 100))

# ====== ×©×™×‘×•×¥ ×¢× × ×•×¨××œ×™×–×¦×™×” ×™×—×¡×™×ª ×œ×›×œ ×¡×˜×•×“× ×˜ ======
def greedy_match(students_df: pd.DataFrame, sites_df: pd.DataFrame, W: Weights) -> pd.DataFrame:
    results = []
    supervisor_count = {}  # ×“×•×’××” ×œ×”×’×‘×œ×” ×¤×¨-××“×¨×™×š: ×¢×“ 2 ×¡×˜×•×“× ×˜×™× (× ×™×ª×Ÿ ×œ×©× ×•×ª/×œ×‘×˜×œ)

    for _, s in students_df.iterrows():
        # ×›×œ ×”××•×¢××“×™× ×”×¤× ×•×™×™×
        cand = sites_df[sites_df["capacity_left"] > 0].copy()

        if cand.empty:
            results.append({
                "×ª\"×– ×”×¡×˜×•×“× ×˜": s.get("stu_id",""),
                "×©× ×¤×¨×˜×™": s.get("stu_first",""),
                "×©× ××©×¤×—×”": s.get("stu_last",""),
                "×©× ××§×•× ×”×”×ª××—×•×ª": "×œ× ×©×•×‘×¥",
                "×¢×™×¨ ×”××•×¡×“": "",
                "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": "",
                "×©× ×”××“×¨×™×š": "",
                "××—×•×– ×”×ª×××”": 0,
                "_expl": {"×”×ª×××ª ×ª×—×•×":0,"××¨×—×§/×’×™××•×’×¨×¤×™×”":0,"×‘×§×©×•×ª ××™×•×—×“×•×ª":0,"×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª":0}
            })
            continue

        # × ×™×§×•×“ ×’×•×œ××™ ×œ×›×œ ××ª×¨
        cand["raw"] = cand.apply(lambda r: raw_score(s, r, W), axis=1)

        # ×¡×™× ×•×Ÿ ×¤×¨-××“×¨×™×š (×× ×¨×•×¦×™×)
        def allowed_supervisor(r):
            sup = r.get("×©× ×”××“×¨×™×š", "")
            return supervisor_count.get(sup, 0) < 2 if sup else True
        cand = cand[cand.apply(allowed_supervisor, axis=1)]

        if cand.empty:
            # ×× × ×¤×œ× ×• ×‘×’×œ×œ ××’×‘×œ×ª ××“×¨×™×š â€“ × ×—×–×•×¨ ×œ×›×œ ×”×¤× ×•×™×™× (×¢×“×™×£ ×œ×©×‘×¥ ×××©×¨ ×œ×)
            cand = sites_df[sites_df["capacity_left"] > 0].copy()
            cand["raw"] = cand.apply(lambda r: raw_score(s, r, W), axis=1)
            if cand.empty:
                results.append({
                    "×ª\"×– ×”×¡×˜×•×“× ×˜": s.get("stu_id",""),
                    "×©× ×¤×¨×˜×™": s.get("stu_first",""),
                    "×©× ××©×¤×—×”": s.get("stu_last",""),
                    "×©× ××§×•× ×”×”×ª××—×•×ª": "×œ× ×©×•×‘×¥",
                    "×¢×™×¨ ×”××•×¡×“": "",
                    "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": "",
                    "×©× ×”××“×¨×™×š": "",
                    "××—×•×– ×”×ª×××”": 0,
                    "_expl": {"×”×ª×××ª ×ª×—×•×":0,"××¨×—×§/×’×™××•×’×¨×¤×™×”":0,"×‘×§×©×•×ª ××™×•×—×“×•×ª":0,"×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª":0}
                })
                continue

        # --- × ×•×¨××œ×™×–×¦×™×” ×™×—×¡×™×ª ×œ×¡×˜×•×“× ×˜: ××‘×˜×™×—×” ×¤×™×–×•×¨ 0..100 ×‘×™×Ÿ ×”××ª×¨×™× ×©×œ ××•×ª×• ×¡×˜×•×“× ×˜ ---
        rmin, rmax = float(cand["raw"].min()), float(cand["raw"].max())
        if rmax > rmin:
            cand["score"] = (cand["raw"] - rmin) / (rmax - rmin) * 100.0
        else:
            cand["score"] = 50.0  # ××™×Ÿ ×©×•× ×•×ª â€“ ××¦×‘×™×¢ ×©××™×Ÿ ×”×‘×“×œ ×‘×™×Ÿ ×”××ª×¨×™× ×¢×‘×•×¨ ×”×¡×˜×•×“× ×˜

        # ×’× × ×©××•×¨ ×¤×™×¨×•×˜ ××¨×›×™×‘×™× ×œ×¤×™ ×”× ×™×§×•×“ ×”×’×•×œ××™ ×©× ×‘×—×¨
        def parts_for(r):
            # ×¤×™×¨×•×§ ×œ×¤×™ raw ×©× ×‘× ×” ×Ö¾f,c,s
            same_city = (_norm(s.get("stu_city")) and _norm(r.get("site_city")) and
                         _norm(s.get("stu_city")) == _norm(r.get("site_city")))
            f = domain_score(s.get("stu_pref",""), r.get("site_field",""))
            c = city_score(s.get("stu_city",""), r.get("site_city",""))
            sp = special_score(s.get("stu_req",""), same_city)
            return {
                "×”×ª×××ª ×ª×—×•×": int(round(W.w_field * f)),
                "××¨×—×§/×’×™××•×’×¨×¤×™×”": int(round(W.w_city * c)),
                "×‘×§×©×•×ª ××™×•×—×“×•×ª": int(round(W.w_special * sp)),
                "×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª": 0
            }

        cand = cand.sort_values("score", ascending=False)
        chosen = cand.iloc[0]
        idx = chosen.name
        sites_df.at[idx, "capacity_left"] -= 1

        sup_name = chosen.get("×©× ×”××“×¨×™×š", "")
        if sup_name:
            supervisor_count[sup_name] = supervisor_count.get(sup_name, 0) + 1

        results.append({
            "×ª\"×– ×”×¡×˜×•×“× ×˜": s.get("stu_id",""),
            "×©× ×¤×¨×˜×™": s.get("stu_first",""),
            "×©× ××©×¤×—×”": s.get("stu_last",""),
            "×©× ××§×•× ×”×”×ª××—×•×ª": chosen.get("site_name",""),
            "×¢×™×¨ ×”××•×¡×“": chosen.get("site_city",""),
            "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": chosen.get("site_field",""),
            "×©× ×”××“×¨×™×š": sup_name,
            "××—×•×– ×”×ª×××”": int(round(float(chosen["score"]))),   # ×™×—×¡×™, 0..100
            "_expl": parts_for(chosen)
        })

    return pd.DataFrame(results)

# ---- ×™×¦×™×¨×ª XLSX ----
def df_to_xlsx_bytes(df: pd.DataFrame, sheet_name: str = "×©×™×‘×•×¥") -> bytes:
    xlsx_io = BytesIO()
    import xlsxwriter
    with pd.ExcelWriter(xlsx_io, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    xlsx_io.seek(0)
    return xlsx_io.getvalue()

# =========================
# 1) ×”×•×¨××•×ª ×©×™××•×©
# =========================
st.markdown("## ğŸ“˜ ×”×•×¨××•×ª ×©×™××•×©")
st.markdown("""
1. **×§×•×‘×¥ ×¡×˜×•×“× ×˜×™× (CSV/XLSX):** ×©× ×¤×¨×˜×™, ×©× ××©×¤×—×”, ×ª×¢×•×“×ª ×–×”×•×ª, ×¢×™×¨/×›×ª×•×‘×ª, ×˜×œ×¤×•×Ÿ, ××™××™×™×œ.  
   ××•×¤×¦×™×•× ×œ×™: ×ª×—×•× ××•×¢×“×£/×™× (××¤×©×¨ ×›××”, ××•×¤×¨×“×™× ×‘×¤×¡×™×§/; / /), ×‘×§×©×” ××™×•×—×“×ª.  
2. **×§×•×‘×¥ ××ª×¨×™×/××“×¨×™×›×™× (CSV/XLSX):** ××•×¡×“/×©×™×¨×•×ª, ×ª×—×•× ×”×ª××—×•×ª, ×¢×™×¨, ×§×™×‘×•×œ×ª, ××“×¨×™×š, ×—×•×•×ª ×“×¢×ª.  
3. ×›×¤×ª×•×¨ **×‘×¦×¢ ×©×™×‘×•×¥** ××—×©×‘ × ×™×§×•×“ ***×™×—×¡×™ ×œ×›×œ ×¡×˜×•×“× ×˜*** ×•××“×’×™× ×¤×™×–×•×¨ ×××™×ª×™ ×©×œ ××—×•×–×™ ×”×ª×××”.
""")

# =========================
# 2) ×“×•×’××” ×œ×©×™××•×©
# =========================
st.markdown("## ğŸ§ª ×“×•×’××” ×œ×©×™××•×©")
example_students = pd.DataFrame([
    {"×©× ×¤×¨×˜×™":"×¨×•×ª", "×©× ××©×¤×—×”":"×›×”×Ÿ", "×ª×¢×•×“×ª ×–×”×•×ª":"123456789", "×¢×™×¨ ××’×•×¨×™×":"×ª×œ ××‘×™×‘", "×˜×œ×¤×•×Ÿ":"0501111111", "×“×•×\"×œ":"ruth@example.com", "×ª×—×•××™× ××•×¢×“×¤×™×":"×‘×¨×™××•×ª ×”× ×¤×©; ×—×™× ×•×š ××™×•×—×“", "×‘×§×©×” ××™×•×—×“×ª":"×§×¨×•×‘ ×œ×‘×™×ª"},
    {"×©× ×¤×¨×˜×™":"×™×•××‘", "×©× ××©×¤×—×”":"×œ×•×™", "×ª×¢×•×“×ª ×–×”×•×ª":"987654321", "×¢×™×¨ ××’×•×¨×™×":"×—×™×¤×”", "×˜×œ×¤×•×Ÿ":"0502222222", "×“×•×\"×œ":"yoav@example.com", "×ª×—×•× ××•×¢×“×£":"×¨×•×•×—×”"},
    {"×©× ×¤×¨×˜×™":"×¡×××—", "×©× ××©×¤×—×”":"×—'×•×¨×™", "×ª×¢×•×“×ª ×–×”×•×ª":"456789123", "×¢×™×¨ ××’×•×¨×™×":"×¢×›×•", "×˜×œ×¤×•×Ÿ":"0503333333", "×“×•×\"×œ":"sama@example.com", "×ª×—×•× ××•×¢×“×£":"×—×™× ×•×š ××™×•×—×“"},
])
example_sites = pd.DataFrame([
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××¨×›×– ×—×•×¡×Ÿ ×ª×œ ××‘×™×‘", "×ª×—×•× ×”×”×ª××—×•×ª":"×‘×¨×™××•×ª ×”× ×¤×©", "×¢×™×¨":"×ª×œ ××‘×™×‘", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":2, "×©× ×¤×¨×˜×™":"×“× ×™××œ", "×©× ××©×¤×—×”":"×›×”×Ÿ", "×—×•×•×ª ×“×¢×ª ××“×¨×™×š":"××“×¨×™×š ××¦×•×™×Ÿ"},
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××—×œ×§×ª ×¨×•×•×—×” ×—×™×¤×”", "×ª×—×•× ×”×”×ª××—×•×ª":"×¨×•×•×—×”", "×¢×™×¨":"×—×™×¤×”", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":1, "×©× ×¤×¨×˜×™":"××™×›×œ", "×©× ××©×¤×—×”":"×œ×•×™", "×—×•×•×ª ×“×¢×ª ××“×¨×™×š":"×–×§×•×§×” ×œ×©×™×¤×•×¨"},
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"×‘×™×ª ×¡×¤×¨ ×™×“ ×œ×‘× ×™×", "×ª×—×•× ×”×”×ª××—×•×ª":"×—×™× ×•×š ××™×•×—×“", "×¢×™×¨":"×¢×›×•", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":1, "×©× ×¤×¨×˜×™":"×©×¨×”", "×©× ××©×¤×—×”":"×›×”×Ÿ"},
])
colX, colY = st.columns(2, gap="large")
with colX:
    st.write("**×“×•×’××” â€“ ×¡×˜×•×“× ×˜×™×**")
    st.dataframe(example_students, use_container_width=True)
with colY:
    st.write("**×“×•×’××” â€“ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×**")
    st.dataframe(example_sites, use_container_width=True)

# =========================
# 3) ×”×¢×œ××ª ×§×‘×¦×™×
# =========================
st.markdown("## ğŸ“¤ ×”×¢×œ××ª ×§×‘×¦×™×")
colA, colB = st.columns(2, gap="large")

with colA:
    students_file = st.file_uploader("×§×•×‘×¥ ×¡×˜×•×“× ×˜×™×", type=["csv","xlsx","xls"], key="students_file")
    if students_file is not None:
        try:
            st.session_state["df_students_raw"] = read_any(students_file)
            st.dataframe(st.session_state["df_students_raw"].head(5), use_container_width=True)
        except Exception as e:
            st.error(f"×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×§×•×‘×¥ ×”×¡×˜×•×“× ×˜×™×: {e}")

with colB:
    sites_file = st.file_uploader("×§×•×‘×¥ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×", type=["csv","xlsx","xls"], key="sites_file")
    if sites_file is not None:
        try:
            st.session_state["df_sites_raw"] = read_any(sites_file)
            st.dataframe(st.session_state["df_sites_raw"].head(5), use_container_width=True)
        except Exception as e:
            st.error(f"×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×§×•×‘×¥ ×”××ª×¨×™×/××“×¨×™×›×™×: {e}")

for k in ["df_students_raw","df_sites_raw","result_df","sites_after"]:
    st.session_state.setdefault(k, None)

# =========================
# ×©×™×‘×•×¥ ×•×”×¦×’×ª ×ª×•×¦××•×ª
# =========================
st.markdown("## âš™ï¸ ×‘×™×¦×•×¢ ×”×©×™×‘×•×¥")
st.markdown('<div class="cta-wrap">', unsafe_allow_html=True)
run_match = st.button("×‘×¦×¢ ×©×™×‘×•×¥ ğŸš€", use_container_width=True, key="run_match")
st.markdown('</div>', unsafe_allow_html=True)

if run_match:
    try:
        students = resolve_students(st.session_state["df_students_raw"])
        sites    = resolve_sites(st.session_state["df_sites_raw"])
        result_df = greedy_match(students, sites, Weights())
        st.session_state["result_df"] = result_df
        st.session_state["sites_after"] = sites
        st.success("×”×©×™×‘×•×¥ ×”×•×©×œ× âœ“")
    except Exception as e:
        st.exception(e)

if isinstance(st.session_state["result_df"], pd.DataFrame) and not st.session_state["result_df"].empty:
    st.markdown("## ğŸ“Š ×ª×•×¦××•×ª ×”×©×™×‘×•×¥")
    base_df = st.session_state["result_df"].copy()

    df_show = pd.DataFrame({
        "××—×•×– ×”×ª×××”": base_df["××—×•×– ×”×ª×××”"].astype(int),
        "×©× ×”×¡×˜×•×“× ×˜/×™×ª": (base_df["×©× ×¤×¨×˜×™"].astype(str) + " " + base_df["×©× ××©×¤×—×”"].astype(str)).str.strip(),
        "×ª×¢×•×“×ª ×–×”×•×ª": base_df["×ª\"×– ×”×¡×˜×•×“× ×˜"],
        "×ª×—×•× ×”×ª××—×•×ª": base_df["×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“"],
        "×¢×™×¨ ×”××•×¡×“": base_df["×¢×™×¨ ×”××•×¡×“"],
        "×©× ××§×•× ×”×”×ª××—×•×ª": base_df["×©× ××§×•× ×”×”×ª××—×•×ª"],
        "×©× ×”××“×¨×™×š/×”": base_df["×©× ×”××“×¨×™×š"],
    }).sort_values("××—×•×– ×”×ª×××”", ascending=False)

    st.markdown("### ×˜×‘×œ×ª ×ª×•×¦××•×ª ××¨×›×–×™×ª")
    st.dataframe(df_show, use_container_width=True)

    # ×”×•×¨×“×”
    def df_to_xlsx_bytes(df: pd.DataFrame, sheet_name: str = "×ª×•×¦××•×ª") -> bytes:
        xlsx_io = BytesIO()
        import xlsxwriter
        with pd.ExcelWriter(xlsx_io, engine="xlsxwriter") as writer:
            df.to_excel(writer, index=False, sheet_name=sheet_name)
        xlsx_io.seek(0)
        return xlsx_io.getvalue()

    xlsx_results = df_to_xlsx_bytes(df_show, sheet_name="×ª×•×¦××•×ª")
    st.download_button(
        "â¬‡ï¸ ×”×•×¨×“×ª XLSX â€“ ×ª×•×¦××•×ª ×”×©×™×‘×•×¥",
        data=xlsx_results,
        file_name="student_site_matching.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # ×”×¡×‘×¨ ×¦×™×•×Ÿ (×©×‘×™×¨×ª ×”×ª×××”)
    st.markdown("### ğŸ§© ×”×¡×‘×¨ ×¦×™×•×Ÿ â€“ ×©×‘×™×¨×ª ×”×ª×××”")
    idx_max = len(base_df) - 1
    ex_idx = st.number_input("×‘×—×¨/×™ ×©×•×¨×” ×œ×”×¡×‘×¨ (0..):", min_value=0, max_value=idx_max, value=0, step=1)
    try:
        expl = base_df.iloc[int(ex_idx)]["_expl"]
        ex_df = pd.DataFrame({
            "××¨×›×™×‘": ["××¨×—×§/×’×™××•×’×¨×¤×™×”","×”×ª×××ª ×ª×—×•×","×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª","×‘×§×©×•×ª ××™×•×—×“×•×ª"],
            "×ª×¨×•××”": [expl.get("××¨×—×§/×’×™××•×’×¨×¤×™×”",0), expl.get("×”×ª×××ª ×ª×—×•×",0), expl.get("×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª",0), expl.get("×‘×§×©×•×ª ××™×•×—×“×•×ª",0)]
        })
        ex_df.loc[len(ex_df.index)] = {"××¨×›×™×‘": "×¡×”\"×›", "×ª×¨×•××”": int(base_df.iloc[int(ex_idx)]["××—×•×– ×”×ª×××”"])}
        st.table(ex_df)
    except Exception:
        st.info("××™×Ÿ × ×ª×•× ×™ ×”×¡×‘×¨ ×œ×¦×™×•×Ÿ ×¢×‘×•×¨ ×”×©×•×¨×” ×©× ×‘×—×¨×”.")

    # ×“×•×— ×¡×™×›×•× ×œ×¤×™ ××§×•× ×”×›×©×¨×”
    st.markdown("### ğŸ“ ×˜×‘×œ×ª ×¡×™×›×•× ×œ×¤×™ ××§×•× ×”×›×©×¨×”")
    summary_df = (
        base_df
        .groupby(["×©× ××§×•× ×”×”×ª××—×•×ª","×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“","×©× ×”××“×¨×™×š"])
        .agg({
            "×ª\"×– ×”×¡×˜×•×“× ×˜":"count",
            "×©× ×¤×¨×˜×™": list,
            "×©× ××©×¤×—×”": list
        }).reset_index()
    )
    summary_df.rename(columns={"×ª\"×– ×”×¡×˜×•×“× ×˜":"×›××” ×¡×˜×•×“× ×˜×™×"}, inplace=True)
    summary_df["×”××œ×¦×ª ×©×™×‘×•×¥"] = summary_df.apply(
        lambda row: " + ".join([f"{f} {l}" for f, l in zip(row["×©× ×¤×¨×˜×™"], row["×©× ××©×¤×—×”"])]),
        axis=1
    )
    summary_df = summary_df[[
        "×©× ××§×•× ×”×”×ª××—×•×ª","×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“","×©× ×”××“×¨×™×š","×›××” ×¡×˜×•×“× ×˜×™×","×”××œ×¦×ª ×©×™×‘×•×¥"
    ]]
    st.dataframe(summary_df, use_container_width=True)

    xlsx_summary = df_to_xlsx_bytes(summary_df, sheet_name="×¡×™×›×•×")
    st.download_button(
        "â¬‡ï¸ ×”×•×¨×“×ª XLSX â€“ ×˜×‘×œ×ª ×¡×™×›×•×",
        data=xlsx_summary,
        file_name="student_site_summary.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # ×“×•×— ×§×™×‘×•×œ×•×ª
    st.markdown("### ğŸ·ï¸ ×“×•×— ×§×™×‘×•×œ×•×ª ×œ×¤×™ ××§×•× ×”×›×©×¨×”")
    sites_after = st.session_state.get("sites_after", None)
    if isinstance(sites_after, pd.DataFrame) and not sites_after.empty:
        caps = sites_after.groupby("site_name")["site_capacity"].sum().to_dict()
        assigned = base_df.groupby("×©× ××§×•× ×”×”×ª××—×•×ª")["×ª\"×– ×”×¡×˜×•×“× ×˜"].count().to_dict()
        cap_rows = []
        for site, capacity in caps.items():
            used = int(assigned.get(site, 0))
            cap_rows.append({
                "×©× ××§×•× ×”×”×ª××—×•×ª": site,
                "×§×™×‘×•×œ×ª": int(capacity),
                "×©×•×‘×¦×• ×‘×¤×•×¢×œ": used,
                "×™×ª×¨×”/×—×•×¡×¨": int(capacity - used)
            })
        cap_df = pd.DataFrame(cap_rows).sort_values("×©× ××§×•× ×”×”×ª××—×•×ª")
        st.dataframe(cap_df, use_container_width=True)

        under = cap_df[cap_df["×™×ª×¨×”/×—×•×¡×¨"] > 0]
        over  = cap_df[cap_df["×™×ª×¨×”/×—×•×¡×¨"] < 0]
        if not under.empty:
            st.info("××•×¡×“×•×ª ×¢× ××§×•××•×ª ×¤× ×•×™×™×:\n- " + "\n- ".join(under["×©× ××§×•× ×”×”×ª××—×•×ª"].tolist()))
        if not over.empty:
            st.error("××•×¡×“×•×ª ×¢× ×—×¨×™×’×” (×¢×•×“×£ ×©×™×‘×•×¥):\n- " + "\n- ".join(over["×©× ××§×•× ×”×”×ª××—×•×ª"].tolist()))
    else:
        st.info("×œ× × ××¦××• × ×ª×•× ×™ ×§×™×‘×•×œ×ª ×œ×©×™×‘×•×¥ ×–×”.")
