# matcher_streamlit_beauty_rtl_v7_fixed.py 
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from dataclasses import dataclass
from typing import Optional, Any, List

# =========================
# ×§×•× ×¤×™×’×•×¨×¦×™×” ×›×œ×œ×™×ª
# =========================
st.set_page_config(page_title="××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”", layout="wide")

# ====== CSS â€“ ×¢×™×¦×•×‘ ××•×“×¨× ×™ + RTL ======
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Rubik:wght@400;600&display=swap');

html, body, [class*="css"] { 
  font-family: 'Rubik', 'David', sans-serif !important; 
}

:root{
  --bg-1:#e0f7fa;
  --bg-2:#ede7f6;
  --bg-3:#fff3e0;
  --bg-4:#fce4ec;
  --bg-5:#e8f5e9;
  --ink:#0f172a;
  --primary:#9b5de5;
  --primary-700:#f15bb5;
  --ring:rgba(155,93,229,.35);
}

[data-testid="stAppViewContainer"]{
  background:
    radial-gradient(1200px 600px at 15% 10%, var(--bg-2) 0%, transparent 70%),
    radial-gradient(1000px 700px at 85% 20%, var(--bg-3) 0%, transparent 70%),
    radial-gradient(900px 500px at 50% 80%, var(--bg-4) 0%, transparent 70%),
    radial-gradient(700px 400px at 10% 85%, var(--bg-5) 0%, transparent 70%),
    linear-gradient(135deg, var(--bg-1) 0%, #ffffff 100%) !important;
  color: var(--ink);
}

.main .block-container{
  background: rgba(255,255,255,.78);
  backdrop-filter: blur(10px);
  border:1px solid rgba(15,23,42,.08);
  box-shadow:0 15px 35px rgba(15,23,42,.08);
  border-radius:24px;
  padding:2.5rem;
  margin-top:1rem;
}

h1,h2,h3,.stMarkdown h1,.stMarkdown h2{
  text-align:center;
  letter-spacing:.5px;
  text-shadow:0 1px 2px rgba(255,255,255,.7);
  font-weight:700;
  color:#222;
  margin-bottom:1rem;
}

.stButton > button,
div[data-testid="stDownloadButton"] > button{
  background:linear-gradient(135deg,var(--primary) 0%,var(--primary-700) 100%)!important;
  color:#fff!important;
  border:none!important;
  border-radius:18px!important;
  padding:1rem 2rem!important;
  font-size:1.1rem!important;
  font-weight:600!important;
  box-shadow:0 8px 18px var(--ring)!important;
  transition:all .15s ease!important;
  width:100% !important;
}
.stButton > button:hover,
div[data-testid="stDownloadButton"] > button:hover{ 
  transform:translateY(-3px) scale(1.02); 
  filter:brightness(1.08); 
}
.stButton > button:focus,
div[data-testid="stDownloadButton"] > button:focus{ 
  outline:none!important; 
  box-shadow:0 0 0 4px var(--ring)!important; 
}

.stApp,.main,[data-testid="stSidebar"]{ direction:rtl; text-align:right; }
label,.stMarkdown,.stText,.stCaption{ text-align:right!important; }
</style>
""", unsafe_allow_html=True)

# ====== ×›×•×ª×¨×ª ======
st.markdown("<h1>××¢×¨×›×ª ×©×™×‘×•×¥ ×¡×˜×•×“× ×˜×™× â€“ ×”×ª×××” ×—×›××”</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align:center;color:#475569;margin-top:-8px;'>×›××Ÿ ××©×‘×¦×™× ×¡×˜×•×“× ×˜×™× ×œ××§×•××•×ª ×”×ª××—×•×ª ×‘×§×œ×•×ª, ×‘×”×ª×‘×¡×¡ ×¢×œ ×ª×—×•×, ×¢×™×¨ ×•×‘×§×©×•×ª.</p>", unsafe_allow_html=True)

# ====== ××•×“×œ × ×™×§×•×“ ======
@dataclass
class Weights:
    w_field: float = 0.50
    w_city: float = 0.05
    w_special: float = 0.45

# ×¢××•×“×•×ª ×¡×˜×•×“× ×˜×™×
STU_COLS = {
    "id": ["××¡×¤×¨ ×ª×¢×•×“×ª ×–×”×•×ª", "×ª×¢×•×“×ª ×–×”×•×ª", "×ª\"×–", "×ª×–", "×ª×¢×•×“×ª ×–×”×•×ª ×”×¡×˜×•×“× ×˜"],
    "first": ["×©× ×¤×¨×˜×™"],
    "last": ["×©× ××©×¤×—×”"],
    "address": ["×›×ª×•×‘×ª", "×›×ª×•×‘×ª ×”×¡×˜×•×“× ×˜", "×¨×—×•×‘"],
    "city": ["×¢×™×¨ ××’×•×¨×™×", "×¢×™×¨"],
    "phone": ["×˜×œ×¤×•×Ÿ", "××¡×¤×¨ ×˜×œ×¤×•×Ÿ"],
    "email": ["×“×•×\"×œ", "×“×•××´×œ", "××™××™×™×œ", "×›×ª×•×‘×ª ××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ"],
    "preferred_field": ["×ª×—×•× ××•×¢×“×£","×ª×—×•××™× ××•×¢×“×¤×™×"],
    "special_req": ["×‘×§×©×” ××™×•×—×“×ª"],
    "partner": ["×‘×Ÿ/×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ\\×‘×ª ×–×•×’ ×œ×”×›×©×¨×”", "×‘×Ÿ/×‘×ª ×–×•×’", "×‘×Ÿ\\×‘×ª ×–×•×’"]
}

# ×¢××•×“×•×ª ××ª×¨×™×
SITE_COLS = {
    "name": ["××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”", "××•×¡×“", "×©× ××•×¡×“ ×”×”×ª××—×•×ª", "×©× ×”××•×¡×“", "××•×¡×“ ×”×”×›×©×¨×”"],
    "field": ["×ª×—×•× ×”×”×ª××—×•×ª", "×ª×—×•× ×”×ª××—×•×ª"],
    "street": ["×¨×—×•×‘"],
    "city": ["×¢×™×¨"],
    "capacity": ["××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜", "×§×™×‘×•×œ×ª"],
    "sup_first": ["×©× ×¤×¨×˜×™"],
    "sup_last": ["×©× ××©×¤×—×”"],
    "phone": ["×˜×œ×¤×•×Ÿ"],
    "email": ["××™××™×™×œ", "×›×ª×•×‘×ª ××™×™×œ", "×“×•×\"×œ", "×“×•××´×œ"],
    "review": ["×—×•×•×ª ×“×¢×ª ××“×¨×™×š"]
}

def pick_col(df: pd.DataFrame, options: List[str]) -> Optional[str]:
    for opt in options:
        if opt in df.columns: return opt
    return None

# ----- ×§×¨×™××ª ×§×‘×¦×™× -----
def read_any(uploaded) -> pd.DataFrame:
    name = (uploaded.name or "").lower()
    if name.endswith(".csv"):
        return pd.read_csv(uploaded, encoding="utf-8-sig")
    if name.endswith((".xlsx",".xls")):
        return pd.read_excel(uploaded)
    return pd.read_csv(uploaded, encoding="utf-8-sig")

def normalize_text(x: Any) -> str:
    if x is None: return ""
    return str(x).strip()

# ----- ×¡×˜×•×“× ×˜×™× -----
def resolve_students(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["stu_id"] = out[pick_col(out, STU_COLS["id"])]
    out["stu_first"] = out[pick_col(out, STU_COLS["first"])]
    out["stu_last"]  = out[pick_col(out, STU_COLS["last"])]
    out["stu_city"]  = out[pick_col(out, STU_COLS["city"])] if pick_col(out, STU_COLS["city"]) else ""
    out["stu_pref"]  = out[pick_col(out, STU_COLS["preferred_field"])] if pick_col(out, STU_COLS["preferred_field"]) else ""
    out["stu_req"]   = out[pick_col(out, STU_COLS["special_req"])] if pick_col(out, STU_COLS["special_req"]) else ""
    for c in ["stu_id","stu_first","stu_last","stu_city","stu_pref","stu_req"]:
        out[c] = out[c].apply(normalize_text)
    return out

# ----- ××ª×¨×™× -----
def resolve_sites(df: pd.DataFrame) -> pd.DataFrame:
    out = df.copy()
    out["site_name"]  = out[pick_col(out, SITE_COLS["name"])]
    out["site_field"] = out[pick_col(out, SITE_COLS["field"])]
    out["site_city"]  = out[pick_col(out, SITE_COLS["city"])]
    cap_col = pick_col(out, SITE_COLS["capacity"])
    out["site_capacity"] = pd.to_numeric(out[cap_col], errors="coerce").fillna(1).astype(int) if cap_col else 1
    out["capacity_left"] = out["site_capacity"].astype(int)
    sup_first = pick_col(out, SITE_COLS["sup_first"])
    sup_last  = pick_col(out, SITE_COLS["sup_last"])
    out["×©× ×”××“×¨×™×š"] = ""
    if sup_first or sup_last:
        ff = out[sup_first] if sup_first else ""
        ll = out[sup_last]  if sup_last else ""
        out["×©× ×”××“×¨×™×š"] = (ff.astype(str) + " " + ll.astype(str)).str.strip()
    for c in ["site_name","site_field","site_city","×©× ×”××“×¨×™×š"]:
        out[c] = out[c].apply(normalize_text)
    return out

# ====== ×—×™×©×•×‘ ×¦×™×•×Ÿ ======
def compute_score(stu: pd.Series, site: pd.Series, W: Weights) -> float:
    same_city = (stu.get("stu_city") and site.get("site_city") and stu.get("stu_city") == site.get("site_city"))
    field_s   = 90.0 if stu.get("stu_pref") and stu.get("stu_pref") in site.get("site_field","") else 60.0
    city_s    = 100.0 if same_city else 65.0
    special_s = 90.0 if "×§×¨×•×‘" in stu.get("stu_req","") and same_city else 70.0
    score = W.w_field*field_s + W.w_city*city_s + W.w_special*special_s
    return float(np.clip(score, 0, 100))

# --- ×’×¨×¡×” ×¢× ×¤×™×¨×•×˜ ××¨×›×™×‘×™× (×œ×©×‘×™×¨×ª ×”×¦×™×•×Ÿ) ---
def compute_score_with_explain(stu: pd.Series, site: pd.Series, W: Weights):
    same_city = (stu.get("stu_city") and site.get("site_city") and stu.get("stu_city") == site.get("site_city"))
    field_s   = 90.0 if stu.get("stu_pref") and stu.get("stu_pref") in site.get("site_field","") else 60.0
    city_s    = 100.0 if same_city else 65.0
    special_s = 90.0 if "×§×¨×•×‘" in stu.get("stu_req","") and same_city else 70.0

    parts = {
        "×”×ª×××ª ×ª×—×•×": round(W.w_field*field_s),
        "××¨×—×§/×’×™××•×’×¨×¤×™×”": round(W.w_city*city_s),
        "×‘×§×©×•×ª ××™×•×—×“×•×ª": round(W.w_special*special_s),
        "×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª": 0  # ××™×Ÿ ×§×œ×˜ ×“×™×¨×•×’ ××¤×•×¨×© ×‘×§×•×‘×¥ ×–×”; × ×©××¨ 0 ×œ×©×§×™×¤×•×ª
    }
    score = int(np.clip(sum(parts.values()), 0, 100))
    return score, parts

# =========================
# 1) ×”×•×¨××•×ª ×©×™××•×©
# =========================
st.markdown("## ğŸ“˜ ×”×•×¨××•×ª ×©×™××•×©")
st.markdown("""
1. **×§×•×‘×¥ ×¡×˜×•×“× ×˜×™× (CSV/XLSX):** ×©× ×¤×¨×˜×™, ×©× ××©×¤×—×”, ×ª×¢×•×“×ª ×–×”×•×ª, ×›×ª×•×‘×ª/×¢×™×¨, ×˜×œ×¤×•×Ÿ, ××™××™×™×œ.  
   ××•×¤×¦×™×•× ×œ×™: ×ª×—×•× ××•×¢×“×£, ×‘×§×©×” ××™×•×—×“×ª, ×‘×Ÿ/×‘×ª ×–×•×’ ×œ×”×›×©×¨×”.  
2. **×§×•×‘×¥ ××ª×¨×™×/××“×¨×™×›×™× (CSV/XLSX):** ××•×¡×“/×©×™×¨×•×ª, ×ª×—×•× ×”×ª××—×•×ª, ×¨×—×•×‘, ×¢×™×¨, ××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”, ××“×¨×™×š, ×—×•×•×ª ×“×¢×ª ××“×¨×™×š.  
3. **×‘×¦×¢ ×©×™×‘×•×¥** ××—×©×‘ *××—×•×– ×”×ª×××”* ×œ×¤×™ ×ª×—×•× (50%), ×‘×§×©×•×ª ××™×•×—×“×•×ª (45%), ×¢×™×¨ (5%). 
4. ×‘×¡×•×£ ××¤×©×¨ ×œ×”×•×¨×™×“ **XLSX**. 
""")

# =========================
# 2) ×“×•×’××” ×œ×©×™××•×©
# =========================
st.markdown("## ğŸ§ª ×“×•×’××” ×œ×©×™××•×©")
example_students = pd.DataFrame([
    {"×©× ×¤×¨×˜×™":"×¨×•×ª", "×©× ××©×¤×—×”":"×›×”×Ÿ", "×ª×¢×•×“×ª ×–×”×•×ª":"123456789", "×¢×™×¨ ××’×•×¨×™×":"×ª×œ ××‘×™×‘", "×˜×œ×¤×•×Ÿ":"0501111111", "×“×•×\"×œ":"ruth@example.com", "×ª×—×•× ××•×¢×“×£":"×‘×¨×™××•×ª ×”× ×¤×©", "×‘×§×©×” ××™×•×—×“×ª":"×§×¨×•×‘ ×œ×‘×™×ª"},
    {"×©× ×¤×¨×˜×™":"×™×•××‘", "×©× ××©×¤×—×”":"×œ×•×™", "×ª×¢×•×“×ª ×–×”×•×ª":"987654321", "×¢×™×¨ ××’×•×¨×™×":"×—×™×¤×”", "×˜×œ×¤×•×Ÿ":"0502222222", "×“×•×\"×œ":"yoav@example.com", "×ª×—×•× ××•×¢×“×£":"×¨×•×•×—×”"},
    {"×©× ×¤×¨×˜×™":"×¡×××—", "×©× ××©×¤×—×”":"×—'×•×¨×™", "×ª×¢×•×“×ª ×–×”×•×ª":"456789123", "×¢×™×¨ ××’×•×¨×™×":"×¢×›×•", "×˜×œ×¤×•×Ÿ":"0503333333", "×“×•×\"×œ":"sama@example.com", "×ª×—×•× ××•×¢×“×£":"×—×™× ×•×š ××™×•×—×“"},
])
example_sites = pd.DataFrame([
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××¨×›×– ×—×•×¡×Ÿ ×ª×œ ××‘×™×‘", "×ª×—×•× ×”×”×ª××—×•×ª":"×‘×¨×™××•×ª ×”× ×¤×©", "×¢×™×¨":"×ª×œ ××‘×™×‘", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":2, "×©× ×¤×¨×˜×™":"×“× ×™××œ", "×©× ××©×¤×—×”":"×›×”×Ÿ", "×—×•×•×ª ×“×¢×ª ××“×¨×™×š":"××“×¨×™×š ××¦×•×™×Ÿ"},
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"××—×œ×§×ª ×¨×•×•×—×” ×—×™×¤×”", "×ª×—×•× ×”×”×ª××—×•×ª":"×¨×•×•×—×”", "×¢×™×¨":"×—×™×¤×”", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":1, "×©× ×¤×¨×˜×™":"××™×›×œ", "×©× ××©×¤×—×”":"×œ×•×™", "×—×•×•×ª ×“×¢×ª ××“×¨×™×š":"×–×§×•×§×” ×œ×©×™×¤×•×¨"},
    {"××•×¡×“ / ×©×™×¨×•×ª ×”×›×©×¨×”":"×‘×™×ª ×¡×¤×¨ ×™×“ ×œ×‘× ×™×", "×ª×—×•× ×”×”×ª××—×•×ª":"×—×™× ×•×š ××™×•×—×“", "×¢×™×¨":"×¢×›×•", "××¡×¤×¨ ×¡×˜×•×“× ×˜×™× ×©× ×™×ª×Ÿ ×œ×§×œ×•×˜ ×”×©× ×”":1, "×©× ×¤×¨×˜×™":"×©×¨×”", "×©× ××©×¤×—×”":"×›×”×Ÿ"},
])
colX, colY = st.columns(2, gap="large")
with colX:
    st.write("**×“×•×’××” â€“ ×¡×˜×•×“× ×˜×™×**")
    st.dataframe(example_students, use_container_width=True)
with colY:
    st.write("**×“×•×’××” â€“ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×**")
    st.dataframe(example_sites, use_container_width=True)

# =========================
# 3) ×”×¢×œ××ª ×§×‘×¦×™×
# =========================
st.markdown("## ğŸ“¤ ×”×¢×œ××ª ×§×‘×¦×™×")
colA, colB = st.columns(2, gap="large")

with colA:
    students_file = st.file_uploader("×§×•×‘×¥ ×¡×˜×•×“× ×˜×™×", type=["csv","xlsx","xls"], key="students_file")
    if students_file is not None:
        try:
            st.session_state["df_students_raw"] = read_any(students_file)
            st.dataframe(st.session_state["df_students_raw"].head(5), use_container_width=True)
        except Exception as e:
            st.error(f"×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×§×•×‘×¥ ×”×¡×˜×•×“× ×˜×™×: {e}")

with colB:
    sites_file = st.file_uploader("×§×•×‘×¥ ××ª×¨×™ ×”×ª××—×•×ª/××“×¨×™×›×™×", type=["csv","xlsx","xls"], key="sites_file")
    if sites_file is not None:
        try:
            st.session_state["df_sites_raw"] = read_any(sites_file)
            st.dataframe(st.session_state["df_sites_raw"].head(5), use_container_width=True)
        except Exception as e:
            st.error(f"×œ× × ×™×ª×Ÿ ×œ×§×¨×•× ××ª ×§×•×‘×¥ ×”××ª×¨×™×/××“×¨×™×›×™×: {e}")

for k in ["df_students_raw","df_sites_raw","result_df","unmatched_students","unused_sites"]:
    st.session_state.setdefault(k, None)

# ====== ×©×™×‘×•×¥ ======
def greedy_match(students_df: pd.DataFrame, sites_df: pd.DataFrame, W: Weights) -> pd.DataFrame:
    results = []
    supervisor_count = {}  # ××•× ×™× ×¤×¨-××“×¨×™×š (×“×•×’××”: ×¢×“ 2 ×¡×˜×•×“× ×˜×™× ×œ×›×œ ××“×¨×™×š)

    for _, s in students_df.iterrows():
        cand = sites_df[sites_df["capacity_left"] > 0].copy()
        if cand.empty:
            results.append({
                "×ª\"×– ×”×¡×˜×•×“× ×˜": s["stu_id"],
                "×©× ×¤×¨×˜×™": s["stu_first"],
                "×©× ××©×¤×—×”": s["stu_last"],
                "×©× ××§×•× ×”×”×ª××—×•×ª": "×œ× ×©×•×‘×¥",
                "×¢×™×¨ ×”××•×¡×“": "",
                "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": "",
                "×©× ×”××“×¨×™×š": "",
                "××—×•×– ×”×ª×××”": 0,
                "_expl": {"×”×ª×××ª ×ª×—×•×":0,"××¨×—×§/×’×™××•×’×¨×¤×™×”":0,"×‘×§×©×•×ª ××™×•×—×“×•×ª":0,"×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª":0}
            })
            continue

        # ×—×™×©×•×‘ ×¦×™×•×Ÿ + ×¤×™×¨×•×§ ×¨×›×™×‘×™×
        cand[["score","_parts"]] = cand.apply(
            lambda r: pd.Series(compute_score_with_explain(s, r, W)),
            axis=1
        )

        # ×¡×™× ×•×Ÿ ×œ×¤×™ ××“×¨×™×š: ××•×ª×¨ ×¢×“ 2 ×¡×˜×•×“× ×˜×™× ×œ×›×œ ××“×¨×™×š (× ×™×ª×Ÿ ×œ×©× ×•×ª ×œ×¤×™ ×¦×•×¨×š)
        def allowed_supervisor(r):
            sup = r.get("×©× ×”××“×¨×™×š", "")
            return supervisor_count.get(sup, 0) < 2

        cand = cand[cand.apply(allowed_supervisor, axis=1)]

        if cand.empty:
            # ×× ××™×Ÿ ××“×¨×™×›×™× ×¤× ×•×™×™× â€“ × ×‘×—×¨ ××ª ×”××ª×¨ ×¢× ×”×¦×™×•×Ÿ ×”×’×‘×•×” ×‘×™×•×ª×¨ ××‘×™×Ÿ ×”×–××™× ×™× ×œ×¤× ×™ ×”×¡×™× ×•×Ÿ
            all_sites = sites_df[sites_df["capacity_left"] > 0].copy()
            if all_sites.empty:
                results.append({
                    "×ª\"×– ×”×¡×˜×•×“× ×˜": s["stu_id"],
                    "×©× ×¤×¨×˜×™": s["stu_first"],
                    "×©× ××©×¤×—×”": s["stu_last"],
                    "×©× ××§×•× ×”×”×ª××—×•×ª": "×œ× ×©×•×‘×¥",
                    "×¢×™×¨ ×”××•×¡×“": "",
                    "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": "",
                    "×©× ×”××“×¨×™×š": "",
                    "××—×•×– ×”×ª×××”": 0,
                    "_expl": {"×”×ª×××ª ×ª×—×•×":0,"××¨×—×§/×’×™××•×’×¨×¤×™×”":0,"×‘×§×©×•×ª ××™×•×—×“×•×ª":0,"×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª":0}
                })
                continue

            all_sites[["score","_parts"]] = all_sites.apply(
                lambda r: pd.Series(compute_score_with_explain(s, r, W)),
                axis=1
            )
            cand = all_sites.sort_values("score", ascending=False).head(1)
        else:
            cand = cand.sort_values("score", ascending=False)

        chosen = cand.iloc[0]
        idx = chosen.name
        sites_df.at[idx, "capacity_left"] -= 1

        sup_name = chosen.get("×©× ×”××“×¨×™×š", "")
        supervisor_count[sup_name] = supervisor_count.get(sup_name, 0) + 1

        results.append({
            "×ª\"×– ×”×¡×˜×•×“× ×˜": s["stu_id"],
            "×©× ×¤×¨×˜×™": s["stu_first"],
            "×©× ××©×¤×—×”": s["stu_last"],
            "×©× ××§×•× ×”×”×ª××—×•×ª": chosen["site_name"],
            "×¢×™×¨ ×”××•×¡×“": chosen.get("site_city", ""),
            "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“": chosen["site_field"],
            "×©× ×”××“×¨×™×š": sup_name,
            # >>> ×“×¨×™×©×ª ×”××¨×¦×™×: ××—×•×– ×”×ª×××” ××¡×¤×¨ ×©×œ×
            "××—×•×– ×”×ª×××”": int(chosen["score"]),
            "_expl": chosen["_parts"]
        })

    return pd.DataFrame(results)

# ---- ×™×¦×™×¨×ª XLSX ----
def df_to_xlsx_bytes(df: pd.DataFrame, sheet_name: str = "×©×™×‘×•×¥") -> bytes:
    xlsx_io = BytesIO()
    import xlsxwriter
    with pd.ExcelWriter(xlsx_io, engine="xlsxwriter") as writer:
        cols = list(df.columns)
        has_match_col = "××—×•×– ×”×ª×××”" in cols
        if has_match_col:
            cols = [c for c in cols if c != "××—×•×– ×”×ª×××”"] + ["××—×•×– ×”×ª×××”"]

        df[cols].to_excel(writer, index=False, sheet_name=sheet_name)

        if has_match_col:
            workbook  = writer.book
            worksheet = writer.sheets[sheet_name]
            red_fmt = workbook.add_format({"font_color": "red"})
            col_idx = len(cols) - 1
            worksheet.set_column(col_idx, col_idx, 12, red_fmt)
    xlsx_io.seek(0)
    return xlsx_io.getvalue()

# =========================
# ×©×™×‘×•×¥ ×•×”×¦×’×ª ×ª×•×¦××•×ª
# =========================
if "result_df" not in st.session_state:
    st.session_state["result_df"] = None

st.markdown("## âš™ï¸ ×‘×™×¦×•×¢ ×”×©×™×‘×•×¥")
colM1, colM2 = st.columns([2,1], gap="large")
with colM1:
    run_match = st.button("ğŸš€ ×‘×¦×¢ ×©×™×‘×•×¥", use_container_width=True)
with colM2:
    MATCH_THRESHOLD = st.slider("×¡×£ ×”×ª×××” (××—×•×–×™×) â€“ ××ª×—×ª ×œ×¡×£: ×‘×“×™×§×” ×™×“× ×™×ª", min_value=0, max_value=100, value=70, step=1)

if run_match:
    try:
        students = resolve_students(st.session_state["df_students_raw"])
        sites    = resolve_sites(st.session_state["df_sites_raw"])
        result_df = greedy_match(students, sites, Weights())
        st.session_state["result_df"] = result_df
        # × ×©××•×¨ ×’× ×¢×•×ª×§ ×©×œ ×”"sites" ×›×“×™ ×œ×”×©×ª××© ×œ×§×™×‘×•×œ×•×ª
        st.session_state["sites_after"] = sites
        st.success("×”×©×™×‘×•×¥ ×”×•×©×œ× âœ“")
    except Exception as e:
        st.exception(e)

if isinstance(st.session_state["result_df"], pd.DataFrame) and not st.session_state["result_df"].empty:
    st.markdown("## ğŸ“Š ×ª×•×¦××•×ª ×”×©×™×‘×•×¥")

    base_df = st.session_state["result_df"].copy()

    # ---- ×‘× ×™×™×ª ×˜×‘×œ×ª ×”×ª×•×¦××•×ª ×”××¨×›×–×™×ª ×œ×¤×™ ×¡×“×¨/×ª×•×•×™×•×ª ×”××¨×¦×™× ----
    df_show = pd.DataFrame({
        "××—×•×– ×”×ª×××”": base_df["××—×•×– ×”×ª×××”"].astype(int),
        "×©× ×”×¡×˜×•×“× ×˜/×™×ª": (base_df["×©× ×¤×¨×˜×™"].astype(str) + " " + base_df["×©× ××©×¤×—×”"].astype(str)).str.strip(),
        "×ª×¢×•×“×ª ×–×”×•×ª": base_df["×ª\"×– ×”×¡×˜×•×“× ×˜"],
        "×ª×—×•× ×”×ª××—×•×ª": base_df["×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“"],
        "×¢×™×¨ ×”××•×¡×“": base_df["×¢×™×¨ ×”××•×¡×“"],
        "×©× ××§×•× ×”×”×ª××—×•×ª": base_df["×©× ××§×•× ×”×”×ª××—×•×ª"],
        "×©× ×”××“×¨×™×š/×”": base_df["×©× ×”××“×¨×™×š"],
    })

    # ××™×•×Ÿ ××”×’×‘×•×” ×œ× ××•×š + ×¡×˜×˜×•×¡ ×¡×£
    df_show = df_show.sort_values("××—×•×– ×”×ª×××”", ascending=False)
    df_show["×¡×˜×˜×•×¡"] = df_show["××—×•×– ×”×ª×××”"].apply(lambda v: "âš  ×“×•×¨×© ×‘×“×™×§×” ×™×“× ×™×ª" if v < MATCH_THRESHOLD else "×ª×§×™×Ÿ")

    st.markdown("### ×˜×‘×œ×ª ×ª×•×¦××•×ª ××¨×›×–×™×ª")
    st.dataframe(df_show, use_container_width=True)

    # ×”×•×¨×“×ª ×§×•×‘×¥ ×ª×•×¦××•×ª (×‘×“×™×•×§ ×”×¢××•×“×•×ª ×©× ×¨××•×ª)
    xlsx_results = df_to_xlsx_bytes(df_show, sheet_name="×ª×•×¦××•×ª")
    st.download_button("â¬‡ï¸ ×”×•×¨×“×ª XLSX â€“ ×ª×•×¦××•×ª ×”×©×™×‘×•×¥", data=xlsx_results,
        file_name="student_site_matching.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    # --- ×”×¡×‘×¨ ×¦×™×•×Ÿ (×©×‘×™×¨×ª ×”×ª×××”) ---
    st.markdown("### ğŸ§© ×”×¡×‘×¨ ×¦×™×•×Ÿ â€“ ×©×‘×™×¨×ª ×”×ª×××”")
    idx_max = len(base_df) - 1
    ex_idx = st.number_input("×‘×—×¨/×™ ×©×•×¨×” ×œ×”×¡×‘×¨ (0..):", min_value=0, max_value=idx_max, value=0, step=1)
    try:
        expl = base_df.iloc[int(ex_idx)]["_expl"]
        ex_df = pd.DataFrame({
            "××¨×›×™×‘": ["××¨×—×§/×’×™××•×’×¨×¤×™×”","×”×ª×××ª ×ª×—×•×","×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª","×‘×§×©×•×ª ××™×•×—×“×•×ª"],
            "×ª×¨×•××”": [expl.get("××¨×—×§/×’×™××•×’×¨×¤×™×”",0), expl.get("×”×ª×××ª ×ª×—×•×",0), expl.get("×¢×“×™×¤×•×™×•×ª ×”×¡×˜×•×“× ×˜/×™×ª",0), expl.get("×‘×§×©×•×ª ××™×•×—×“×•×ª",0)]
        })
        ex_df.loc[len(ex_df.index)] = {"××¨×›×™×‘": "×¡×”\"×›", "×ª×¨×•××”": int(base_df.iloc[int(ex_idx)]["××—×•×– ×”×ª×××”"])}
        st.table(ex_df)
    except Exception:
        st.info("××™×Ÿ × ×ª×•× ×™ ×”×¡×‘×¨ ×œ×¦×™×•×Ÿ ×¢×‘×•×¨ ×”×©×•×¨×” ×©× ×‘×—×¨×”.")

    # --- ×“×•×— ×¡×™×›×•× ×œ×¤×™ ××§×•× ×”×›×©×¨×” (×›××•×ª/×©××•×ª) ---
    st.markdown("### ğŸ“ ×˜×‘×œ×ª ×¡×™×›×•× ×œ×¤×™ ××§×•× ×”×›×©×¨×”")
    summary_df = (
        base_df
        .groupby(["×©× ××§×•× ×”×”×ª××—×•×ª","×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“","×©× ×”××“×¨×™×š"])
        .agg({
            "×ª\"×– ×”×¡×˜×•×“× ×˜":"count",
            "×©× ×¤×¨×˜×™": list,
            "×©× ××©×¤×—×”": list
        }).reset_index()
    )
    summary_df.rename(columns={"×ª\"×– ×”×¡×˜×•×“× ×˜":"×›××” ×¡×˜×•×“× ×˜×™×"}, inplace=True)
    summary_df["×”××œ×¦×ª ×©×™×‘×•×¥"] = summary_df.apply(
        lambda row: " + ".join([f"{f} {l}" for f, l in zip(row["×©× ×¤×¨×˜×™"], row["×©× ××©×¤×—×”"])]),
        axis=1
    )
    summary_df = summary_df[[
        "×©× miejsce ×”×”×ª××—×•×ª".replace("miejsce","××§×•×"),  # ×”×’× ×” ×§×˜× ×” ××¤× ×™ ×§×™×“×•×“ ×“×¤×“×¤×Ÿ
        "×ª×—×•× ×”×”×ª××—×•×ª ×‘××•×¡×“",
        "×©× ×”××“×¨×™×š",
        "×›××” ×¡×˜×•×“× ×˜×™×",
        "×”××œ×¦×ª ×©×™×‘×•×¥"
    ]].rename(columns={"×©× miejsce ×”×”×ª××—×•×ª".replace("miejsce","××§×•×"): "×©× ××§×•× ×”×”×ª××—×•×ª"})

    st.dataframe(summary_df, use_container_width=True)
    xlsx_summary = df_to_xlsx_bytes(summary_df, sheet_name="×¡×™×›×•×")
    st.download_button("â¬‡ï¸ ×”×•×¨×“×ª XLSX â€“ ×˜×‘×œ×ª ×¡×™×›×•×", data=xlsx_summary,
        file_name="student_site_summary.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

    # --- ×“×•×— ×§×™×‘×•×œ×•×ª: ×§×™×‘×•×œ×ª/×©×•×‘×¦×•/×™×ª×¨×” ---
    st.markdown("### ğŸ·ï¸ ×“×•×— ×§×™×‘×•×œ×•×ª ×œ×¤×™ ××§×•× ×”×›×©×¨×”")
    sites_after = st.session_state.get("sites_after", None)
    if isinstance(sites_after, pd.DataFrame) and not sites_after.empty:
        caps = sites_after.groupby("site_name")["site_capacity"].sum().to_dict()
        assigned = base_df.groupby("×©× ××§×•× ×”×”×ª××—×•×ª")["×ª\"×– ×”×¡×˜×•×“× ×˜"].count().to_dict()
        cap_rows = []
        for site, capacity in caps.items():
            used = int(assigned.get(site, 0))
            cap_rows.append({
                "×©× ××§×•× ×”×”×ª××—×•×ª": site,
                "×§×™×‘×•×œ×ª": int(capacity),
                "×©×•×‘×¦×• ×‘×¤×•×¢×œ": used,
                "×™×ª×¨×”/×—×•×¡×¨": int(capacity - used)
            })
        cap_df = pd.DataFrame(cap_rows).sort_values("×©× ××§×•× ×”×”×ª××—×•×ª")
        st.dataframe(cap_df, use_container_width=True)

        # ×”×“×’×©×” ×˜×§×¡×˜×•××œ×™×ª
        under = cap_df[cap_df["×™×ª×¨×”/×—×•×¡×¨"] > 0]
        over  = cap_df[cap_df["×™×ª×¨×”/×—×•×¡×¨"] < 0]
        if not under.empty:
            st.info("××•×¡×“×•×ª ×¢× ××§×•××•×ª ×¤× ×•×™×™×:\n- " + "\n- ".join(under["×©× ××§×•× ×”×”×ª××—×•×ª"].tolist()))
        if not over.empty:
            st.error("××•×¡×“×•×ª ×¢× ×—×¨×™×’×” (×¢×•×“×£ ×©×™×‘×•×¥):\n- " + "\n- ".join(over["×©× ××§×•× ×”×”×ª××—×•×ª"].tolist()))
    else:
        st.info("×œ× × ××¦××• × ×ª×•× ×™ ×§×™×‘×•×œ×ª ×œ×©×™×‘×•×¥ ×–×”.")

    # --- ×“×•×— ×¨×™×›×•×–×™ ×¤×¨Ö¾××•×¨×” ---
    st.markdown("### ğŸ‘©â€ğŸ« ×“×•×— ×¤×¨Ö¾××•×¨×” ×©×™×˜×•×ª")
    teachers_list = ["(×›×•×œ×)"] + sorted([x for x in base_df["×©× ×”××“×¨×™×š"].unique() if str(x).strip() != ""])
    pick_teacher = st.selectbox("×¡×™× ×•×Ÿ ×œ×¤×™ ××•×¨×”:", teachers_list, index=0)
    df_for_teacher = base_df.copy()
    if pick_teacher != "(×›×•×œ×)":
        df_for_teacher = df_for_teacher[df_for_teacher["×©× ×”××“×¨×™×š"] == pick_teacher]
    # ×¨×©×™××ª ×”×¡×˜×•×“× ×˜×™× + × ×™×¦×•×œ ×§×™×‘×•×œ×ª ×œ××•×ª× ××•×¡×“×•×ª
    st.dataframe(
        pd.DataFrame({
            "×©× ×”×¡×˜×•×“× ×˜/×™×ª": (df_for_teacher["×©× ×¤×¨×˜×™"].astype(str) + " " + df_for_teacher["×©× ××©×¤×—×”"].astype(str)).str.strip(),
            "×ª×¢×•×“×ª ×–×”×•×ª": df_for_teacher["×ª\"×– ×”×¡×˜×•×“× ×˜"],
            "×©× ××§×•× ×”×”×ª××—×•×ª": df_for_teacher["×©× ××§×•× ×”×”×ª××—×•×ª"],
            "××—×•×– ×”×ª×××”": df_for_teacher["××—×•×– ×”×ª×××”"].astype(int)
        }).sort_values("××—×•×– ×”×ª×××”", ascending=False),
        use_container_width=True
    )
